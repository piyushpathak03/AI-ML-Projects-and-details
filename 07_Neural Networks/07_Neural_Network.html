<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>07_Neural_Network</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Author:-Pratik-Sharma">Author: <a href="https://github.com/sharmapratik88/">Pratik Sharma</a><a class="anchor-link" href="#Author:-Pratik-Sharma">&#182;</a></h3><h2 id="Project-7---Neural-Networks">Project 7 - Neural Networks<a class="anchor-link" href="#Project-7---Neural-Networks">&#182;</a></h2><p>Recognizing multi-digit numbers in photographs captured at street level is an important component of modern-day map making. A classic example of a corpus of such street level photographs is Google’s Street View imagery comprised of hundreds of millions of geo-located 360 degree panoramic images. The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed number with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents.</p>
<p>More broadly, recognizing numbers in photographs is a problem of interest to the optical character recognition community. While OCR on constrained domains like document processing is well studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts, colors, styles, orientations, and character arrangements. The recognition problem is further complicated by environmental factors such as lighting, shadows, specularities, and occlusions as well as by image acquisition factors such as resolution, motion, and focus blurs.</p>
<p>In this project we will use dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.</p>
<p><strong>The Street View House Numbers (SVHN) Dataset</strong></p>
<p>SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.</p>
<p><a href="https://drive.google.com/file/d/1L2-WXzguhUsCArrFUc8EEkXcj33pahoS/view?usp=sharing">Link to the dataset</a></p>
<p><strong>Acknowledgement for the datasets</strong></p>
<p>Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. PDF <a href="http://ufldl.stanford.edu/housenumbers">http://ufldl.stanford.edu/housenumbers</a> as the URL for this site when necessary.</p>
<p><strong>Objective of the project</strong> is to learn how to implement a simple image classification pipeline based on a deep neural network.</p>
<ul>
<li>Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)</li>
<li>Data fetching and understand the train/val/test splits</li>
<li>Implement and apply a deep neural network classifier including (feed forward neural network, RELU, activations)</li>
<li>Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions)</li>
<li>Implement batch normalization for training the neural network</li>
<li>Print the classification accuracy metrics</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Mounting Google Drive</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="k">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True).
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Setting the current working directory</span>
<span class="kn">import</span> <span class="nn">os</span><span class="p">;</span> <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;drive/My Drive/Great Learning/Neural Network&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='import'></a></p>
<h3 id="Import-Packages">Import Packages<a class="anchor-link" href="#Import-Packages">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="o">,</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span><span class="o">,</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">matplotlib.style</span> <span class="k">as</span> <span class="nn">style</span><span class="p">;</span> <span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># Metrics and preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">auc</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>

<span class="c1"># TF and Keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="k">import</span> <span class="n">optimizers</span>

<span class="c1"># Checking if GPU is found</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">device_name</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()</span>
<span class="k">if</span> <span class="n">device_name</span> <span class="o">!=</span> <span class="s1">&#39;/device:GPU:0&#39;</span><span class="p">:</span>
  <span class="k">raise</span> <span class="ne">SystemError</span><span class="p">(</span><span class="s1">&#39;GPU device not found&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Found GPU at: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device_name</span><span class="p">))</span>

<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>

</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Found GPU at: /device:GPU:0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls <span class="s1">&#39;/content/drive/My Drive/Great Learning/Neural Network&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&#39;07_Neural Network.ipynb&#39;   SVHN_single_grey1.h5
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='load'></a></p>
<h3 id="Load-train,-val-and-test-datasets-from-h5py-file">Load train, val and test datasets from h5py file<a class="anchor-link" href="#Load-train,-val-and-test-datasets-from-h5py-file">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Read the h5 file</span>
<span class="n">h5_SVH</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s1">&#39;SVHN_single_grey1.h5&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="c1"># Load the training, validation and test sets</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;X_train&#39;</span><span class="p">][:]</span>
<span class="n">y_train_o</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;y_train&#39;</span><span class="p">][:]</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;X_val&#39;</span><span class="p">][:]</span>
<span class="n">y_val_o</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;y_val&#39;</span><span class="p">][:]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;X_test&#39;</span><span class="p">][:]</span>
<span class="n">y_test_o</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;y_test&#39;</span><span class="p">][:]</span>

<span class="c1"># Close this file</span>

<span class="n">h5_SVH</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training set&#39;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train_o</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation set&#39;</span><span class="p">,</span> <span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_val_o</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set&#39;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test_o</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique labels in y_train:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train_o</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique labels in y_val:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_val_o</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique labels in y_test:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test_o</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training set (42000, 32, 32) (42000,)
Validation set (60000, 32, 32) (60000,)
Test set (18000, 32, 32) (18000,)


Unique labels in y_train: [0 1 2 3 4 5 6 7 8 9]
Unique labels in y_val: [0 1 2 3 4 5 6 7 8 9]
Unique labels in y_test: [0 1 2 3 4 5 6 7 8 9]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o1'></a></p>
<h4 id="Observation-1---Sets-Shape">Observation 1 - Sets Shape<a class="anchor-link" href="#Observation-1---Sets-Shape">&#182;</a></h4><ul>
<li>Length of training sets: 42k, validation sets: 60k, test sets: 18k</li>
<li>Size of the images: 32*32</li>
<li>Number of class: 10</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='visualize'></a></p>
<h3 id="Visualizing-first-10-images">Visualizing first 10 images<a class="anchor-link" href="#Visualizing-first-10-images">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Visualizing first 10 images in the dataset and their labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Label for each of the above image: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">y_train_o</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="mi">10</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA7kAAAB1CAYAAACLZSaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Label for each of the above image: [2 6 7 4 4 0 3 0 7 3]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking first image and label in training set&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Label:&#39;</span><span class="p">,</span> <span class="n">y_train_o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking first image and label in training set
--------------------------------------------------------------------------------
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Label: 2
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking first image and label in validation set&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_val</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Label:&#39;</span><span class="p">,</span> <span class="n">y_val_o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking first image and label in validation set
--------------------------------------------------------------------------------
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0
dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdVUlEQVR4nO2da4xd1ZXnf4unwYXL4GcZW2BSBdhA
2hMnJJNGhEeDeIbwCHkoiBaJaI2aKK3pfEAdJUOHidQ9M518iFrdSUTUqMmQZIhRTMJM8BAThMJA
B4IN2MHlBwSb8iOxXdjGTmy8+8O95+bWrb1W3Xuq6hZz8v9JpTpn7bvP2Xffs+4+d/3P2ttSSggh
qskxU90AIcTkIQcXosLIwYWoMHJwISqMHFyICnPcZB14eHhY4Xkhukhvb6+12sY1gpvZVWb2iplt
NLO7x3MsIcTEU9rBzexY4B+Bq4GlwCfMbOlENUwIMX7Gc4t+IbAxpbQZwMy+C9wArGt94csvvwzA
CSecwO9//3sA3n77bffAb731VtYe1TnhhBPcsmnTpo3aP3ToEAAzZ85065144olZ+/79+906+/bt
c8sOHz48Yr+3t5fh4eHwXBC/79/97ndZe/H+crT2b39/Pxs3bgTAbNRdXoOjR4+6Zccdl7+U5syZ
49aZN2/eiP0DBw4wffp0AHp6etx6URs9jjnGH8ta39f27duZP3/+mMc89thj3TKvPwC8h8tar4+h
oSH6+voA/z0X/eVhZZ9kM7NbgKtSSp+p798GvD+ldBeM/A0+ODhY6hxCiJiBgYHGdu43+KQF2Zop
Rm2N4BrBm9EIPpIyI/hYjCfItg1Y1LS/sG4TQrxDGM8I/m/AgJktpubYHwc+mXvhwYMHgdooW2zv
2rXLPfBvfvObrP3AgQNunRkzZrhlixYtGrE/f/589u7dC8BJJ53k1vNGkWh0Ke5QcuRG1WJ0LntX
sGPHjqx99+7dbp3ivRf09/fz7LPPAv7o0tzWHN6IVYxAOc4777wR+3PnzmXLli0AnHPOOW692bNn
u2XeqBrdfeQ+l+KO8MiRI2696K4gKuuE448/flzHK+3gKaUjZnYX8BPgWODbKaWXyx5PCDHxjOs3
eErpUeDRCWqLEGKC0aOqQlQYObgQFUYOLkSFkYMLUWG68qDLzp07gdqDHcV28fhqjk2bNoXHyRFJ
OK0PLXz+85/ngQceAOC9732vW+/iiy/O2ltlt2ZaH1ZoJtf+4kGVV1991a1XSEc5Nm/enLV7UiP8
QbYs+OQnP8nPfvYzIG5/VObJZNEDI61S6a233soTTzwBxLLW8uXL3bJTTjkla4/krty1U9gi2TBq
Y1SvzNOjZWUyjeBCVBg5uBAVRg4uRIWRgwtRYeTgQlSYrkTR165dC9RyV4vt559/3n19mchwFOGd
NWvWKNvTTz8NdBZ9L4iSTVoTOZrZunXriP2+vr6G7bnnnnPrbdiwwS3bti2fwBeli+Yism+88QYQ
R3i91FTw+z/6zFq59dZb+eUvfwnE0fczzjjDLTv55JOz9rJR6ChSHpVFeKmfOXvxeXjp0NH1CxrB
hag0cnAhKowcXIgKIwcXosLIwYWoMHJwISpMV2SyF198EYCbb765sR0lm3jztUXznUWzWLYmVzTb
hoaG3HqtslbB3Llz3TpRQkwhERa8733va9iKfskRSU2eHFbM5ZUjJ8cU/RfJSdHMnl47Op1PrrB5
8h/Anj173DIvEajT+dMKWzRzaiQpRueLjum9tuz05hrBhagwcnAhKowcXIgKIwcXosLIwYWoMHJw
ISpMV2SyNWvWjNqO5BNP4olkmk7LCls0V5dXFsl1kez22muvuTZvCSKIM4Y8yS5aVDGXcbV06VK3
rODXv/61W+ZlmkVtz2XeFbZIGow+My/DK5JRc8tXFbao/dE1VyZ7LSeFFb7gZeuNJbmNy8HN7FVg
H/A2cCSl5M9gKIToOhMxgl+aUmo/6VcI0TX0G1yICmNlH4EDMLMtwB4gAd9IKX2zKBseHm4ceHBw
cDxtFEI4DAwMNLZ7e3tHBQXGe4t+UUppm5nNBVaZ2a9SSk+2vujGG28E4OGHH25sv/nmm+5BvcBG
FFyJAh6ta4f/+Mc/5tprrwVg8eLFbr3rrrsua1+2bJlbZ/369W7Z6tWrR+x/+ctf5ktf+hIw+jn1
ZqJAj7dWdidBtq985St84QtfyJY1EwXZvMUZorb39vaO2F+xYgU33XQTAJdeeqlb7/bbb3fLvM/G
m/IIRgfmNmzYwNlnnw1MbZBtcHCw4cBjTc3ktqNUrT80aFv9/07gYeDC8RxPCDGxlB7BzWw6cExK
aV99+0rgy7nXNo/WxXankwJGdohlkChbKPpm944ZTT7oZcJBnD0VSW/RJI9LlizJ2s8991y3zsKF
C0fZbr755jHb8cwzz7hl3mSTkRya+3nYzk/G6Drw7vKi0TYnyxbnKDtKl1m6KCfxFa/13tdkymTz
gIfrHXAc8D9TSv9nHMcTQkwwpR08pbQZ+JMJbIsQYoKRTCZEhZGDC1Fh5OBCVBg5uBAVpivZZM1r
SRXbr7/+uvv64eHhrP3EE09060RyQa6ssEXHnD59etb+1ltvuXWKNb7arVfYIjkmevgkJ3kBfPCD
H2y7zqFDhxqvj7LhXnnlFbcsl5EFcV/lZMjC5h0PYmnTy7qKHhTJXR+FZFVWCovO52W85eoU8lh0
fURoBBeiwsjBhagwcnAhKowcXIgKIwcXosJ0JYq+fPnyUdtRdNKL1paNJEZE0Vov5TKKkEZzie3e
vdu1RQksUdTYm5Otv7/frdOqHBw6dKiRuhnNDRclonhlUVLRtGnT3LIoeShSPrwyL7oO+c+zsJVN
0/Qi5eBH36O5AztZ7qgZjeBCVBg5uBAVRg4uRIWRgwtRYeTgQlQYObgQFaYrMtnll18+avvgwYPu
67dv3561RzOxdrqcTWGLpJrWWT/baUckC0XtiIgkEk9ujOSdXDJPYfvtb3/r1svJfAXe3GuRPJX7
zApb1C+RTOZJm9HccLk2Ru0u6DTBaSxyn2UxX5wnG47VTo3gQlQYObgQFUYOLkSFkYMLUWHk4EJU
GDm4EBWmKzLZnDlzRm17EhTkl5KBcnIRxEvkRMf0Ms3KLJwI+Yyxwha1I5IAvbIo8ysnrRSvj+qV
yayKssKiufLKLlPlZRxGdXLXR/H66D2XWWAwqhctsVV2FeAxW2hm3zaznWb2UpPtNDNbZWaD9f+n
ljq7EGJSaecr6F+Aq1psdwOPp5QGgMfr+0KIdxhjOnh9ve/WR5huAO6vb98PfGSC2yWEmACsnXt7
MzsT+FFK6fz6/t6U0sz6tgF7iv2C4eHhxoEHBwcnsMlCiIKBgYHGdm9v76gAxLiDbCmlZGbht0Tx
fPOsWbMa2ytWrHBf/+ijj2bt3hrUEAc8WhcOeOSRR7j++usBuOSSS9x6d9xxR9YeTWv0jW98wy1b
s2bNiP2f/vSnXHbZZUAcZDvzzDPdso9+9KNZe/H+crQG2Y4ePdrov3Xr1rn1os/s6aefztqjnIPW
58YfeughbrnlFgCuu+46t95dd93lljVf8M1ECzC09sfmzZs566yzgDjIVibYB+0H2X71q1811nn3
jhcFYKG8TLbDzPrqJ+4DdpY8jhBiEik7gq8Ebgf+rv7/h9GLm5cAKraj5Xi80Sz6ORF9Y+Zkt8IW
TXbofetH35qexAexLBRNrBjdnXj1otGltY379+9vfB5RplbURq8skt0iWSjKkopGY68syk7Ltb2w
RSN42aWLvLLcNVz0X/R5RrQjkz0IPA2cY2ZbzezT1Bz7CjMbBP6svi+EeIcx5tdCSukTTtHljl0I
8Q5Bj6oKUWHk4EJUGDm4EBVGDi5EhelKNlkhwRw9erSx3dPT477ek8nKZvZEckwk43iTDEYTK0Zl
OamjsEUPukR9NWPGjKw9mkwykgbLylNevUjeieSpiLEe7sgRSVqRfBl9LlFfdTrZJOT7qrjmtTaZ
EGIUcnAhKowcXIgKIwcXosLIwYWoMHJwISpMV2SyQpJqzjuOsq48aWWi14ICOHDggFvmrdMVnSuS
haK1uDqdnLDA68dINsy958IWrU0W5eN78mCUnRbJhlG9KBPR68dIGsz1bzufS5TBWIacDFxmostm
NIILUWHk4EJUGDm4EBVGDi5EhZGDC1FhuhJFb44eF9tRwoAXnSwTeYd4yaAogWLfvn0dnysqi6Kk
ZRIowO+rKPraOj+ZmTVsUbQ5UhyiOc88cpHywnbqqf5iOa2zsTZTZtmraGmr6HOJ3nOkYnSifLST
fBOhEVyICiMHF6LCyMGFqDBycCEqjBxciAojBxeiwnRVJjvuuOPaksk8+SGa5yqSd3LzkxWvb15W
qRVvvrNt27a5dXbt2uWWRXN/lcWTUSIJJyetFbZojrqorAyRPBVJopEE+Oabb2btncqyRf9FCSVl
l9LyJLTctVDIrt7xxpIn21m66NtmttPMXmqy3WNm28zshfrfNWMdRwjRfdq5Rf8X4KqM/WsppWX1
v/x6v0KIKWVMB08pPQnk5w8WQryjseh3RONFZmcCP0opnV/fvwf4c+BN4BfAX6eU9jTXGR4ebhx4
cHBwotorhGhiYGCgsd3b2zvqh3rZINs/AfcCqf7/H4A7vBfngmwrV650D/7QQw9l7W+88YZbJwo2
tAbZHnvsMa688koAli1b5ta79tprs/YoyLZq1Sq3bOvWraNee8UVVwDxM+wXXHCBW/aZz3wma7/w
wgvdOtHMLI899phb9uCDD7plr7/+etZ+0kknuXX6+vpG7H/zm9/kzjvvBOCmm25y6912221u2Smn
nJK1R0G21kDlxo0b6e/vB8oH2ToNcsLoINuGDRs4++yzwzrjDrLlSCntSCm9nVI6CnwL8K8mIcSU
UWoEN7O+lNJQffdG4KXo9c3fTO0sCRPNx+URjYA5maywLVy40K23YMGCrH379u1unWikiOYgi5Ya
ijKKPDkpWkKpVUqaMWNGwxaN7pFM6X2eZWXAKGMsuivwpLxIdotkw6j9kVzXzk/fTtpRdv63MR3c
zB4ELgFmm9lW4L8Al5jZMmq36K8Cf1Hq7EKISWVMB08pfSJjvm8S2iKEmGD0qKoQFUYOLkSFkYML
UWHk4EJUmK5kkxUSxZEjRxrbkdRRRnKJZLJocr8ITwaJJtSLJK1o0sWo/dFSPZG85jE8PDxif8aM
GQ1bJJNFGXuePBg9iJHrq8IWXR/RZ+fJU9FnlisrrrWo/ZFMFsml3nWcO1dhKys3agQXosLIwYWo
MHJwISqMHFyICiMHF6LCyMGFqDBdkcmyJw5kIS9zpmz+bS6zqrB564+BvxZXJBd1siZYsy3Kdpo1
a5ZbNnv27Kw9kpmi/ojWaivzviN5J8ry63QtsfEQTf4YXVdl1mODzvqqOEck80VoBBeiwsjBhagw
cnAhKowcXIgKIwcXosJ0JYreHBVvZ64rL2JYNmqZm6ersHlL3cDopIyCKPIeRaFzCQjNM856eEso
AfT29mbt0fGipJcyCSXgKx89PT1unfnz57u2aEmp6DooE22O1I0oYl+2zGtjNCdb2WtfI7gQFUYO
LkSFkYMLUWHk4EJUGDm4EBVGDi5EhemKTFZIYocPH25sT5ScUdDpPGmFLZIzPMno4MGDbp1ISopk
sqgdUSKK1yeR3BUlV0TJMlEfe3PDeYsBAixatMi1RQk2ZSTWiFwfFv0RLRlUdjkh77OOPhfvfY2V
eDNmb5jZIjNbbWbrzOxlM/tc3X6ama0ys8H6/1PHOpYQoru083V3hNr630uBDwB/aWZLgbuBx1NK
A8Dj9X0hxDuIMR08pTSUUnq+vr0PWA+cDtwA3F9/2f3ARyarkUKIclgnyfNmdibwJHA+8OuU0sy6
3YA9xT7A8PBw48CDg4MT1FwhRDMDAwON7d7e3lFBgbaDbGbWA/wA+KuU0pvNAYaUUjIz95uiCMAc
OnSosb1q1Sr3XA888EDWvn79erdO9Ox163PNjzzyCNdffz0AS5YscetdeumlHbfjqaeecst27tw5
6rUXXXQRAIsXL3br3XDDDW7Zpz71qaw9WoDhmWeeGbG/ZMmSxnt6+OGH3Xo///nP3TIvOBe9rw99
6EMj9j/2sY/xve99D4Crr77arbd8+XK3rEyQrbXtGzdupL+/f8x6nQZUC7zgXOtntmnTJt71rncB
fmBx3EG2eoOOp+bc30kpraibd5hZX728D9jp1RdCTA1jjuD12+/7gPUppa82Fa0Ebgf+rv7/h52c
OPqG876Fo1GpUwmnsEVL/3jftJFcd/jwYbcsd5dR2KLleKL35p0vkpKirKXoc4nkOq/9c+fOdesU
o1POtnDhQrdep8shQfy+omyySAqL7hojvGOWySYbS6prp4V/CtwGvGhmL9Rtf0PNsb9vZp8GXgNu
beNYQoguMqaDp5SeAryvicsntjlCiIlEj6oKUWHk4EJUGDm4EBVGDi5EhelKNlnzpIfFdiRbeETL
8ZSdlC6SfjyijKuIk08+2bVF7y1qo9eW6AGI/fv3u7YoUy6S63LvDWDevHlundzDJIUtyiaL+sNr
Y9nPrOySQZ3KlF6dwqZJF4UQo5CDC1Fh5OBCVBg5uBAVRg4uRIWRgwtRYboikxXrf/X09DS2ozXB
Dh06lLVPxqSL3tpe4GealZVcIhkkIlrvrDXHvCBazyy35lph8/q+LFGW3MyZM11b1C+RxOrVi7Ku
oskOo2uuk8lS2iFqh5e5NpbcrBFciAojBxeiwsjBhagwcnAhKowcXIgKM2VR9Fwkt8BbdieKGPb0
9Lhlp546etGVwtbX1+fWi5bd8YiirrlIbhEljZI8tm3b5patW7cua4+SPPbs2ePaooh9pFR47zuK
yreWTZs2rWE7cOCAW68d5aGVTpdkKmxlk02iCLtXNhnt0AguRIWRgwtRYeTgQlQYObgQFUYOLkSF
kYMLUWG6IpMVktiCBQsa21GyiSfVRMsCRdJJJJPNnj3breclokRL1kQyWU7mKyTBSDbctGmTW+bJ
JwsWLHDr7NixY5RtaGgIgL1797r1ov73iGS35rn6oCaTFbZIZooSR7z+96RXyCfEtLN00UQnouSk
vLKJTQVjjuBmtsjMVpvZOjN72cw+V7ffY2bbzOyF+t8142qJEGLCaWcEPwL8dUrpeTM7BXjOzIq1
f7+WUvofk9c8IcR4aGdtsiFgqL69z8zWA6dPdsOEEOPHOvmtYGZnAk8C5wP/Gfhz4E3gF9RG+cYz
kMPDw40DDw4OTkhjhRAjGRgYaGz39vaOChi07eBm1gP8DPhKSmmFmc0DfgMk4F6gL6V0R/H6Zgdf
uXIlAEuWLGH9+vUA/OQnP3HP9cQTT2TtUWAuCpadc845I/bvvfdevvjFLwJw2WWXufUWLVqUta9Y
scKts3r1aresNci2atUqrrjiCiA/u0lBtMZ28wfcTCdBts9+9rN8/etfB+Cpp55y60WBKm8xgve/
//1unTvvvHPE/owZMxqf8dlnn93xuaKy6Jn41iDbli1bWLx4MRAHbyc6yNYavB0cHGx8vl47moNw
OQdvSyYzs+OBHwDfSSmtAEgp7UgpvZ1SOgp8C7iwnWMJIbrHmL/BraYT3AesTyl9tcneV/99DnAj
8JJ3jF27dgG1EbzYzkk1BV5mVfRtGn1j5mStwhYtGeRlr3nL9HjnGut4EI9KkTy1Zs2arH3z5s1u
ndzI88orrwCjpatmogwv7w5k+vTpbp1cfxS26LOOpCPvLi/6XHJ3JtHdYkEkoUV47y0n1xVty80r
2E4b2omi/ylwG/Cimb1Qt/0N8AkzW0btFv1V4C/aOJYQoou0E0V/Csh9TTw68c0RQkwkelRViAoj
BxeiwsjBhagwcnAhKkxXssmaHzIotvft2+e+PpJq2jlHKzl5p7BF2U5eNlkkrUUTNUZtjLK4or7y
2u8tuwR5SW7r1q1AnNUWyXWeTBbJf63nOu200xo2b0kmiCW0/fv3Z+2RTJY7XvF5RJMdlnngBnxp
K1q6yJOBx5LJNIILUWHk4EJUGDm4EBVGDi5EhZGDC1Fh5OBCVJiuTrrYvB3lFkdZVx7R2l45mamw
ebIK+HJMlJ8drXWWe88zZsxw21gQyWuedBVl1+X6t+i/SIKKpCZPJovkuty5CluUMRZJQ15ZJ7nb
ZtZWVlskoZVZxy3Ck93GmpRRI7gQFUYOLkSFkYMLUWHk4EJUGDm4EBVGDi5EhemKTNbf3z9qO5KF
Tj89v65CJC9EskRO1rrgggsAOOuss9x63tS98+bNc+tE0zdv2bJllO3mm28GOlvDqx0ieScnk334
wx8G8hP/FURZdJ50eO6557p1li5dOmJ/3759nHfeeUAts8wjem9lZMPW6+qNN95wr8Gyx2zGkxtz
13Bh866BqC9AI7gQlUYOLkSFkYMLUWHk4EJUGDm4EBWmo9VFO6F58cEiAvjaa69xxhlnAPHSRV5Z
9GB9tJxQ6zxphw8fbjy8P2fOHLeeFxGPIqTRkjetEd6hoaEwOaUgSr7x2hIlZLRGcbdv3878+fOB
ODmkzGJ7ncxf99xzz7F8+XIgbn90zXpR9E4UmLVr1/Lud7+79LkgVj48xaf1PTcvPtgOpRYfNLNp
Zvasma0xs5fN7G/r9sVm9oyZbTSz75lZfvEkIcSU0c4t+u+Ay1JKfwIsA64ysw8Afw98LaXUD+wB
Pj15zRRClGFMB081iqTp4+t/CbgMeKhuvx/4yKS0UAhRmrZ+g5vZscBzQD/wj8B/B/5fffTGzBYB
/zuldH5Rp/k3+ODg4AQ3WwgBjPiNnvsN3tajqimlt4FlZjYTeBjwnz/MUATWFGRTkK0ZBdlGMt4g
W/Zcnbw4pbQXWA38R2CmmRVXykJg27haIoSYcMYcwc1sDnA4pbTXzE4CrqAWYFsN3AJ8F7gd+KF7
kqYRo9hesGCBe04v0SCaEyxaKqb123vLli0sXLgQiL+Fd+/e3dbxmom+8aNkgogoocB739EIkqtT
2KL2RKOqN2/cnj173Dq5efSKJYui99xpIg3Ed3+5u4yibdF1FVFm3ricvbCVmWsO2rtF7wPur/8O
Pwb4fkrpR2a2Dviumf1X4JfAfW0cSwjRRcZ08JTSWuA/ZOybgQsno1FCiIlBj6oKUWHk4EJUGDm4
EBWmK8kmQojJp1SyiRDi/1/k4EJUmEm7RRdCTD0awYWoMHJwISpMVxzczK4ys1fqs7/c3Y1zOu14
1cxeNLMXzOwXXT73t81sp5m91GQ7zcxWmdlg/f+pU9SOe8xsW71fXjCzaya5DYvMbLWZravPEvS5
ur2r/RG0o9v9MXmzJqWUJvUPOBbYBJwFnACsAZZO9nmdtrwKzJ6ic18MvAd4qcn234C769t3A38/
Re24B/h8F/uiD3hPffsUYAOwtNv9EbSj2/1hQE99+3jgGeADwPeBj9ft/wz8p06P3Y0R/EJgY0pp
c0rp99Syz27ownnfUaSUngRa09NuoDYbDnRpVhynHV0lpTSUUnq+vr0PWA+cTpf7I2hHV0k1JmXW
pG44+OnA6037W5mCTqyTgMfM7Dkzu3OK2tDMvJTSUH17O+Avejb53GVma+u38JP+U6HAzM6klsz0
DFPYHy3tgC73h5kda2YvADuBVdTuevemlIr811J+88cWZLsopfQe4GrgL83s4qluUEGq3YdNlWb5
T8C7qE2qOQT8QzdOamY9wA+Av0opjZgKp5v9kWlH1/sjpfR2SmkZtclTLqTDWZM8uuHg24BFTftT
NvtLSmlb/f9OalNPTXW66w4z6wOo/985FY1IKe2oX2BHgW/RhX4xs+OpOdV3Ukor6uau90euHVPR
HwVpgmdN6oaD/xswUI8IngB8HFjZhfOOwMymm9kpxTZwJfBSXGvSWUltNhwYY1acyaRwqjo3Msn9
YrXpSe4D1qeUvtpU1NX+8NoxBf0xpz7fIU2zJq3nD7MmQdn+6FKU8BpqEcpNwBe6FZ1sacNZ1CL4
a4CXu90O4EFqt3uHqf2e+jQwC3gcGAT+L3DaFLXjX4EXgbXUnKxvkttwEbXb77XAC/W/a7rdH0E7
ut0f76Y2K9Jaal8mX2q6Zp8FNgL/Czix02PrUVUhKswfW5BNiD8q5OBCVBg5uBAVRg4uRIWRgwtR
YeTgQlQYObgQFebfAfmL0QQbDJBwAAAAAElFTkSuQmCC
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Label: 0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking first image and label in test set&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Label:&#39;</span><span class="p">,</span> <span class="n">y_test_o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking first image and label in test set
--------------------------------------------------------------------------------
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Label: 1
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='flatten'></a></p>
<h3 id="Flatten-and-normalize-the-images-for-Keras">Flatten and normalize the images for Keras<a class="anchor-link" href="#Flatten-and-normalize-the-images-for-Keras">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reshaping X data: (n, 32, 32) =&gt; (n, 1024)&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Making sure that the values are float so that we can get decimal points after division&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Normalizing the RGB codes by dividing it to the max RGB value&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">X_val</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">X_test</span> <span class="o">/=</span> <span class="mi">255</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Converting y data into categorical (one-hot encoding)&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train_o</span><span class="p">)</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_val_o</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test_o</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Reshaping X data: (n, 32, 32) =&gt; (n, 1024)
--------------------------------------------------------------------------------
Making sure that the values are float so that we can get decimal points after division
--------------------------------------------------------------------------------
Normalizing the RGB codes by dividing it to the max RGB value
--------------------------------------------------------------------------------
Converting y data into categorical (one-hot encoding)
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_train shape:&#39;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_val shape:&#39;</span><span class="p">,</span> <span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X_test shape:&#39;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_train shape:&#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_val shape:&#39;</span><span class="p">,</span> <span class="n">y_val</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_test shape:&#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of images in X_train&#39;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of images in X_val&#39;</span><span class="p">,</span> <span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of images in X_test&#39;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X_train shape: (42000, 1024)
X_val shape: (60000, 1024)
X_test shape: (18000, 1024)


y_train shape: (42000, 10)
y_val shape: (60000, 10)
y_test shape: (18000, 10)


Number of images in X_train 42000
Number of images in X_val 60000
Number of images in X_test 18000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='Baby'></a></p>
<h3 id="Modelling---Baby-sitting-the-learning-process">Modelling - Baby sitting the learning process<a class="anchor-link" href="#Modelling---Baby-sitting-the-learning-process">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Fully-connected-linear-layer">Fully connected linear layer<a class="anchor-link" href="#Fully-connected-linear-layer">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradW</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradB</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span> <span class="o">=</span> <span class="kc">None</span>        

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nextgrad</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">nextgrad</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nextgrad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">nextgrad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">gradW</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradB</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="ReLU">ReLU<a class="anchor-link" href="#ReLU">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ReLU</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nextgrad</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span> <span class="o">=</span> <span class="n">nextgrad</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">&lt;=</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradInput</span><span class="p">,</span> <span class="p">[]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Softmax-function">Softmax function<a class="anchor-link" href="#Softmax-function">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">exp_x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Cross-entropy-loss">Cross entropy loss<a class="anchor-link" href="#Cross-entropy-loss">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CrossEntropy</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">cross_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">),</span> <span class="n">y</span><span class="p">]</span><span class="o">+</span><span class="mf">1e-16</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>
        <span class="k">return</span> <span class="n">loss</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">y_idx</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>        
        <span class="n">grad</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">grad</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">),</span> <span class="n">y</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">grad</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>
        <span class="k">return</span> <span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-class-that-enables-the-forward-prop-and-backward-propagation-of-the-entire-network">NN class that enables the forward prop and backward propagation of the entire network<a class="anchor-link" href="#NN-class-that-enables-the-forward-prop-and-backward-propagation-of-the-entire-network">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">NN</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lossfunc</span> <span class="o">=</span> <span class="n">CrossEntropy</span><span class="p">(),</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">lossfunc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        
    <span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nextgrad</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_grad_param</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">nextgrad</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">nextgrad</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">grads</span>
    
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">nextgrad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">out</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">nextgrad</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">predict_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p</span>
    
    <span class="k">def</span> <span class="nf">clear_grad_param</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Update-function-SGD-with-momentum">Update function SGD with momentum<a class="anchor-link" href="#Update-function-SGD-with-momentum">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">velocity</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">velocity</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">grads</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)):</span>
            <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Get-minibatches">Get minibatches<a class="anchor-link" href="#Get-minibatches">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">minibatches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">permutation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="p">,</span> <span class="n">minibatch_size</span><span class="p">):</span>
        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="p">]</span>
        <span class="n">minibatches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">))</span>
        
    <span class="k">return</span> <span class="n">minibatches</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="The-training-loop">The training loop<a class="anchor-link" href="#The-training-loop">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">X_val</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Lambda</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">verb</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="n">val_loss_epoch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">minibatches</span> <span class="o">=</span> <span class="n">minibatch</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">)</span>
    <span class="n">minibatches_val</span> <span class="o">=</span> <span class="n">minibatch</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
        <span class="n">loss_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">val_loss_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">velocity</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">param_layer</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">param_layer</span><span class="p">)]</span>
            <span class="n">velocity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            
        <span class="c1"># iterate over mini batches</span>
        <span class="k">for</span> <span class="n">X_mini</span><span class="p">,</span> <span class="n">y_mini</span> <span class="ow">in</span> <span class="n">minibatches</span><span class="p">:</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">X_mini</span><span class="p">,</span> <span class="n">y_mini</span><span class="p">)</span>
            <span class="n">loss_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">update</span><span class="p">(</span><span class="n">velocity</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">X_mini_val</span><span class="p">,</span> <span class="n">y_mini_val</span> <span class="ow">in</span> <span class="n">minibatches_val</span><span class="p">:</span>
            <span class="n">val_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span><span class="n">X_mini</span><span class="p">,</span> <span class="n">y_mini</span><span class="p">)</span>
            <span class="n">val_loss_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        
        <span class="c1"># accuracy of model at end of epoch after all mini batch updates</span>
        <span class="n">m_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">m_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_train_pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_val_pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_train1</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_vall</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">m_train</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">):</span>
            <span class="n">X_tr</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="p">:</span> <span class="p">]</span>
            <span class="n">y_tr</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,]</span>
            <span class="n">y_train1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train1</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
            <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train_pred</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_tr</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">m_val</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">):</span>
            <span class="n">X_va</span> <span class="o">=</span> <span class="n">X_val</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="p">:</span> <span class="p">]</span>
            <span class="n">y_va</span> <span class="o">=</span> <span class="n">y_val</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,]</span>
            <span class="n">y_vall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_vall</span><span class="p">,</span> <span class="n">y_va</span><span class="p">)</span>
            <span class="n">y_val_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_val_pred</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_va</span><span class="p">))</span>
            
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">check_accuracy</span><span class="p">(</span><span class="n">y_train1</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">check_accuracy</span><span class="p">(</span><span class="n">y_vall</span><span class="p">,</span> <span class="n">y_val_pred</span><span class="p">)</span>
        
        <span class="c1">## weights</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="c1">## adding regularization to cost</span>
        <span class="n">mean_train_loss</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)))</span>
        <span class="n">mean_val_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">val_loss_batch</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_loss_batch</span><span class="p">))</span>
        
        <span class="n">val_loss_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_val_loss</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verb</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="k">50</span>==0:
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{3}</span><span class="s2">/</span><span class="si">{4}</span><span class="s2">: Loss = </span><span class="si">{0}</span><span class="s2"> | Training Accuracy = </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">epoch</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">net</span><span class="p">,</span> <span class="n">val_acc</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Checking-the-accuracy-of-the-model">Checking the accuracy of the model<a class="anchor-link" href="#Checking-the-accuracy-of-the-model">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">check_accuracy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Invoking-all-that-we-have-created-until-now">Invoking all that we have created until now<a class="anchor-link" href="#Invoking-all-that-we-have-created-until-now">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Invoking the model</span>
<span class="c1">## input size</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">train_and_test_loop</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">verb</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="c1">## hyperparameters</span>
    <span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">lr</span>
    <span class="n">hidden_nodes1</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">output_nodes</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="c1">## define neural net</span>
    <span class="n">nn</span> <span class="o">=</span> <span class="n">NN</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">add_layer</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_nodes1</span><span class="p">))</span>

    <span class="n">nn</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">nn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_o</span><span class="p">,</span> <span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">=</span> <span class="n">iterations</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span>\
                      <span class="n">X_val</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_test_o</span><span class="p">,</span> <span class="n">Lambda</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">verb</span> <span class="o">=</span> <span class="n">verb</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">val_acc</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Double-Check-that-the-loss-is-reasonable-:-Disable-the-regularization">Double Check that the loss is reasonable : Disable the regularization<a class="anchor-link" href="#Double-Check-that-the-loss-is-reasonable-:-Disable-the-regularization">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.00001</span>
<span class="n">Lambda</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">train_and_test_loop</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 0/1: Loss = 2.3117883972138844 | Training Accuracy = 0.09335714285714286
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.09438888888888888</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Now,-lets-crank-up-the-Lambda(Regularization)-and-check-what-it-does-to-our-loss-function">Now, lets crank up the Lambda(Regularization) and check what it does to our loss function<a class="anchor-link" href="#Now,-lets-crank-up-the-Lambda(Regularization)-and-check-what-it-does-to-our-loss-function">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.00001</span>
<span class="n">Lambda</span> <span class="o">=</span> <span class="mf">1e3</span>
<span class="n">train_and_test_loop</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 0/1: Loss = 2.3082000425724667 | Training Accuracy = 0.08478571428571428
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.08188888888888889</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Now,-lets-overfit-to-a-small-subset-of-our-dataset,-in-this-case-20-images">Now, lets overfit to a small subset of our dataset, in this case 20 images<a class="anchor-link" href="#Now,-lets-overfit-to-a-small-subset-of-our-dataset,-in-this-case-20-images">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train_subset</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span>
<span class="n">y_train_subset</span> <span class="o">=</span> <span class="n">y_train_o</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_subset</span>
<span class="n">y_train_o</span> <span class="o">=</span> <span class="n">y_train_subset</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train_o</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[24]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((20, 1024), (20,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Make-sure-that-you-can-overfit-very-small-portion-of-the-training-data">Make sure that you can overfit very small portion of the training data<a class="anchor-link" href="#Make-sure-that-you-can-overfit-very-small-portion-of-the-training-data">&#182;</a></h4><p>So, set a small learning rate and turn regularization off
In the code below:</p>
<ul>
<li>Take the first 20 examples</li>
<li>turn off regularization(reg=0.0)</li>
<li>use simple vanilla 'sgd'</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">Lambda</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">train_and_test_loop</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 0 ns, sys: 8 µs, total: 8 µs
Wall time: 8.11 µs
Epoch 0/5000: Loss = 2.343525441008851 | Training Accuracy = 0.0
Epoch 50/5000: Loss = 1.9368840865311359 | Training Accuracy = 0.3
Epoch 100/5000: Loss = 1.8502138907049706 | Training Accuracy = 0.3
Epoch 150/5000: Loss = 1.795704759770493 | Training Accuracy = 0.35
Epoch 200/5000: Loss = 1.7505141963680764 | Training Accuracy = 0.4
Epoch 250/5000: Loss = 1.7098591715226046 | Training Accuracy = 0.45
Epoch 300/5000: Loss = 1.6720807405140872 | Training Accuracy = 0.45
Epoch 350/5000: Loss = 1.6364256819871694 | Training Accuracy = 0.5
Epoch 400/5000: Loss = 1.602489808977548 | Training Accuracy = 0.55
Epoch 450/5000: Loss = 1.5700278004175436 | Training Accuracy = 0.55
Epoch 500/5000: Loss = 1.5388749934942745 | Training Accuracy = 0.6
Epoch 550/5000: Loss = 1.5089113416081257 | Training Accuracy = 0.6
Epoch 600/5000: Loss = 1.480043412413456 | Training Accuracy = 0.6
Epoch 650/5000: Loss = 1.4521947854019437 | Training Accuracy = 0.65
Epoch 700/5000: Loss = 1.425300621663516 | Training Accuracy = 0.65
Epoch 750/5000: Loss = 1.3993044229509757 | Training Accuracy = 0.65
Epoch 800/5000: Loss = 1.3741559975684867 | Training Accuracy = 0.65
Epoch 850/5000: Loss = 1.3498101223720105 | Training Accuracy = 0.65
Epoch 900/5000: Loss = 1.3262256235641494 | Training Accuracy = 0.65
Epoch 950/5000: Loss = 1.303364719491542 | Training Accuracy = 0.65
Epoch 1000/5000: Loss = 1.2811925334058236 | Training Accuracy = 0.65
Epoch 1050/5000: Loss = 1.2596767202488166 | Training Accuracy = 0.65
Epoch 1100/5000: Loss = 1.2387871723562258 | Training Accuracy = 0.65
Epoch 1150/5000: Loss = 1.218495781389982 | Training Accuracy = 0.65
Epoch 1200/5000: Loss = 1.1987762414312768 | Training Accuracy = 0.7
Epoch 1250/5000: Loss = 1.1796038829744615 | Training Accuracy = 0.7
Epoch 1300/5000: Loss = 1.1609555306717911 | Training Accuracy = 0.7
Epoch 1350/5000: Loss = 1.1428093797371377 | Training Accuracy = 0.7
Epoch 1400/5000: Loss = 1.1251448873080339 | Training Accuracy = 0.7
Epoch 1450/5000: Loss = 1.1079426760244366 | Training Accuracy = 0.8
Epoch 1500/5000: Loss = 1.0911844477557584 | Training Accuracy = 0.85
Epoch 1550/5000: Loss = 1.0748529058881875 | Training Accuracy = 0.85
Epoch 1600/5000: Loss = 1.058931684932634 | Training Accuracy = 0.85
Epoch 1650/5000: Loss = 1.0434052864697851 | Training Accuracy = 0.85
Epoch 1700/5000: Loss = 1.0282590206397022 | Training Accuracy = 0.85
Epoch 1750/5000: Loss = 1.013478952527564 | Training Accuracy = 0.85
Epoch 1800/5000: Loss = 0.9990518529073633 | Training Accuracy = 0.85
Epoch 1850/5000: Loss = 0.9849651528906417 | Training Accuracy = 0.85
Epoch 1900/5000: Loss = 0.9712069020941513 | Training Accuracy = 0.85
Epoch 1950/5000: Loss = 0.9577657299933456 | Training Accuracy = 0.85
Epoch 2000/5000: Loss = 0.9446308101711862 | Training Accuracy = 0.85
Epoch 2050/5000: Loss = 0.9317918272064819 | Training Accuracy = 0.85
Epoch 2100/5000: Loss = 0.9192389459746264 | Training Accuracy = 0.85
Epoch 2150/5000: Loss = 0.9069627831576392 | Training Accuracy = 0.85
Epoch 2200/5000: Loss = 0.8949543807808057 | Training Accuracy = 0.85
Epoch 2250/5000: Loss = 0.8832051816107626 | Training Accuracy = 0.9
Epoch 2300/5000: Loss = 0.8717070062651777 | Training Accuracy = 0.95
Epoch 2350/5000: Loss = 0.8604520318976363 | Training Accuracy = 0.95
Epoch 2400/5000: Loss = 0.849432772333326 | Training Accuracy = 0.95
Epoch 2450/5000: Loss = 0.8386420595418531 | Training Accuracy = 0.95
Epoch 2500/5000: Loss = 0.828073026343203 | Training Accuracy = 0.95
Epoch 2550/5000: Loss = 0.8177190902516587 | Training Accuracy = 0.95
Epoch 2600/5000: Loss = 0.8075739383704768 | Training Accuracy = 0.95
Epoch 2650/5000: Loss = 0.7976315132574238 | Training Accuracy = 0.95
Epoch 2700/5000: Loss = 0.7878859996879619 | Training Accuracy = 0.95
Epoch 2750/5000: Loss = 0.778331812248966 | Training Accuracy = 0.95
Epoch 2800/5000: Loss = 0.7689635837014647 | Training Accuracy = 1.0
Epoch 2850/5000: Loss = 0.7597761540560017 | Training Accuracy = 1.0
Epoch 2900/5000: Loss = 0.7507645603089181 | Training Accuracy = 1.0
Epoch 2950/5000: Loss = 0.7419240267921232 | Training Accuracy = 1.0
Epoch 3000/5000: Loss = 0.7332499560928596 | Training Accuracy = 1.0
Epoch 3050/5000: Loss = 0.7247379205035223 | Training Accuracy = 1.0
Epoch 3100/5000: Loss = 0.716383653964874 | Training Accuracy = 1.0
Epoch 3150/5000: Loss = 0.7081830444689625 | Training Accuracy = 1.0
Epoch 3200/5000: Loss = 0.700132126890769 | Training Accuracy = 1.0
Epoch 3250/5000: Loss = 0.6922270762200713 | Training Accuracy = 1.0
Epoch 3300/5000: Loss = 0.6844642011672761 | Training Accuracy = 1.0
Epoch 3350/5000: Loss = 0.6768399381190008 | Training Accuracy = 1.0
Epoch 3400/5000: Loss = 0.6693508454210667 | Training Accuracy = 1.0
Epoch 3450/5000: Loss = 0.6619935979682519 | Training Accuracy = 1.0
Epoch 3500/5000: Loss = 0.6547649820817112 | Training Accuracy = 1.0
Epoch 3550/5000: Loss = 0.6476618906563633 | Training Accuracy = 1.0
Epoch 3600/5000: Loss = 0.6406813185618502 | Training Accuracy = 1.0
Epoch 3650/5000: Loss = 0.6338203582818351 | Training Accuracy = 1.0
Epoch 3700/5000: Loss = 0.62707619577748 | Training Accuracy = 1.0
Epoch 3750/5000: Loss = 0.6204461065619331 | Training Accuracy = 1.0
Epoch 3800/5000: Loss = 0.613927451973544 | Training Accuracy = 1.0
Epoch 3850/5000: Loss = 0.6075176756363615 | Training Accuracy = 1.0
Epoch 3900/5000: Loss = 0.6012143000972181 | Training Accuracy = 1.0
Epoch 3950/5000: Loss = 0.5950149236294051 | Training Accuracy = 1.0
Epoch 4000/5000: Loss = 0.5889172171935882 | Training Accuracy = 1.0
Epoch 4050/5000: Loss = 0.5829189215472004 | Training Accuracy = 1.0
Epoch 4100/5000: Loss = 0.5770178444941011 | Training Accuracy = 1.0
Epoch 4150/5000: Loss = 0.5712118582668013 | Training Accuracy = 1.0
Epoch 4200/5000: Loss = 0.5654988970340131 | Training Accuracy = 1.0
Epoch 4250/5000: Loss = 0.5598769545267331 | Training Accuracy = 1.0
Epoch 4300/5000: Loss = 0.5543440817764675 | Training Accuracy = 1.0
Epoch 4350/5000: Loss = 0.5488983849595841 | Training Accuracy = 1.0
Epoch 4400/5000: Loss = 0.5435380233421363 | Training Accuracy = 1.0
Epoch 4450/5000: Loss = 0.538261207319821 | Training Accuracy = 1.0
Epoch 4500/5000: Loss = 0.5330661965480605 | Training Accuracy = 1.0
Epoch 4550/5000: Loss = 0.5279512981574574 | Training Accuracy = 1.0
Epoch 4600/5000: Loss = 0.5229148650501726 | Training Accuracy = 1.0
Epoch 4650/5000: Loss = 0.5179552942730058 | Training Accuracy = 1.0
Epoch 4700/5000: Loss = 0.513071025463205 | Training Accuracy = 1.0
Epoch 4750/5000: Loss = 0.5082605393632545 | Training Accuracy = 1.0
Epoch 4800/5000: Loss = 0.5035223564010968 | Training Accuracy = 1.0
Epoch 4850/5000: Loss = 0.49885503533244346 | Training Accuracy = 1.0
Epoch 4900/5000: Loss = 0.4942571719420129 | Training Accuracy = 1.0
Epoch 4950/5000: Loss = 0.4897273978007071 | Training Accuracy = 1.0
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[25]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.1381111111111111</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Loading-the-original-dataset-again">Loading the original dataset again<a class="anchor-link" href="#Loading-the-original-dataset-again">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">h5_SVH</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s1">&#39;SVHN_single_grey1.h5&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="c1"># Load the training, validation and test sets</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;X_train&#39;</span><span class="p">][:]</span>
<span class="n">y_train_o</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;y_train&#39;</span><span class="p">][:]</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;X_val&#39;</span><span class="p">][:]</span>
<span class="n">y_val_o</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;y_val&#39;</span><span class="p">][:]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;X_test&#39;</span><span class="p">][:]</span>
<span class="n">y_test_o</span> <span class="o">=</span> <span class="n">h5_SVH</span><span class="p">[</span><span class="s1">&#39;y_test&#39;</span><span class="p">][:]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reshaping X data: (n, 32, 32) =&gt; (n, 1024)&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Making sure that the values are float so that we can get decimal points after division&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Normalizing the RGB codes by dividing it to the max RGB value&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">X_val</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">X_test</span> <span class="o">/=</span> <span class="mi">255</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Converting y data into categorical (one-hot encoding)&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train_o</span><span class="p">)</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_val_o</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test_o</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Reshaping X data: (n, 32, 32) =&gt; (n, 1024)
--------------------------------------------------------------------------------
Making sure that the values are float so that we can get decimal points after division
--------------------------------------------------------------------------------
Normalizing the RGB codes by dividing it to the max RGB value
--------------------------------------------------------------------------------
Converting y data into categorical (one-hot encoding)
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Start-with-small-regularization-and-find-learning-rate-that-makes-the-loss-go-down.">Start with small regularization and find learning rate that makes the loss go down.<a class="anchor-link" href="#Start-with-small-regularization-and-find-learning-rate-that-makes-the-loss-go-down.">&#182;</a></h4><ul>
<li>we start with Lambda(small regularization) = 1e-7</li>
<li>we start with a small learning rate = 1e-7</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-7</span>
<span class="n">Lambda</span> <span class="o">=</span> <span class="mf">1e-7</span>
<span class="n">train_and_test_loop</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 0/500: Loss = 2.317728157047642 | Training Accuracy = 0.104
Epoch 50/500: Loss = 2.3127425227478797 | Training Accuracy = 0.10471428571428572
Epoch 100/500: Loss = 2.3094828415428403 | Training Accuracy = 0.1055
Epoch 150/500: Loss = 2.307345836509397 | Training Accuracy = 0.10542857142857143
Epoch 200/500: Loss = 2.305942805671862 | Training Accuracy = 0.10428571428571429
Epoch 250/500: Loss = 2.3050204802732313 | Training Accuracy = 0.10395238095238095
Epoch 300/500: Loss = 2.3044129184583078 | Training Accuracy = 0.10254761904761905
Epoch 350/500: Loss = 2.3040111864235984 | Training Accuracy = 0.101
Epoch 400/500: Loss = 2.303743794017468 | Training Accuracy = 0.10019047619047619
Epoch 450/500: Loss = 2.3035638954300524 | Training Accuracy = 0.09911904761904762
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[27]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.09555555555555556</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Lets-try-to-train-now-with-a-value-of-learning-rate-0.001">Lets try to train now with a value of learning rate 0.001<a class="anchor-link" href="#Lets-try-to-train-now-with-a-value-of-learning-rate-0.001">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">Lambda</span> <span class="o">=</span> <span class="mf">1e-7</span>
<span class="n">train_and_test_loop</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 0/500: Loss = 2.3045206865294667 | Training Accuracy = 0.11473809523809524
Epoch 50/500: Loss = 2.259865884155515 | Training Accuracy = 0.20614285714285716
Epoch 100/500: Loss = 2.251416078728257 | Training Accuracy = 0.21633333333333332
Epoch 150/500: Loss = 2.2471058220607465 | Training Accuracy = 0.22138095238095237
Epoch 200/500: Loss = 2.2442164094973287 | Training Accuracy = 0.22454761904761905
Epoch 250/500: Loss = 2.2420426056295346 | Training Accuracy = 0.22678571428571428
Epoch 300/500: Loss = 2.240300552374621 | Training Accuracy = 0.22766666666666666
Epoch 350/500: Loss = 2.2388468080995563 | Training Accuracy = 0.22914285714285715
Epoch 400/500: Loss = 2.237598607772921 | Training Accuracy = 0.2300952380952381
Epoch 450/500: Loss = 2.2365039099696107 | Training Accuracy = 0.23076190476190475
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[28]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.21433333333333332</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Hyperparameter-Optimization">Hyperparameter Optimization<a class="anchor-link" href="#Hyperparameter-Optimization">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Running-a-finer-search">Running a finer search<a class="anchor-link" href="#Running-a-finer-search">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">))</span>
    <span class="n">Lambda</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="n">train_and_test_loop</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Try </span><span class="si">{0}</span><span class="s2">/</span><span class="si">{1}</span><span class="s2">: Best_val_acc: </span><span class="si">{2}</span><span class="s2">, lr: </span><span class="si">{3}</span><span class="s2">, Lambda: </span><span class="si">{4}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">best_acc</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Try 1/10: Best_val_acc: 0.18288888888888888, lr: 0.005248163657617819, Lambda: 64.48340786832672

Try 2/10: Best_val_acc: 0.2053888888888889, lr: 0.006679712019881258, Lambda: 0.3646857771377305

Try 3/10: Best_val_acc: 0.18827777777777777, lr: 0.0046008725625766725, Lambda: 0.03253300599381195

Try 4/10: Best_val_acc: 0.19616666666666666, lr: 0.004120077105146745, Lambda: 13.396751846027179

Try 5/10: Best_val_acc: 0.18988888888888888, lr: 0.0015322728061813945, Lambda: 0.05780821685783054

Try 6/10: Best_val_acc: 0.2031111111111111, lr: 0.003223010681924104, Lambda: 19.57233858291238

Try 7/10: Best_val_acc: 0.18738888888888888, lr: 0.007976192792141505, Lambda: 0.0004221599617830911

Try 8/10: Best_val_acc: 0.19411111111111112, lr: 0.009793789314692974, Lambda: 1.7025515288536694

Try 9/10: Best_val_acc: 0.19827777777777778, lr: 0.0023285365617220083, Lambda: 5.1261156557902146

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Observation-2---Baby-sitting-the-neural-network-for-SVHN">Observation 2 - Baby sitting the neural network for SVHN<a class="anchor-link" href="#Observation-2---Baby-sitting-the-neural-network-for-SVHN">&#182;</a></h5><ul>
<li>Best accuracy achieved using this method after hyperparameter optimization: 21%.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='BasicNN'></a></p>
<h3 id="Modelling---Neural-Network-API">Modelling - Neural Network API<a class="anchor-link" href="#Modelling---Neural-Network-API">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-sigmoid-activations,-SGD-optimizer">NN model, sigmoid activations, SGD optimizer<a class="anchor-link" href="#NN-model,-sigmoid-activations,-SGD-optimizer">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with sigmoid activations&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Input Layer - adding input layer and activation functions sigmoid</span>
<span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">)))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model1</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with sigmoid activations
--------------------------------------------------------------------------------
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 128)               131200    
_________________________________________________________________
activation (Activation)      (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                8256      
_________________________________________________________________
activation_1 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                650       
_________________________________________________________________
activation_2 (Activation)    (None, 10)                0         
=================================================================
Total params: 140,106
Trainable params: 140,106
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">model1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 3s 64us/sample - loss: 2.3172 - acc: 0.1011 - val_loss: 2.3029 - val_acc: 0.1029
Epoch 2/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3030 - acc: 0.1024 - val_loss: 2.3030 - val_acc: 0.1024
Epoch 3/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3031 - acc: 0.0996 - val_loss: 2.3028 - val_acc: 0.0991
Epoch 4/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3030 - acc: 0.0988 - val_loss: 2.3028 - val_acc: 0.1019
Epoch 5/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3029 - acc: 0.0998 - val_loss: 2.3027 - val_acc: 0.1009
Epoch 6/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3028 - acc: 0.0989 - val_loss: 2.3029 - val_acc: 0.0998
Epoch 7/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3028 - acc: 0.1022 - val_loss: 2.3026 - val_acc: 0.1011
Epoch 8/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.3027 - acc: 0.1015 - val_loss: 2.3027 - val_acc: 0.0998
Epoch 9/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.3027 - acc: 0.1011 - val_loss: 2.3028 - val_acc: 0.1001
Epoch 10/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3027 - acc: 0.1016 - val_loss: 2.3026 - val_acc: 0.1012
Epoch 11/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3027 - acc: 0.1014 - val_loss: 2.3024 - val_acc: 0.1020
Epoch 12/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3026 - acc: 0.0993 - val_loss: 2.3024 - val_acc: 0.0998
Epoch 13/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3026 - acc: 0.1008 - val_loss: 2.3023 - val_acc: 0.1032
Epoch 14/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3025 - acc: 0.1026 - val_loss: 2.3023 - val_acc: 0.1045
Epoch 15/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3024 - acc: 0.1019 - val_loss: 2.3022 - val_acc: 0.1067
Epoch 16/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3024 - acc: 0.1028 - val_loss: 2.3022 - val_acc: 0.0962
Epoch 17/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3024 - acc: 0.1019 - val_loss: 2.3022 - val_acc: 0.1077
Epoch 18/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3023 - acc: 0.1036 - val_loss: 2.3021 - val_acc: 0.1125
Epoch 19/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3022 - acc: 0.1033 - val_loss: 2.3022 - val_acc: 0.1000
Epoch 20/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3023 - acc: 0.1028 - val_loss: 2.3021 - val_acc: 0.1013
Epoch 21/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3022 - acc: 0.1040 - val_loss: 2.3021 - val_acc: 0.1061
Epoch 22/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3021 - acc: 0.1048 - val_loss: 2.3020 - val_acc: 0.1111
Epoch 23/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3021 - acc: 0.1043 - val_loss: 2.3020 - val_acc: 0.1078
Epoch 24/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.3020 - acc: 0.1039 - val_loss: 2.3021 - val_acc: 0.1015
Epoch 25/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3021 - acc: 0.1037 - val_loss: 2.3019 - val_acc: 0.1015
Epoch 26/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3020 - acc: 0.1052 - val_loss: 2.3018 - val_acc: 0.1037
Epoch 27/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.3020 - acc: 0.1053 - val_loss: 2.3018 - val_acc: 0.1041
Epoch 28/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3019 - acc: 0.1047 - val_loss: 2.3018 - val_acc: 0.1081
Epoch 29/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3019 - acc: 0.1064 - val_loss: 2.3018 - val_acc: 0.1072
Epoch 30/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3019 - acc: 0.1028 - val_loss: 2.3018 - val_acc: 0.1039
Epoch 31/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.3018 - acc: 0.1055 - val_loss: 2.3017 - val_acc: 0.1143
Epoch 32/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3017 - acc: 0.1055 - val_loss: 2.3018 - val_acc: 0.1142
Epoch 33/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3016 - acc: 0.1061 - val_loss: 2.3018 - val_acc: 0.1019
Epoch 34/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.3018 - acc: 0.1057 - val_loss: 2.3015 - val_acc: 0.1066
Epoch 35/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3017 - acc: 0.1079 - val_loss: 2.3015 - val_acc: 0.1040
Epoch 36/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3017 - acc: 0.1078 - val_loss: 2.3015 - val_acc: 0.1039
Epoch 37/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1084 - val_loss: 2.3018 - val_acc: 0.1082
Epoch 38/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.3015 - acc: 0.1052 - val_loss: 2.3017 - val_acc: 0.0992
Epoch 39/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3014 - acc: 0.1075 - val_loss: 2.3017 - val_acc: 0.1029
Epoch 40/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3015 - acc: 0.1057 - val_loss: 2.3013 - val_acc: 0.1061
Epoch 41/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3014 - acc: 0.1077 - val_loss: 2.3015 - val_acc: 0.1013
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1063 - val_loss: 2.3013 - val_acc: 0.1096
Epoch 43/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1086 - val_loss: 2.3013 - val_acc: 0.1166
Epoch 44/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1085 - val_loss: 2.3012 - val_acc: 0.1049
Epoch 45/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3013 - acc: 0.1101 - val_loss: 2.3013 - val_acc: 0.1107
Epoch 46/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3013 - acc: 0.1059 - val_loss: 2.3012 - val_acc: 0.1158
Epoch 47/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.3012 - acc: 0.1110 - val_loss: 2.3012 - val_acc: 0.1061
Epoch 48/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3012 - acc: 0.1094 - val_loss: 2.3011 - val_acc: 0.1081
Epoch 49/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3012 - acc: 0.1083 - val_loss: 2.3013 - val_acc: 0.1005
Epoch 50/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3011 - acc: 0.1099 - val_loss: 2.3011 - val_acc: 0.1132
Epoch 51/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3010 - acc: 0.1121 - val_loss: 2.3013 - val_acc: 0.1023
Epoch 52/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3011 - acc: 0.1110 - val_loss: 2.3010 - val_acc: 0.1064
Epoch 53/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3011 - acc: 0.1106 - val_loss: 2.3009 - val_acc: 0.1101
Epoch 54/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3010 - acc: 0.1100 - val_loss: 2.3009 - val_acc: 0.1094
Epoch 55/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3009 - acc: 0.1097 - val_loss: 2.3009 - val_acc: 0.1133
Epoch 56/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3009 - acc: 0.1113 - val_loss: 2.3009 - val_acc: 0.1195
Epoch 57/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3009 - acc: 0.1130 - val_loss: 2.3008 - val_acc: 0.1099
Epoch 58/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3009 - acc: 0.1145 - val_loss: 2.3008 - val_acc: 0.1093
Epoch 59/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3009 - acc: 0.1117 - val_loss: 2.3008 - val_acc: 0.1138
Epoch 60/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3008 - acc: 0.1125 - val_loss: 2.3006 - val_acc: 0.1204
Epoch 61/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3008 - acc: 0.1122 - val_loss: 2.3007 - val_acc: 0.1053
Epoch 62/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3007 - acc: 0.1095 - val_loss: 2.3008 - val_acc: 0.1187
Epoch 63/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3007 - acc: 0.1140 - val_loss: 2.3007 - val_acc: 0.1177
Epoch 64/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.3007 - acc: 0.1117 - val_loss: 2.3005 - val_acc: 0.1193
Epoch 65/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3006 - acc: 0.1120 - val_loss: 2.3005 - val_acc: 0.1189
Epoch 66/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3006 - acc: 0.1135 - val_loss: 2.3005 - val_acc: 0.1089
Epoch 67/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3006 - acc: 0.1143 - val_loss: 2.3005 - val_acc: 0.1201
Epoch 68/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3004 - acc: 0.1117 - val_loss: 2.3005 - val_acc: 0.1099
Epoch 69/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3005 - acc: 0.1138 - val_loss: 2.3004 - val_acc: 0.1221
Epoch 70/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3004 - acc: 0.1152 - val_loss: 2.3004 - val_acc: 0.1177
Epoch 71/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3004 - acc: 0.1198 - val_loss: 2.3005 - val_acc: 0.1110
Epoch 72/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3004 - acc: 0.1152 - val_loss: 2.3003 - val_acc: 0.1209
Epoch 73/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3004 - acc: 0.1161 - val_loss: 2.3002 - val_acc: 0.1174
Epoch 74/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3003 - acc: 0.1162 - val_loss: 2.3002 - val_acc: 0.1155
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3002 - acc: 0.1153 - val_loss: 2.3002 - val_acc: 0.1095
Epoch 76/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3002 - acc: 0.1156 - val_loss: 2.3001 - val_acc: 0.1209
Epoch 77/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3002 - acc: 0.1168 - val_loss: 2.3001 - val_acc: 0.1187
Epoch 78/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3001 - acc: 0.1217 - val_loss: 2.3003 - val_acc: 0.1151
Epoch 79/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3001 - acc: 0.1150 - val_loss: 2.3000 - val_acc: 0.1183
Epoch 80/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3001 - acc: 0.1196 - val_loss: 2.3001 - val_acc: 0.1110
Epoch 81/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3001 - acc: 0.1145 - val_loss: 2.3000 - val_acc: 0.1260
Epoch 82/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.3000 - acc: 0.1196 - val_loss: 2.3001 - val_acc: 0.1094
Epoch 83/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.3000 - acc: 0.1144 - val_loss: 2.2999 - val_acc: 0.1208
Epoch 84/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2999 - acc: 0.1197 - val_loss: 2.2998 - val_acc: 0.1211
Epoch 85/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2999 - acc: 0.1178 - val_loss: 2.2998 - val_acc: 0.1247
Epoch 86/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2998 - acc: 0.1186 - val_loss: 2.2997 - val_acc: 0.1234
Epoch 87/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2998 - acc: 0.1185 - val_loss: 2.2998 - val_acc: 0.1148
Epoch 88/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2998 - acc: 0.1168 - val_loss: 2.2997 - val_acc: 0.1222
Epoch 89/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2998 - acc: 0.1189 - val_loss: 2.2997 - val_acc: 0.1289
Epoch 90/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2997 - acc: 0.1195 - val_loss: 2.2998 - val_acc: 0.1131
Epoch 91/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2997 - acc: 0.1196 - val_loss: 2.2997 - val_acc: 0.1146
Epoch 92/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2996 - acc: 0.1196 - val_loss: 2.2995 - val_acc: 0.1250
Epoch 93/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2996 - acc: 0.1202 - val_loss: 2.2995 - val_acc: 0.1207
Epoch 94/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2995 - acc: 0.1209 - val_loss: 2.2995 - val_acc: 0.1238
Epoch 95/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2995 - acc: 0.1215 - val_loss: 2.2995 - val_acc: 0.1158
Epoch 96/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2994 - acc: 0.1203 - val_loss: 2.2996 - val_acc: 0.1181
Epoch 97/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2994 - acc: 0.1227 - val_loss: 2.2995 - val_acc: 0.1090
Epoch 98/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2994 - acc: 0.1210 - val_loss: 2.2994 - val_acc: 0.1194
Epoch 99/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2994 - acc: 0.1224 - val_loss: 2.2993 - val_acc: 0.1255
Epoch 100/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2993 - acc: 0.1243 - val_loss: 2.2994 - val_acc: 0.1126
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with sigmoid activations&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with sigmoid activations
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 47us/sample - loss: 2.2994 - acc: 0.1126
Validation accuracy: 11.26
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-sigmoid-activations,-SGD-optimizer,-changing-learning-rate">NN model, sigmoid activations, SGD optimizer, changing learning rate<a class="anchor-link" href="#NN-model,-sigmoid-activations,-SGD-optimizer,-changing-learning-rate">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with sigmoid activations - changing learning rate&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">model1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with sigmoid activations - changing learning rate
--------------------------------------------------------------------------------
Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2991 - acc: 0.1169 - val_loss: 2.2993 - val_acc: 0.1169
Epoch 2/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1221 - val_loss: 2.2992 - val_acc: 0.1207
Epoch 3/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2990 - acc: 0.1222 - val_loss: 2.2992 - val_acc: 0.1231
Epoch 4/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1248 - val_loss: 2.2992 - val_acc: 0.1244
Epoch 5/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1266 - val_loss: 2.2992 - val_acc: 0.1257
Epoch 6/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1285 - val_loss: 2.2992 - val_acc: 0.1260
Epoch 7/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1264 - val_loss: 2.2991 - val_acc: 0.1277
Epoch 8/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1262 - val_loss: 2.2991 - val_acc: 0.1290
Epoch 9/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1290 - val_loss: 2.2991 - val_acc: 0.1291
Epoch 10/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1296 - val_loss: 2.2991 - val_acc: 0.1291
Epoch 11/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1286 - val_loss: 2.2991 - val_acc: 0.1295
Epoch 12/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1320 - val_loss: 2.2991 - val_acc: 0.1291
Epoch 13/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2989 - acc: 0.1301 - val_loss: 2.2991 - val_acc: 0.1289
Epoch 14/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1279 - val_loss: 2.2991 - val_acc: 0.1287
Epoch 15/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1305 - val_loss: 2.2991 - val_acc: 0.1286
Epoch 16/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2989 - acc: 0.1282 - val_loss: 2.2991 - val_acc: 0.1289
Epoch 17/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1305 - val_loss: 2.2991 - val_acc: 0.1286
Epoch 18/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1276 - val_loss: 2.2991 - val_acc: 0.1293
Epoch 19/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1284 - val_loss: 2.2991 - val_acc: 0.1300
Epoch 20/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2989 - acc: 0.1305 - val_loss: 2.2991 - val_acc: 0.1300
Epoch 21/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1314 - val_loss: 2.2991 - val_acc: 0.1294
Epoch 22/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1301 - val_loss: 2.2991 - val_acc: 0.1296
Epoch 23/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1304 - val_loss: 2.2991 - val_acc: 0.1293
Epoch 24/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1315 - val_loss: 2.2991 - val_acc: 0.1279
Epoch 25/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1285 - val_loss: 2.2991 - val_acc: 0.1289
Epoch 26/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1281 - val_loss: 2.2991 - val_acc: 0.1292
Epoch 27/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1303 - val_loss: 2.2991 - val_acc: 0.1293
Epoch 28/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1315 - val_loss: 2.2991 - val_acc: 0.1281
Epoch 29/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1288 - val_loss: 2.2991 - val_acc: 0.1285
Epoch 30/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2989 - acc: 0.1285 - val_loss: 2.2990 - val_acc: 0.1287
Epoch 31/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2989 - acc: 0.1293 - val_loss: 2.2990 - val_acc: 0.1290
Epoch 32/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1287 - val_loss: 2.2990 - val_acc: 0.1294
Epoch 33/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1316 - val_loss: 2.2990 - val_acc: 0.1288
Epoch 34/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1297 - val_loss: 2.2990 - val_acc: 0.1289
Epoch 35/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1300 - val_loss: 2.2990 - val_acc: 0.1294
Epoch 36/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2989 - acc: 0.1313 - val_loss: 2.2990 - val_acc: 0.1283
Epoch 37/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2988 - acc: 0.1293 - val_loss: 2.2990 - val_acc: 0.1284
Epoch 38/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2988 - acc: 0.1300 - val_loss: 2.2990 - val_acc: 0.1288
Epoch 39/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1285 - val_loss: 2.2990 - val_acc: 0.1293
Epoch 40/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1292 - val_loss: 2.2990 - val_acc: 0.1298
Epoch 41/100
42000/42000 [==============================] - 1s 29us/sample - loss: 2.2988 - acc: 0.1310 - val_loss: 2.2990 - val_acc: 0.1293
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1317 - val_loss: 2.2990 - val_acc: 0.1290
Epoch 43/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1301 - val_loss: 2.2990 - val_acc: 0.1291
Epoch 44/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1301 - val_loss: 2.2990 - val_acc: 0.1285
Epoch 45/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1310 - val_loss: 2.2990 - val_acc: 0.1288
Epoch 46/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1300 - val_loss: 2.2990 - val_acc: 0.1286
Epoch 47/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1310 - val_loss: 2.2990 - val_acc: 0.1283
Epoch 48/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1312 - val_loss: 2.2990 - val_acc: 0.1279
Epoch 49/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1260 - val_loss: 2.2990 - val_acc: 0.1295
Epoch 50/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1295 - val_loss: 2.2990 - val_acc: 0.1300
Epoch 51/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1297 - val_loss: 2.2990 - val_acc: 0.1302
Epoch 52/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2988 - acc: 0.1319 - val_loss: 2.2990 - val_acc: 0.1297
Epoch 53/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2988 - acc: 0.1313 - val_loss: 2.2990 - val_acc: 0.1287
Epoch 54/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1287 - val_loss: 2.2989 - val_acc: 0.1296
Epoch 55/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1314 - val_loss: 2.2989 - val_acc: 0.1295
Epoch 56/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1299 - val_loss: 2.2989 - val_acc: 0.1292
Epoch 57/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2988 - acc: 0.1321 - val_loss: 2.2989 - val_acc: 0.1289
Epoch 58/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1298 - val_loss: 2.2989 - val_acc: 0.1293
Epoch 59/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2988 - acc: 0.1293 - val_loss: 2.2989 - val_acc: 0.1301
Epoch 60/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1285 - val_loss: 2.2989 - val_acc: 0.1304
Epoch 61/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1317 - val_loss: 2.2989 - val_acc: 0.1305
Epoch 62/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1312 - val_loss: 2.2989 - val_acc: 0.1306
Epoch 63/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1307 - val_loss: 2.2989 - val_acc: 0.1302
Epoch 64/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1331 - val_loss: 2.2989 - val_acc: 0.1294
Epoch 65/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1318 - val_loss: 2.2989 - val_acc: 0.1296
Epoch 66/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1304 - val_loss: 2.2989 - val_acc: 0.1296
Epoch 67/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1306 - val_loss: 2.2989 - val_acc: 0.1300
Epoch 68/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1323 - val_loss: 2.2989 - val_acc: 0.1293
Epoch 69/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1300 - val_loss: 2.2989 - val_acc: 0.1298
Epoch 70/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2987 - acc: 0.1308 - val_loss: 2.2989 - val_acc: 0.1302
Epoch 71/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1307 - val_loss: 2.2989 - val_acc: 0.1304
Epoch 72/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1316 - val_loss: 2.2989 - val_acc: 0.1309
Epoch 73/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1319 - val_loss: 2.2989 - val_acc: 0.1301
Epoch 74/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1331 - val_loss: 2.2989 - val_acc: 0.1287
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1304 - val_loss: 2.2989 - val_acc: 0.1290
Epoch 76/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1294 - val_loss: 2.2989 - val_acc: 0.1298
Epoch 77/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1307 - val_loss: 2.2989 - val_acc: 0.1300
Epoch 78/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1292 - val_loss: 2.2989 - val_acc: 0.1303
Epoch 79/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1312 - val_loss: 2.2988 - val_acc: 0.1303
Epoch 80/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1324 - val_loss: 2.2988 - val_acc: 0.1301
Epoch 81/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1315 - val_loss: 2.2988 - val_acc: 0.1308
Epoch 82/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1318 - val_loss: 2.2988 - val_acc: 0.1305
Epoch 83/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1308 - val_loss: 2.2988 - val_acc: 0.1310
Epoch 84/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1311 - val_loss: 2.2988 - val_acc: 0.1316
Epoch 85/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1324 - val_loss: 2.2988 - val_acc: 0.1314
Epoch 86/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1318 - val_loss: 2.2988 - val_acc: 0.1308
Epoch 87/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1334 - val_loss: 2.2988 - val_acc: 0.1299
Epoch 88/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1312 - val_loss: 2.2988 - val_acc: 0.1305
Epoch 89/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1306 - val_loss: 2.2988 - val_acc: 0.1307
Epoch 90/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1332 - val_loss: 2.2988 - val_acc: 0.1297
Epoch 91/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1320 - val_loss: 2.2988 - val_acc: 0.1299
Epoch 92/100
42000/42000 [==============================] - 1s 29us/sample - loss: 2.2986 - acc: 0.1315 - val_loss: 2.2988 - val_acc: 0.1297
Epoch 93/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2986 - acc: 0.1313 - val_loss: 2.2988 - val_acc: 0.1295
Epoch 94/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1301 - val_loss: 2.2988 - val_acc: 0.1297
Epoch 95/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2986 - acc: 0.1307 - val_loss: 2.2988 - val_acc: 0.1302
Epoch 96/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1309 - val_loss: 2.2988 - val_acc: 0.1303
Epoch 97/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2986 - acc: 0.1324 - val_loss: 2.2988 - val_acc: 0.1299
Epoch 98/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1320 - val_loss: 2.2988 - val_acc: 0.1295
Epoch 99/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2986 - acc: 0.1299 - val_loss: 2.2988 - val_acc: 0.1310
Epoch 100/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1308 - val_loss: 2.2988 - val_acc: 0.1307
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with sigmoid activations - changing learning rate&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results1</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with sigmoid activations - changing learning rate
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 45us/sample - loss: 2.2988 - acc: 0.1307
Validation accuracy: 13.07
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o3'></a></p>
<h5 id="Observation-3---NN-model-with-sigmoid-activations">Observation 3 - NN model with sigmoid activations<a class="anchor-link" href="#Observation-3---NN-model-with-sigmoid-activations">&#182;</a></h5><ul>
<li>Validation score is very low, changing learning rate further reduces it.</li>
<li>Optimizing the network in order to better learn the patterns in the dataset.</li>
<li>Best model out of the above is the one with lower learning rate using SGD optimizer and sigmoid activations.</li>
<li>Next, let's use relu activations and see if the score improves.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-SGD-optimizer">NN model, relu activations, SGD optimizer<a class="anchor-link" href="#NN-model,-relu-activations,-SGD-optimizer">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with relu activations and sgd optimizers&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Input Layer - adding input layer and activation functions relu</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">)))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 2 µs, sys: 1 µs, total: 3 µs
Wall time: 6.68 µs
NN model with relu activations and sgd optimizers
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 128)               131200    
_________________________________________________________________
activation_3 (Activation)    (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 64)                8256      
_________________________________________________________________
activation_4 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 10)                650       
_________________________________________________________________
activation_5 (Activation)    (None, 10)                0         
=================================================================
Total params: 140,106
Trainable params: 140,106
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.3001 - acc: 0.1166 - val_loss: 2.2903 - val_acc: 0.1328
Epoch 2/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2854 - acc: 0.1465 - val_loss: 2.2786 - val_acc: 0.1673
Epoch 3/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2722 - acc: 0.1781 - val_loss: 2.2643 - val_acc: 0.1904
Epoch 4/100
42000/42000 [==============================] - 1s 25us/sample - loss: 2.2561 - acc: 0.2140 - val_loss: 2.2467 - val_acc: 0.2199
Epoch 5/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2369 - acc: 0.2507 - val_loss: 2.2263 - val_acc: 0.2579
Epoch 6/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.2128 - acc: 0.2883 - val_loss: 2.1973 - val_acc: 0.3150
Epoch 7/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.1828 - acc: 0.3158 - val_loss: 2.1645 - val_acc: 0.3450
Epoch 8/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.1463 - acc: 0.3465 - val_loss: 2.1254 - val_acc: 0.3584
Epoch 9/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.1025 - acc: 0.3752 - val_loss: 2.0772 - val_acc: 0.3822
Epoch 10/100
42000/42000 [==============================] - 1s 26us/sample - loss: 2.0490 - acc: 0.4008 - val_loss: 2.0188 - val_acc: 0.4164
Epoch 11/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.9873 - acc: 0.4255 - val_loss: 1.9517 - val_acc: 0.4352
Epoch 12/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.9183 - acc: 0.4470 - val_loss: 1.8801 - val_acc: 0.4531
Epoch 13/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.8455 - acc: 0.4674 - val_loss: 1.8076 - val_acc: 0.4808
Epoch 14/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.7732 - acc: 0.4886 - val_loss: 1.7343 - val_acc: 0.4963
Epoch 15/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.7041 - acc: 0.5085 - val_loss: 1.6676 - val_acc: 0.5157
Epoch 16/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.6407 - acc: 0.5236 - val_loss: 1.6103 - val_acc: 0.5370
Epoch 17/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.5833 - acc: 0.5417 - val_loss: 1.5525 - val_acc: 0.5501
Epoch 18/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.5326 - acc: 0.5534 - val_loss: 1.5026 - val_acc: 0.5629
Epoch 19/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.4851 - acc: 0.5659 - val_loss: 1.4584 - val_acc: 0.5728
Epoch 20/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.4431 - acc: 0.5756 - val_loss: 1.4193 - val_acc: 0.5908
Epoch 21/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.4061 - acc: 0.5859 - val_loss: 1.3822 - val_acc: 0.5966
Epoch 22/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.3737 - acc: 0.5931 - val_loss: 1.3552 - val_acc: 0.5914
Epoch 23/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.3442 - acc: 0.6000 - val_loss: 1.3209 - val_acc: 0.6088
Epoch 24/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.3146 - acc: 0.6076 - val_loss: 1.2990 - val_acc: 0.6103
Epoch 25/100
42000/42000 [==============================] - 1s 25us/sample - loss: 1.2933 - acc: 0.6137 - val_loss: 1.2714 - val_acc: 0.6263
Epoch 26/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.2681 - acc: 0.6206 - val_loss: 1.2635 - val_acc: 0.6183
Epoch 27/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.2485 - acc: 0.6246 - val_loss: 1.2253 - val_acc: 0.6389
Epoch 28/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.2259 - acc: 0.6333 - val_loss: 1.2039 - val_acc: 0.6449
Epoch 29/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.2094 - acc: 0.6355 - val_loss: 1.1899 - val_acc: 0.6465
Epoch 30/100
42000/42000 [==============================] - 1s 25us/sample - loss: 1.1919 - acc: 0.6437 - val_loss: 1.1801 - val_acc: 0.6503
Epoch 31/100
42000/42000 [==============================] - 1s 25us/sample - loss: 1.1786 - acc: 0.6477 - val_loss: 1.1587 - val_acc: 0.6580
Epoch 32/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1616 - acc: 0.6523 - val_loss: 1.1568 - val_acc: 0.6514
Epoch 33/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1512 - acc: 0.6531 - val_loss: 1.1345 - val_acc: 0.6618
Epoch 34/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1352 - acc: 0.6613 - val_loss: 1.1188 - val_acc: 0.6700
Epoch 35/100
42000/42000 [==============================] - 1s 25us/sample - loss: 1.1242 - acc: 0.6632 - val_loss: 1.1040 - val_acc: 0.6727
Epoch 36/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1088 - acc: 0.6689 - val_loss: 1.0946 - val_acc: 0.6725
Epoch 37/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0974 - acc: 0.6719 - val_loss: 1.0941 - val_acc: 0.6751
Epoch 38/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0869 - acc: 0.6758 - val_loss: 1.0704 - val_acc: 0.6830
Epoch 39/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0775 - acc: 0.6783 - val_loss: 1.0789 - val_acc: 0.6772
Epoch 40/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0685 - acc: 0.6812 - val_loss: 1.0560 - val_acc: 0.6874
Epoch 41/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0565 - acc: 0.6835 - val_loss: 1.0430 - val_acc: 0.6918
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0457 - acc: 0.6873 - val_loss: 1.0934 - val_acc: 0.6640
Epoch 43/100
42000/42000 [==============================] - 1s 25us/sample - loss: 1.0348 - acc: 0.6916 - val_loss: 1.0173 - val_acc: 0.6985
Epoch 44/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0230 - acc: 0.6930 - val_loss: 1.0077 - val_acc: 0.7038
Epoch 45/100
42000/42000 [==============================] - 1s 25us/sample - loss: 1.0125 - acc: 0.6962 - val_loss: 0.9966 - val_acc: 0.7057
Epoch 46/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0083 - acc: 0.6993 - val_loss: 1.0228 - val_acc: 0.6914
Epoch 47/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9951 - acc: 0.7034 - val_loss: 1.0381 - val_acc: 0.6836
Epoch 48/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9866 - acc: 0.7040 - val_loss: 0.9950 - val_acc: 0.7046
Epoch 49/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.9829 - acc: 0.7075 - val_loss: 0.9727 - val_acc: 0.7103
Epoch 50/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9720 - acc: 0.7098 - val_loss: 0.9611 - val_acc: 0.7149
Epoch 51/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9621 - acc: 0.7136 - val_loss: 0.9521 - val_acc: 0.7190
Epoch 52/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9557 - acc: 0.7144 - val_loss: 0.9603 - val_acc: 0.7140
Epoch 53/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9464 - acc: 0.7175 - val_loss: 0.9550 - val_acc: 0.7157
Epoch 54/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.9408 - acc: 0.7178 - val_loss: 0.9284 - val_acc: 0.7271
Epoch 55/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9319 - acc: 0.7215 - val_loss: 0.9394 - val_acc: 0.7183
Epoch 56/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.9281 - acc: 0.7238 - val_loss: 0.9207 - val_acc: 0.7272
Epoch 57/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9127 - acc: 0.7280 - val_loss: 0.9036 - val_acc: 0.7338
Epoch 58/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.9087 - acc: 0.7296 - val_loss: 0.9100 - val_acc: 0.7281
Epoch 59/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9039 - acc: 0.7315 - val_loss: 0.9017 - val_acc: 0.7313
Epoch 60/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8953 - acc: 0.7330 - val_loss: 0.8901 - val_acc: 0.7363
Epoch 61/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8903 - acc: 0.7342 - val_loss: 0.9211 - val_acc: 0.7243
Epoch 62/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.8842 - acc: 0.7363 - val_loss: 0.8956 - val_acc: 0.7299
Epoch 63/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8779 - acc: 0.7378 - val_loss: 0.8624 - val_acc: 0.7475
Epoch 64/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.8720 - acc: 0.7404 - val_loss: 0.8584 - val_acc: 0.7469
Epoch 65/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.8632 - acc: 0.7435 - val_loss: 0.8876 - val_acc: 0.7364
Epoch 66/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8595 - acc: 0.7448 - val_loss: 0.8548 - val_acc: 0.7465
Epoch 67/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8490 - acc: 0.7484 - val_loss: 0.8642 - val_acc: 0.7442
Epoch 68/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8486 - acc: 0.7457 - val_loss: 0.8481 - val_acc: 0.7492
Epoch 69/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8393 - acc: 0.7504 - val_loss: 0.8327 - val_acc: 0.7544
Epoch 70/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8353 - acc: 0.7501 - val_loss: 0.8289 - val_acc: 0.7560
Epoch 71/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8261 - acc: 0.7539 - val_loss: 0.8208 - val_acc: 0.7594
Epoch 72/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8244 - acc: 0.7542 - val_loss: 0.8829 - val_acc: 0.7296
Epoch 73/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8219 - acc: 0.7559 - val_loss: 0.8300 - val_acc: 0.7531
Epoch 74/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8139 - acc: 0.7574 - val_loss: 0.8140 - val_acc: 0.7588
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8078 - acc: 0.7588 - val_loss: 0.8330 - val_acc: 0.7498
Epoch 76/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8063 - acc: 0.7593 - val_loss: 0.7989 - val_acc: 0.7649
Epoch 77/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8026 - acc: 0.7609 - val_loss: 0.8428 - val_acc: 0.7449
Epoch 78/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7969 - acc: 0.7625 - val_loss: 0.8424 - val_acc: 0.7461
Epoch 79/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7871 - acc: 0.7662 - val_loss: 0.8011 - val_acc: 0.7637
Epoch 80/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7874 - acc: 0.7667 - val_loss: 0.7827 - val_acc: 0.7681
Epoch 81/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7836 - acc: 0.7662 - val_loss: 0.7725 - val_acc: 0.7734
Epoch 82/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7790 - acc: 0.7682 - val_loss: 0.7892 - val_acc: 0.7655
Epoch 83/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7736 - acc: 0.7713 - val_loss: 0.7670 - val_acc: 0.7764
Epoch 84/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.7643 - acc: 0.7731 - val_loss: 0.7617 - val_acc: 0.7786
Epoch 85/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7653 - acc: 0.7727 - val_loss: 0.7642 - val_acc: 0.7736
Epoch 86/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7625 - acc: 0.7740 - val_loss: 0.7830 - val_acc: 0.7649
Epoch 87/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7564 - acc: 0.7759 - val_loss: 0.7579 - val_acc: 0.7788
Epoch 88/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7540 - acc: 0.7751 - val_loss: 0.7516 - val_acc: 0.7801
Epoch 89/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7418 - acc: 0.7804 - val_loss: 0.7488 - val_acc: 0.7813
Epoch 90/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7452 - acc: 0.7795 - val_loss: 0.7650 - val_acc: 0.7742
Epoch 91/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7419 - acc: 0.7801 - val_loss: 0.7780 - val_acc: 0.7645
Epoch 92/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7399 - acc: 0.7804 - val_loss: 0.7546 - val_acc: 0.7770
Epoch 93/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7336 - acc: 0.7807 - val_loss: 0.7553 - val_acc: 0.7751
Epoch 94/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7345 - acc: 0.7808 - val_loss: 0.7326 - val_acc: 0.7833
Epoch 95/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7269 - acc: 0.7834 - val_loss: 0.7250 - val_acc: 0.7897
Epoch 96/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7175 - acc: 0.7872 - val_loss: 0.7265 - val_acc: 0.7863
Epoch 97/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.7217 - acc: 0.7840 - val_loss: 0.7476 - val_acc: 0.7760
Epoch 98/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7156 - acc: 0.7873 - val_loss: 0.7110 - val_acc: 0.7939
Epoch 99/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7118 - acc: 0.7906 - val_loss: 0.7762 - val_acc: 0.7646
Epoch 100/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.7070 - acc: 0.7895 - val_loss: 0.7015 - val_acc: 0.7965
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with relu activations&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with relu activations
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 48us/sample - loss: 0.7015 - acc: 0.7965
Validation accuracy: 79.65
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-SGD-optimizer,-changing-learning-rate">NN model, relu activations, SGD optimizer, changing learning rate<a class="anchor-link" href="#NN-model,-relu-activations,-SGD-optimizer,-changing-learning-rate">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with relu activations and sgd optimizers - changing learning rate&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs
Wall time: 15.5 µs
NN model with relu activations and sgd optimizers - changing learning rate
--------------------------------------------------------------------------------
Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6704 - acc: 0.8051 - val_loss: 0.6922 - val_acc: 0.8003
Epoch 2/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6680 - acc: 0.8054 - val_loss: 0.6917 - val_acc: 0.7996
Epoch 3/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6679 - acc: 0.8055 - val_loss: 0.6901 - val_acc: 0.8005
Epoch 4/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6671 - acc: 0.8058 - val_loss: 0.6899 - val_acc: 0.7997
Epoch 5/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6665 - acc: 0.8065 - val_loss: 0.6900 - val_acc: 0.8002
Epoch 6/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6665 - acc: 0.8061 - val_loss: 0.6891 - val_acc: 0.8007
Epoch 7/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6659 - acc: 0.8061 - val_loss: 0.6901 - val_acc: 0.8005
Epoch 8/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6655 - acc: 0.8067 - val_loss: 0.6885 - val_acc: 0.8010
Epoch 9/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6651 - acc: 0.8063 - val_loss: 0.6880 - val_acc: 0.8008
Epoch 10/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6648 - acc: 0.8069 - val_loss: 0.6878 - val_acc: 0.8016
Epoch 11/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6643 - acc: 0.8066 - val_loss: 0.6878 - val_acc: 0.8010
Epoch 12/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6637 - acc: 0.8069 - val_loss: 0.6871 - val_acc: 0.8013
Epoch 13/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6638 - acc: 0.8066 - val_loss: 0.6866 - val_acc: 0.8017
Epoch 14/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6632 - acc: 0.8067 - val_loss: 0.6865 - val_acc: 0.8019
Epoch 15/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6627 - acc: 0.8073 - val_loss: 0.6869 - val_acc: 0.8012
Epoch 16/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6625 - acc: 0.8076 - val_loss: 0.6858 - val_acc: 0.8022
Epoch 17/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6623 - acc: 0.8075 - val_loss: 0.6851 - val_acc: 0.8023
Epoch 18/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6619 - acc: 0.8079 - val_loss: 0.6852 - val_acc: 0.8011
Epoch 19/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6611 - acc: 0.8081 - val_loss: 0.6861 - val_acc: 0.8014
Epoch 20/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6610 - acc: 0.8076 - val_loss: 0.6847 - val_acc: 0.8024
Epoch 21/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6606 - acc: 0.8094 - val_loss: 0.6845 - val_acc: 0.8022
Epoch 22/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6603 - acc: 0.8082 - val_loss: 0.6841 - val_acc: 0.8021
Epoch 23/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6602 - acc: 0.8080 - val_loss: 0.6833 - val_acc: 0.8022
Epoch 24/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6594 - acc: 0.8084 - val_loss: 0.6835 - val_acc: 0.8027
Epoch 25/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6592 - acc: 0.8084 - val_loss: 0.6834 - val_acc: 0.8022
Epoch 26/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6587 - acc: 0.8086 - val_loss: 0.6830 - val_acc: 0.8022
Epoch 27/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6585 - acc: 0.8086 - val_loss: 0.6827 - val_acc: 0.8020
Epoch 28/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6582 - acc: 0.8083 - val_loss: 0.6815 - val_acc: 0.8029
Epoch 29/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6578 - acc: 0.8085 - val_loss: 0.6820 - val_acc: 0.8035
Epoch 30/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6573 - acc: 0.8087 - val_loss: 0.6811 - val_acc: 0.8037
Epoch 31/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6568 - acc: 0.8087 - val_loss: 0.6810 - val_acc: 0.8034
Epoch 32/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6568 - acc: 0.8094 - val_loss: 0.6814 - val_acc: 0.8037
Epoch 33/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6561 - acc: 0.8095 - val_loss: 0.6820 - val_acc: 0.8025
Epoch 34/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6561 - acc: 0.8091 - val_loss: 0.6800 - val_acc: 0.8039
Epoch 35/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6556 - acc: 0.8095 - val_loss: 0.6815 - val_acc: 0.8023
Epoch 36/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6553 - acc: 0.8102 - val_loss: 0.6793 - val_acc: 0.8039
Epoch 37/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6552 - acc: 0.8091 - val_loss: 0.6786 - val_acc: 0.8048
Epoch 38/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6545 - acc: 0.8091 - val_loss: 0.6787 - val_acc: 0.8039
Epoch 39/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6544 - acc: 0.8102 - val_loss: 0.6791 - val_acc: 0.8040
Epoch 40/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6538 - acc: 0.8104 - val_loss: 0.6795 - val_acc: 0.8035
Epoch 41/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6536 - acc: 0.8103 - val_loss: 0.6788 - val_acc: 0.8041
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6531 - acc: 0.8098 - val_loss: 0.6793 - val_acc: 0.8042
Epoch 43/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6528 - acc: 0.8108 - val_loss: 0.6783 - val_acc: 0.8041
Epoch 44/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6525 - acc: 0.8099 - val_loss: 0.6770 - val_acc: 0.8048
Epoch 45/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6522 - acc: 0.8120 - val_loss: 0.6772 - val_acc: 0.8040
Epoch 46/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6518 - acc: 0.8104 - val_loss: 0.6773 - val_acc: 0.8048
Epoch 47/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6514 - acc: 0.8103 - val_loss: 0.6762 - val_acc: 0.8050
Epoch 48/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6512 - acc: 0.8111 - val_loss: 0.6762 - val_acc: 0.8047
Epoch 49/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6509 - acc: 0.8113 - val_loss: 0.6750 - val_acc: 0.8047
Epoch 50/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6503 - acc: 0.8108 - val_loss: 0.6763 - val_acc: 0.8041
Epoch 51/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6502 - acc: 0.8111 - val_loss: 0.6752 - val_acc: 0.8049
Epoch 52/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6497 - acc: 0.8110 - val_loss: 0.6747 - val_acc: 0.8061
Epoch 53/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6495 - acc: 0.8118 - val_loss: 0.6739 - val_acc: 0.8058
Epoch 54/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6493 - acc: 0.8111 - val_loss: 0.6742 - val_acc: 0.8049
Epoch 55/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6491 - acc: 0.8117 - val_loss: 0.6735 - val_acc: 0.8054
Epoch 56/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6483 - acc: 0.8115 - val_loss: 0.6735 - val_acc: 0.8059
Epoch 57/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6482 - acc: 0.8117 - val_loss: 0.6736 - val_acc: 0.8061
Epoch 58/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6479 - acc: 0.8123 - val_loss: 0.6735 - val_acc: 0.8053
Epoch 59/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6475 - acc: 0.8125 - val_loss: 0.6731 - val_acc: 0.8060
Epoch 60/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6472 - acc: 0.8123 - val_loss: 0.6724 - val_acc: 0.8061
Epoch 61/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6469 - acc: 0.8119 - val_loss: 0.6721 - val_acc: 0.8064
Epoch 62/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6465 - acc: 0.8119 - val_loss: 0.6723 - val_acc: 0.8060
Epoch 63/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6463 - acc: 0.8126 - val_loss: 0.6713 - val_acc: 0.8056
Epoch 64/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6460 - acc: 0.8130 - val_loss: 0.6707 - val_acc: 0.8064
Epoch 65/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6454 - acc: 0.8123 - val_loss: 0.6711 - val_acc: 0.8061
Epoch 66/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6453 - acc: 0.8136 - val_loss: 0.6703 - val_acc: 0.8069
Epoch 67/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6449 - acc: 0.8130 - val_loss: 0.6699 - val_acc: 0.8062
Epoch 68/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6446 - acc: 0.8127 - val_loss: 0.6698 - val_acc: 0.8075
Epoch 69/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6442 - acc: 0.8132 - val_loss: 0.6693 - val_acc: 0.8071
Epoch 70/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6437 - acc: 0.8129 - val_loss: 0.6696 - val_acc: 0.8058
Epoch 71/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6437 - acc: 0.8131 - val_loss: 0.6694 - val_acc: 0.8057
Epoch 72/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6433 - acc: 0.8131 - val_loss: 0.6692 - val_acc: 0.8067
Epoch 73/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6430 - acc: 0.8137 - val_loss: 0.6687 - val_acc: 0.8073
Epoch 74/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6428 - acc: 0.8131 - val_loss: 0.6690 - val_acc: 0.8073
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6425 - acc: 0.8139 - val_loss: 0.6676 - val_acc: 0.8073
Epoch 76/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6419 - acc: 0.8140 - val_loss: 0.6672 - val_acc: 0.8077
Epoch 77/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6418 - acc: 0.8141 - val_loss: 0.6672 - val_acc: 0.8074
Epoch 78/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6415 - acc: 0.8141 - val_loss: 0.6676 - val_acc: 0.8061
Epoch 79/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6411 - acc: 0.8145 - val_loss: 0.6669 - val_acc: 0.8072
Epoch 80/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6409 - acc: 0.8139 - val_loss: 0.6685 - val_acc: 0.8061
Epoch 81/100
42000/42000 [==============================] - 1s 25us/sample - loss: 0.6408 - acc: 0.8138 - val_loss: 0.6668 - val_acc: 0.8075
Epoch 82/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6404 - acc: 0.8141 - val_loss: 0.6655 - val_acc: 0.8078
Epoch 83/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6398 - acc: 0.8137 - val_loss: 0.6651 - val_acc: 0.8077
Epoch 84/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6394 - acc: 0.8151 - val_loss: 0.6666 - val_acc: 0.8076
Epoch 85/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6395 - acc: 0.8140 - val_loss: 0.6655 - val_acc: 0.8083
Epoch 86/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6392 - acc: 0.8147 - val_loss: 0.6653 - val_acc: 0.8075
Epoch 87/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6387 - acc: 0.8147 - val_loss: 0.6643 - val_acc: 0.8076
Epoch 88/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6384 - acc: 0.8151 - val_loss: 0.6646 - val_acc: 0.8078
Epoch 89/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6380 - acc: 0.8145 - val_loss: 0.6636 - val_acc: 0.8078
Epoch 90/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6375 - acc: 0.8148 - val_loss: 0.6638 - val_acc: 0.8083
Epoch 91/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6376 - acc: 0.8157 - val_loss: 0.6637 - val_acc: 0.8088
Epoch 92/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6370 - acc: 0.8152 - val_loss: 0.6632 - val_acc: 0.8087
Epoch 93/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6367 - acc: 0.8152 - val_loss: 0.6636 - val_acc: 0.8081
Epoch 94/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6367 - acc: 0.8140 - val_loss: 0.6623 - val_acc: 0.8089
Epoch 95/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6362 - acc: 0.8158 - val_loss: 0.6631 - val_acc: 0.8092
Epoch 96/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6358 - acc: 0.8150 - val_loss: 0.6630 - val_acc: 0.8080
Epoch 97/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6358 - acc: 0.8151 - val_loss: 0.6615 - val_acc: 0.8091
Epoch 98/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6353 - acc: 0.8160 - val_loss: 0.6622 - val_acc: 0.8086
Epoch 99/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6350 - acc: 0.8152 - val_loss: 0.6614 - val_acc: 0.8087
Epoch 100/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6348 - acc: 0.8156 - val_loss: 0.6611 - val_acc: 0.8088
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with relu activations&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with relu activations
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 51us/sample - loss: 0.6611 - acc: 0.8088
Validation accuracy: 80.88
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-adam-optimizer">NN model, relu activations, adam optimizer<a class="anchor-link" href="#NN-model,-relu-activations,-adam-optimizer">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with relu activations and adam optimizer&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 2 µs, sys: 0 ns, total: 2 µs
Wall time: 5.01 µs
NN model with relu activations and adam optimizer
--------------------------------------------------------------------------------
Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 34us/sample - loss: 3.3943 - acc: 0.1031 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 2/100
42000/42000 [==============================] - 1s 30us/sample - loss: 2.3013 - acc: 0.1004 - val_loss: 2.3027 - val_acc: 0.1014
Epoch 3/100
42000/42000 [==============================] - 1s 29us/sample - loss: 2.2895 - acc: 0.1191 - val_loss: 2.2743 - val_acc: 0.1331
Epoch 4/100
42000/42000 [==============================] - 1s 31us/sample - loss: 2.2683 - acc: 0.1293 - val_loss: 2.2518 - val_acc: 0.1432
Epoch 5/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.1576 - acc: 0.1853 - val_loss: 2.0355 - val_acc: 0.2498
Epoch 6/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.8345 - acc: 0.3417 - val_loss: 1.6677 - val_acc: 0.4254
Epoch 7/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.5568 - acc: 0.4742 - val_loss: 1.4540 - val_acc: 0.5070
Epoch 8/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.3969 - acc: 0.5453 - val_loss: 1.4334 - val_acc: 0.5188
Epoch 9/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.3505 - acc: 0.5663 - val_loss: 1.3200 - val_acc: 0.5760
Epoch 10/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2855 - acc: 0.5901 - val_loss: 1.2031 - val_acc: 0.6226
Epoch 11/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2371 - acc: 0.6069 - val_loss: 1.2411 - val_acc: 0.6005
Epoch 12/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2108 - acc: 0.6166 - val_loss: 1.2598 - val_acc: 0.5979
Epoch 13/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2105 - acc: 0.6179 - val_loss: 1.2068 - val_acc: 0.6124
Epoch 14/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1587 - acc: 0.6356 - val_loss: 1.1786 - val_acc: 0.6265
Epoch 15/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1466 - acc: 0.6399 - val_loss: 1.0966 - val_acc: 0.6581
Epoch 16/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.1529 - acc: 0.6390 - val_loss: 1.2340 - val_acc: 0.6092
Epoch 17/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1638 - acc: 0.6342 - val_loss: 1.1474 - val_acc: 0.6446
Epoch 18/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1361 - acc: 0.6437 - val_loss: 1.1375 - val_acc: 0.6424
Epoch 19/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1319 - acc: 0.6441 - val_loss: 1.1487 - val_acc: 0.6376
Epoch 20/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1126 - acc: 0.6519 - val_loss: 1.0731 - val_acc: 0.6636
Epoch 21/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1100 - acc: 0.6529 - val_loss: 1.1204 - val_acc: 0.6526
Epoch 22/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1103 - acc: 0.6528 - val_loss: 1.1775 - val_acc: 0.6292
Epoch 23/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1069 - acc: 0.6525 - val_loss: 1.0985 - val_acc: 0.6520
Epoch 24/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0999 - acc: 0.6546 - val_loss: 1.0967 - val_acc: 0.6591
Epoch 25/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0973 - acc: 0.6555 - val_loss: 1.0405 - val_acc: 0.6792
Epoch 26/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1014 - acc: 0.6541 - val_loss: 1.1677 - val_acc: 0.6265
Epoch 27/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0893 - acc: 0.6584 - val_loss: 1.0540 - val_acc: 0.6711
Epoch 28/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0889 - acc: 0.6568 - val_loss: 1.0725 - val_acc: 0.6622
Epoch 29/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0825 - acc: 0.6615 - val_loss: 1.1438 - val_acc: 0.6394
Epoch 30/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0843 - acc: 0.6596 - val_loss: 1.0277 - val_acc: 0.6816
Epoch 31/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0669 - acc: 0.6661 - val_loss: 1.0409 - val_acc: 0.6762
Epoch 32/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0803 - acc: 0.6599 - val_loss: 1.0849 - val_acc: 0.6575
Epoch 33/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0737 - acc: 0.6627 - val_loss: 1.1215 - val_acc: 0.6391
Epoch 34/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0673 - acc: 0.6649 - val_loss: 1.0624 - val_acc: 0.6672
Epoch 35/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0648 - acc: 0.6656 - val_loss: 1.0486 - val_acc: 0.6743
Epoch 36/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0647 - acc: 0.6647 - val_loss: 1.0660 - val_acc: 0.6658
Epoch 37/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0650 - acc: 0.6636 - val_loss: 1.0980 - val_acc: 0.6513
Epoch 38/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0624 - acc: 0.6673 - val_loss: 1.0543 - val_acc: 0.6686
Epoch 39/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0690 - acc: 0.6653 - val_loss: 1.0335 - val_acc: 0.6793
Epoch 40/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0487 - acc: 0.6729 - val_loss: 1.0449 - val_acc: 0.6762
Epoch 41/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0556 - acc: 0.6700 - val_loss: 1.0483 - val_acc: 0.6722
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0526 - acc: 0.6711 - val_loss: 1.0227 - val_acc: 0.6811
Epoch 43/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0472 - acc: 0.6733 - val_loss: 1.0363 - val_acc: 0.6783
Epoch 44/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0532 - acc: 0.6717 - val_loss: 1.0223 - val_acc: 0.6808
Epoch 45/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0416 - acc: 0.6732 - val_loss: 1.0771 - val_acc: 0.6583
Epoch 46/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0372 - acc: 0.6736 - val_loss: 1.0675 - val_acc: 0.6671
Epoch 47/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0606 - acc: 0.6655 - val_loss: 1.0282 - val_acc: 0.6787
Epoch 48/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0661 - acc: 0.6638 - val_loss: 1.0242 - val_acc: 0.6798
Epoch 49/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0452 - acc: 0.6718 - val_loss: 1.0708 - val_acc: 0.6636
Epoch 50/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0386 - acc: 0.6764 - val_loss: 1.0317 - val_acc: 0.6770
Epoch 51/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0393 - acc: 0.6755 - val_loss: 1.0551 - val_acc: 0.6654
Epoch 52/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0469 - acc: 0.6717 - val_loss: 1.0547 - val_acc: 0.6689
Epoch 53/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0485 - acc: 0.6729 - val_loss: 1.0864 - val_acc: 0.6599
Epoch 54/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0401 - acc: 0.6743 - val_loss: 0.9906 - val_acc: 0.6897
Epoch 55/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0368 - acc: 0.6735 - val_loss: 1.0132 - val_acc: 0.6853
Epoch 56/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0445 - acc: 0.6722 - val_loss: 1.0171 - val_acc: 0.6813
Epoch 57/100
42000/42000 [==============================] - 1s 30us/sample - loss: 1.0387 - acc: 0.6763 - val_loss: 1.0498 - val_acc: 0.6689
Epoch 58/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0460 - acc: 0.6731 - val_loss: 1.0686 - val_acc: 0.6675
Epoch 59/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0375 - acc: 0.6751 - val_loss: 1.0465 - val_acc: 0.6723
Epoch 60/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0389 - acc: 0.6742 - val_loss: 1.0595 - val_acc: 0.6651
Epoch 61/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0250 - acc: 0.6791 - val_loss: 1.0227 - val_acc: 0.6823
Epoch 62/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0342 - acc: 0.6758 - val_loss: 1.0227 - val_acc: 0.6824
Epoch 63/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0375 - acc: 0.6764 - val_loss: 1.0060 - val_acc: 0.6898
Epoch 64/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0230 - acc: 0.6793 - val_loss: 1.0115 - val_acc: 0.6835
Epoch 65/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0224 - acc: 0.6798 - val_loss: 1.0603 - val_acc: 0.6657
Epoch 66/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0352 - acc: 0.6760 - val_loss: 1.0281 - val_acc: 0.6746
Epoch 67/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0335 - acc: 0.6775 - val_loss: 0.9844 - val_acc: 0.6960
Epoch 68/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0224 - acc: 0.6811 - val_loss: 1.0320 - val_acc: 0.6740
Epoch 69/100
42000/42000 [==============================] - 1s 30us/sample - loss: 1.0351 - acc: 0.6750 - val_loss: 1.0805 - val_acc: 0.6631
Epoch 70/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0223 - acc: 0.6813 - val_loss: 1.0350 - val_acc: 0.6804
Epoch 71/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0255 - acc: 0.6781 - val_loss: 1.0166 - val_acc: 0.6827
Epoch 72/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0279 - acc: 0.6781 - val_loss: 1.0422 - val_acc: 0.6733
Epoch 73/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0341 - acc: 0.6777 - val_loss: 0.9790 - val_acc: 0.6986
Epoch 74/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0214 - acc: 0.6818 - val_loss: 1.0892 - val_acc: 0.6592
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0283 - acc: 0.6802 - val_loss: 1.0154 - val_acc: 0.6855
Epoch 76/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0244 - acc: 0.6779 - val_loss: 1.0062 - val_acc: 0.6894
Epoch 77/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0194 - acc: 0.6811 - val_loss: 1.0128 - val_acc: 0.6851
Epoch 78/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0110 - acc: 0.6831 - val_loss: 1.0117 - val_acc: 0.6898
Epoch 79/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0215 - acc: 0.6807 - val_loss: 1.0087 - val_acc: 0.6883
Epoch 80/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0231 - acc: 0.6806 - val_loss: 1.0040 - val_acc: 0.6889
Epoch 81/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0298 - acc: 0.6776 - val_loss: 1.0346 - val_acc: 0.6800
Epoch 82/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0202 - acc: 0.6811 - val_loss: 1.0856 - val_acc: 0.6620
Epoch 83/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0209 - acc: 0.6805 - val_loss: 0.9843 - val_acc: 0.6952
Epoch 84/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0093 - acc: 0.6862 - val_loss: 1.0686 - val_acc: 0.6638
Epoch 85/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0101 - acc: 0.6857 - val_loss: 0.9739 - val_acc: 0.6989
Epoch 86/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0075 - acc: 0.6861 - val_loss: 0.9899 - val_acc: 0.6946
Epoch 87/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0080 - acc: 0.6878 - val_loss: 1.0014 - val_acc: 0.6913
Epoch 88/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0107 - acc: 0.6852 - val_loss: 1.0051 - val_acc: 0.6876
Epoch 89/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0133 - acc: 0.6821 - val_loss: 1.0165 - val_acc: 0.6839
Epoch 90/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0023 - acc: 0.6889 - val_loss: 0.9863 - val_acc: 0.6931
Epoch 91/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0083 - acc: 0.6878 - val_loss: 0.9998 - val_acc: 0.6890
Epoch 92/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0092 - acc: 0.6862 - val_loss: 0.9811 - val_acc: 0.6973
Epoch 93/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0127 - acc: 0.6836 - val_loss: 1.0062 - val_acc: 0.6899
Epoch 94/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9985 - acc: 0.6901 - val_loss: 0.9626 - val_acc: 0.7035
Epoch 95/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9983 - acc: 0.6881 - val_loss: 0.9701 - val_acc: 0.7008
Epoch 96/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9938 - acc: 0.6915 - val_loss: 0.9868 - val_acc: 0.6932
Epoch 97/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0051 - acc: 0.6875 - val_loss: 1.0199 - val_acc: 0.6880
Epoch 98/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0072 - acc: 0.6864 - val_loss: 0.9687 - val_acc: 0.7041
Epoch 99/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0078 - acc: 0.6880 - val_loss: 0.9660 - val_acc: 0.7028
Epoch 100/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9940 - acc: 0.6921 - val_loss: 1.0037 - val_acc: 0.6911
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with relu activations&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with relu activations
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 47us/sample - loss: 1.0037 - acc: 0.6911
Validation accuracy: 69.11
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-adam-optimizer,-changing-learning-rate">NN model, relu activations, adam optimizer, changing learning rate<a class="anchor-link" href="#NN-model,-relu-activations,-adam-optimizer,-changing-learning-rate">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with relu activations and adam optimizer&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs
Wall time: 4.77 µs
NN model with relu activations and adam optimizer
--------------------------------------------------------------------------------
Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.9207 - acc: 0.7166 - val_loss: 0.9223 - val_acc: 0.7184
Epoch 2/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9098 - acc: 0.7203 - val_loss: 0.9175 - val_acc: 0.7193
Epoch 3/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9100 - acc: 0.7193 - val_loss: 0.9187 - val_acc: 0.7174
Epoch 4/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.9088 - acc: 0.7202 - val_loss: 0.9171 - val_acc: 0.7187
Epoch 5/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9080 - acc: 0.7191 - val_loss: 0.9185 - val_acc: 0.7184
Epoch 6/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9064 - acc: 0.7220 - val_loss: 0.9181 - val_acc: 0.7187
Epoch 7/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.9074 - acc: 0.7217 - val_loss: 0.9131 - val_acc: 0.7214
Epoch 8/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9038 - acc: 0.7233 - val_loss: 0.9160 - val_acc: 0.7208
Epoch 9/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9038 - acc: 0.7221 - val_loss: 0.9150 - val_acc: 0.7202
Epoch 10/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9043 - acc: 0.7222 - val_loss: 0.9147 - val_acc: 0.7218
Epoch 11/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9017 - acc: 0.7234 - val_loss: 0.9187 - val_acc: 0.7187
Epoch 12/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9026 - acc: 0.7225 - val_loss: 0.9187 - val_acc: 0.7187
Epoch 13/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9057 - acc: 0.7221 - val_loss: 0.9153 - val_acc: 0.7211
Epoch 14/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9016 - acc: 0.7229 - val_loss: 0.9116 - val_acc: 0.7207
Epoch 15/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9031 - acc: 0.7222 - val_loss: 0.9213 - val_acc: 0.7177
Epoch 16/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9001 - acc: 0.7229 - val_loss: 0.9053 - val_acc: 0.7233
Epoch 17/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9013 - acc: 0.7225 - val_loss: 0.9189 - val_acc: 0.7166
Epoch 18/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8989 - acc: 0.7245 - val_loss: 0.9059 - val_acc: 0.7229
Epoch 19/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.9003 - acc: 0.7237 - val_loss: 0.9150 - val_acc: 0.7199
Epoch 20/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9003 - acc: 0.7231 - val_loss: 0.9091 - val_acc: 0.7216
Epoch 21/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8980 - acc: 0.7254 - val_loss: 0.9098 - val_acc: 0.7218
Epoch 22/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8977 - acc: 0.7244 - val_loss: 0.9094 - val_acc: 0.7217
Epoch 23/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8987 - acc: 0.7237 - val_loss: 0.9145 - val_acc: 0.7200
Epoch 24/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8967 - acc: 0.7244 - val_loss: 0.9107 - val_acc: 0.7208
Epoch 25/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8976 - acc: 0.7246 - val_loss: 0.9145 - val_acc: 0.7199
Epoch 26/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8976 - acc: 0.7237 - val_loss: 0.9047 - val_acc: 0.7238
Epoch 27/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8966 - acc: 0.7230 - val_loss: 0.9074 - val_acc: 0.7229
Epoch 28/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8947 - acc: 0.7263 - val_loss: 0.9040 - val_acc: 0.7226
Epoch 29/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8959 - acc: 0.7252 - val_loss: 0.9215 - val_acc: 0.7157
Epoch 30/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8937 - acc: 0.7264 - val_loss: 0.9097 - val_acc: 0.7207
Epoch 31/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8959 - acc: 0.7242 - val_loss: 0.9120 - val_acc: 0.7211
Epoch 32/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8944 - acc: 0.7248 - val_loss: 0.9027 - val_acc: 0.7243
Epoch 33/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8942 - acc: 0.7254 - val_loss: 0.9032 - val_acc: 0.7250
Epoch 34/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8928 - acc: 0.7254 - val_loss: 0.9032 - val_acc: 0.7240
Epoch 35/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8926 - acc: 0.7265 - val_loss: 0.9091 - val_acc: 0.7202
Epoch 36/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8949 - acc: 0.7246 - val_loss: 0.9041 - val_acc: 0.7226
Epoch 37/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8940 - acc: 0.7237 - val_loss: 0.9028 - val_acc: 0.7241
Epoch 38/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8925 - acc: 0.7257 - val_loss: 0.9063 - val_acc: 0.7229
Epoch 39/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8917 - acc: 0.7259 - val_loss: 0.9024 - val_acc: 0.7245
Epoch 40/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8943 - acc: 0.7253 - val_loss: 0.9051 - val_acc: 0.7239
Epoch 41/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8918 - acc: 0.7263 - val_loss: 0.9123 - val_acc: 0.7199
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8918 - acc: 0.7262 - val_loss: 0.9091 - val_acc: 0.7220
Epoch 43/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8912 - acc: 0.7266 - val_loss: 0.9088 - val_acc: 0.7209
Epoch 44/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8900 - acc: 0.7281 - val_loss: 0.9084 - val_acc: 0.7224
Epoch 45/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8904 - acc: 0.7269 - val_loss: 0.9066 - val_acc: 0.7211
Epoch 46/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8903 - acc: 0.7260 - val_loss: 0.9017 - val_acc: 0.7251
Epoch 47/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8908 - acc: 0.7267 - val_loss: 0.9037 - val_acc: 0.7225
Epoch 48/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8892 - acc: 0.7248 - val_loss: 0.9043 - val_acc: 0.7222
Epoch 49/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8892 - acc: 0.7263 - val_loss: 0.8993 - val_acc: 0.7247
Epoch 50/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8902 - acc: 0.7260 - val_loss: 0.9123 - val_acc: 0.7200
Epoch 51/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8890 - acc: 0.7261 - val_loss: 0.9017 - val_acc: 0.7247
Epoch 52/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8873 - acc: 0.7271 - val_loss: 0.8991 - val_acc: 0.7254
Epoch 53/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8879 - acc: 0.7272 - val_loss: 0.8996 - val_acc: 0.7247
Epoch 54/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8880 - acc: 0.7273 - val_loss: 0.9110 - val_acc: 0.7222
Epoch 55/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8882 - acc: 0.7275 - val_loss: 0.9008 - val_acc: 0.7245
Epoch 56/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8879 - acc: 0.7273 - val_loss: 0.9052 - val_acc: 0.7240
Epoch 57/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8860 - acc: 0.7280 - val_loss: 0.9027 - val_acc: 0.7250
Epoch 58/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8857 - acc: 0.7295 - val_loss: 0.8991 - val_acc: 0.7258
Epoch 59/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8899 - acc: 0.7264 - val_loss: 0.9094 - val_acc: 0.7238
Epoch 60/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8868 - acc: 0.7277 - val_loss: 0.9053 - val_acc: 0.7228
Epoch 61/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8864 - acc: 0.7288 - val_loss: 0.8992 - val_acc: 0.7254
Epoch 62/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8879 - acc: 0.7276 - val_loss: 0.8937 - val_acc: 0.7282
Epoch 63/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8860 - acc: 0.7279 - val_loss: 0.9124 - val_acc: 0.7200
Epoch 64/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8867 - acc: 0.7286 - val_loss: 0.9027 - val_acc: 0.7235
Epoch 65/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8852 - acc: 0.7286 - val_loss: 0.8949 - val_acc: 0.7265
Epoch 66/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8861 - acc: 0.7287 - val_loss: 0.8954 - val_acc: 0.7266
Epoch 67/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8840 - acc: 0.7283 - val_loss: 0.9055 - val_acc: 0.7222
Epoch 68/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8838 - acc: 0.7285 - val_loss: 0.8979 - val_acc: 0.7258
Epoch 69/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8849 - acc: 0.7277 - val_loss: 0.8946 - val_acc: 0.7275
Epoch 70/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8830 - acc: 0.7291 - val_loss: 0.8960 - val_acc: 0.7247
Epoch 71/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8848 - acc: 0.7285 - val_loss: 0.8995 - val_acc: 0.7262
Epoch 72/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8834 - acc: 0.7289 - val_loss: 0.9017 - val_acc: 0.7239
Epoch 73/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8826 - acc: 0.7281 - val_loss: 0.8945 - val_acc: 0.7273
Epoch 74/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8825 - acc: 0.7292 - val_loss: 0.8963 - val_acc: 0.7259
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8826 - acc: 0.7280 - val_loss: 0.8977 - val_acc: 0.7272
Epoch 76/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8830 - acc: 0.7291 - val_loss: 0.8935 - val_acc: 0.7268
Epoch 77/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8825 - acc: 0.7294 - val_loss: 0.8943 - val_acc: 0.7264
Epoch 78/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8835 - acc: 0.7282 - val_loss: 0.8985 - val_acc: 0.7260
Epoch 79/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8825 - acc: 0.7271 - val_loss: 0.8932 - val_acc: 0.7282
Epoch 80/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8817 - acc: 0.7296 - val_loss: 0.8885 - val_acc: 0.7285
Epoch 81/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8824 - acc: 0.7278 - val_loss: 0.8929 - val_acc: 0.7276
Epoch 82/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8817 - acc: 0.7291 - val_loss: 0.8922 - val_acc: 0.7279
Epoch 83/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8800 - acc: 0.7310 - val_loss: 0.9002 - val_acc: 0.7251
Epoch 84/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8794 - acc: 0.7299 - val_loss: 0.8957 - val_acc: 0.7252
Epoch 85/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8807 - acc: 0.7294 - val_loss: 0.8998 - val_acc: 0.7242
Epoch 86/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8795 - acc: 0.7294 - val_loss: 0.8992 - val_acc: 0.7249
Epoch 87/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8797 - acc: 0.7305 - val_loss: 0.8921 - val_acc: 0.7282
Epoch 88/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8812 - acc: 0.7295 - val_loss: 0.8967 - val_acc: 0.7238
Epoch 89/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8798 - acc: 0.7304 - val_loss: 0.8901 - val_acc: 0.7291
Epoch 90/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8821 - acc: 0.7296 - val_loss: 0.8958 - val_acc: 0.7253
Epoch 91/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8812 - acc: 0.7286 - val_loss: 0.8913 - val_acc: 0.7284
Epoch 92/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8796 - acc: 0.7296 - val_loss: 0.8986 - val_acc: 0.7248
Epoch 93/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8789 - acc: 0.7305 - val_loss: 0.8969 - val_acc: 0.7255
Epoch 94/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8808 - acc: 0.7296 - val_loss: 0.8978 - val_acc: 0.7260
Epoch 95/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8788 - acc: 0.7307 - val_loss: 0.8898 - val_acc: 0.7299
Epoch 96/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8781 - acc: 0.7309 - val_loss: 0.8893 - val_acc: 0.7282
Epoch 97/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8786 - acc: 0.7301 - val_loss: 0.8924 - val_acc: 0.7273
Epoch 98/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8804 - acc: 0.7296 - val_loss: 0.8923 - val_acc: 0.7278
Epoch 99/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8776 - acc: 0.7310 - val_loss: 0.8898 - val_acc: 0.7301
Epoch 100/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8787 - acc: 0.7312 - val_loss: 0.9003 - val_acc: 0.7231
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with relu activations&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with relu activations
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 47us/sample - loss: 0.9003 - acc: 0.7231
Validation accuracy: 72.31
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o4'></a></p>
<h5 id="Observation-4---NN-model-with-relu-activations">Observation 4 - NN model with relu activations<a class="anchor-link" href="#Observation-4---NN-model-with-relu-activations">&#182;</a></h5><ul>
<li>Improves the scores considerably.</li>
<li>Best accuracy achieved till now is using relu activations, SGD optimizer, changing learning rate to 0.001.</li>
<li>Next, let's try and change the number of activators and see if the score improves.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-changing-number-of-activators,-SGD-optimizers">NN model, relu activations, changing number of activators, SGD optimizers<a class="anchor-link" href="#NN-model,-relu-activations,-changing-number-of-activators,-SGD-optimizers">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with relu activations and changing number of activators&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Input Layer - adding input layer and activation functions relu</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">)))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 2 - Adding second hidden layer</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with relu activations and changing number of activators
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model3</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_2&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 256)               262400    
_________________________________________________________________
activation_6 (Activation)    (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 128)               32896     
_________________________________________________________________
activation_7 (Activation)    (None, 128)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 64)                8256      
_________________________________________________________________
activation_8 (Activation)    (None, 64)                0         
_________________________________________________________________
dense_9 (Dense)              (None, 10)                650       
_________________________________________________________________
activation_9 (Activation)    (None, 10)                0         
=================================================================
Total params: 304,202
Trainable params: 304,202
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">model3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 30us/sample - loss: 2.2970 - acc: 0.1352 - val_loss: 2.2856 - val_acc: 0.1681
Epoch 2/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2796 - acc: 0.1758 - val_loss: 2.2716 - val_acc: 0.2027
Epoch 3/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2635 - acc: 0.2046 - val_loss: 2.2535 - val_acc: 0.2214
Epoch 4/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.2420 - acc: 0.2349 - val_loss: 2.2278 - val_acc: 0.2569
Epoch 5/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2120 - acc: 0.2681 - val_loss: 2.1917 - val_acc: 0.2880
Epoch 6/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.1718 - acc: 0.2916 - val_loss: 2.1462 - val_acc: 0.3122
Epoch 7/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.1214 - acc: 0.3206 - val_loss: 2.0898 - val_acc: 0.3460
Epoch 8/100
42000/42000 [==============================] - 1s 27us/sample - loss: 2.0581 - acc: 0.3461 - val_loss: 2.0236 - val_acc: 0.3535
Epoch 9/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.9848 - acc: 0.3783 - val_loss: 1.9432 - val_acc: 0.3811
Epoch 10/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.9031 - acc: 0.4055 - val_loss: 1.8582 - val_acc: 0.4124
Epoch 11/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.8185 - acc: 0.4314 - val_loss: 1.7743 - val_acc: 0.4404
Epoch 12/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.7381 - acc: 0.4524 - val_loss: 1.6980 - val_acc: 0.4704
Epoch 13/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.6675 - acc: 0.4743 - val_loss: 1.6228 - val_acc: 0.4852
Epoch 14/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.5969 - acc: 0.4995 - val_loss: 1.5545 - val_acc: 0.5227
Epoch 15/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.5448 - acc: 0.5187 - val_loss: 1.5015 - val_acc: 0.5362
Epoch 16/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.4915 - acc: 0.5380 - val_loss: 1.4665 - val_acc: 0.5372
Epoch 17/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.4440 - acc: 0.5557 - val_loss: 1.4270 - val_acc: 0.5549
Epoch 18/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.3993 - acc: 0.5724 - val_loss: 1.3648 - val_acc: 0.5817
Epoch 19/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.3595 - acc: 0.5881 - val_loss: 1.3138 - val_acc: 0.6082
Epoch 20/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.3237 - acc: 0.5979 - val_loss: 1.2766 - val_acc: 0.6204
Epoch 21/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2891 - acc: 0.6102 - val_loss: 1.2549 - val_acc: 0.6227
Epoch 22/100
42000/42000 [==============================] - 1s 30us/sample - loss: 1.2631 - acc: 0.6179 - val_loss: 1.2217 - val_acc: 0.6326
Epoch 23/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2333 - acc: 0.6262 - val_loss: 1.1897 - val_acc: 0.6449
Epoch 24/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.2085 - acc: 0.6334 - val_loss: 1.2089 - val_acc: 0.6307
Epoch 25/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.1796 - acc: 0.6431 - val_loss: 1.1399 - val_acc: 0.6573
Epoch 26/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1567 - acc: 0.6515 - val_loss: 1.1690 - val_acc: 0.6470
Epoch 27/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1386 - acc: 0.6560 - val_loss: 1.1205 - val_acc: 0.6615
Epoch 28/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.1176 - acc: 0.6613 - val_loss: 1.1342 - val_acc: 0.6515
Epoch 29/100
42000/42000 [==============================] - 1s 26us/sample - loss: 1.0952 - acc: 0.6679 - val_loss: 1.0826 - val_acc: 0.6724
Epoch 30/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0830 - acc: 0.6719 - val_loss: 1.0669 - val_acc: 0.6750
Epoch 31/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0597 - acc: 0.6795 - val_loss: 1.0353 - val_acc: 0.6884
Epoch 32/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0421 - acc: 0.6851 - val_loss: 1.0258 - val_acc: 0.6925
Epoch 33/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0331 - acc: 0.6867 - val_loss: 1.0104 - val_acc: 0.6980
Epoch 34/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0165 - acc: 0.6934 - val_loss: 1.0069 - val_acc: 0.6970
Epoch 35/100
42000/42000 [==============================] - 1s 27us/sample - loss: 1.0008 - acc: 0.6960 - val_loss: 0.9970 - val_acc: 0.6992
Epoch 36/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9945 - acc: 0.6982 - val_loss: 0.9940 - val_acc: 0.6965
Epoch 37/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9793 - acc: 0.7029 - val_loss: 0.9624 - val_acc: 0.7110
Epoch 38/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.9663 - acc: 0.7077 - val_loss: 1.0115 - val_acc: 0.6923
Epoch 39/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9564 - acc: 0.7122 - val_loss: 0.9731 - val_acc: 0.7039
Epoch 40/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.9448 - acc: 0.7154 - val_loss: 0.9362 - val_acc: 0.7169
Epoch 41/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9365 - acc: 0.7180 - val_loss: 0.9292 - val_acc: 0.7188
Epoch 42/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9225 - acc: 0.7215 - val_loss: 0.8999 - val_acc: 0.7302
Epoch 43/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9145 - acc: 0.7238 - val_loss: 0.9025 - val_acc: 0.7299
Epoch 44/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9029 - acc: 0.7281 - val_loss: 1.0152 - val_acc: 0.6853
Epoch 45/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.9000 - acc: 0.7281 - val_loss: 0.8805 - val_acc: 0.7349
Epoch 46/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8898 - acc: 0.7289 - val_loss: 0.9236 - val_acc: 0.7178
Epoch 47/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8760 - acc: 0.7355 - val_loss: 0.8661 - val_acc: 0.7407
Epoch 48/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8694 - acc: 0.7385 - val_loss: 0.8628 - val_acc: 0.7422
Epoch 49/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8612 - acc: 0.7381 - val_loss: 0.8997 - val_acc: 0.7266
Epoch 50/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8591 - acc: 0.7398 - val_loss: 0.8416 - val_acc: 0.7478
Epoch 51/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8462 - acc: 0.7453 - val_loss: 0.9037 - val_acc: 0.7258
Epoch 52/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8391 - acc: 0.7459 - val_loss: 0.8628 - val_acc: 0.7382
Epoch 53/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8393 - acc: 0.7460 - val_loss: 0.8461 - val_acc: 0.7462
Epoch 54/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8288 - acc: 0.7493 - val_loss: 0.8156 - val_acc: 0.7549
Epoch 55/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8158 - acc: 0.7539 - val_loss: 0.8001 - val_acc: 0.7626
Epoch 56/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.8154 - acc: 0.7545 - val_loss: 0.8082 - val_acc: 0.7612
Epoch 57/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.8053 - acc: 0.7569 - val_loss: 0.8299 - val_acc: 0.7492
Epoch 58/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7994 - acc: 0.7599 - val_loss: 0.8095 - val_acc: 0.7570
Epoch 59/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7924 - acc: 0.7619 - val_loss: 0.8090 - val_acc: 0.7562
Epoch 60/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7901 - acc: 0.7609 - val_loss: 0.7917 - val_acc: 0.7615
Epoch 61/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7827 - acc: 0.7656 - val_loss: 0.7713 - val_acc: 0.7694
Epoch 62/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7769 - acc: 0.7650 - val_loss: 0.7830 - val_acc: 0.7661
Epoch 63/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7675 - acc: 0.7671 - val_loss: 0.7965 - val_acc: 0.7606
Epoch 64/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7644 - acc: 0.7679 - val_loss: 0.7599 - val_acc: 0.7731
Epoch 65/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7584 - acc: 0.7713 - val_loss: 0.7570 - val_acc: 0.7728
Epoch 66/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7528 - acc: 0.7725 - val_loss: 0.7684 - val_acc: 0.7698
Epoch 67/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7447 - acc: 0.7757 - val_loss: 0.7679 - val_acc: 0.7717
Epoch 68/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7423 - acc: 0.7766 - val_loss: 0.7558 - val_acc: 0.7750
Epoch 69/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7405 - acc: 0.7773 - val_loss: 0.7588 - val_acc: 0.7726
Epoch 70/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7341 - acc: 0.7778 - val_loss: 0.7447 - val_acc: 0.7783
Epoch 71/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7243 - acc: 0.7812 - val_loss: 0.7490 - val_acc: 0.7745
Epoch 72/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7239 - acc: 0.7818 - val_loss: 0.7168 - val_acc: 0.7861
Epoch 73/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7154 - acc: 0.7850 - val_loss: 0.7268 - val_acc: 0.7806
Epoch 74/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7103 - acc: 0.7860 - val_loss: 0.7208 - val_acc: 0.7813
Epoch 75/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7072 - acc: 0.7857 - val_loss: 0.7144 - val_acc: 0.7858
Epoch 76/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7010 - acc: 0.7887 - val_loss: 0.7003 - val_acc: 0.7927
Epoch 77/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.7012 - acc: 0.7879 - val_loss: 0.7082 - val_acc: 0.7896
Epoch 78/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6929 - acc: 0.7915 - val_loss: 0.6906 - val_acc: 0.7964
Epoch 79/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6939 - acc: 0.7909 - val_loss: 0.6842 - val_acc: 0.7974
Epoch 80/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6882 - acc: 0.7921 - val_loss: 0.7020 - val_acc: 0.7897
Epoch 81/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6787 - acc: 0.7941 - val_loss: 0.7151 - val_acc: 0.7848
Epoch 82/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6810 - acc: 0.7929 - val_loss: 0.6744 - val_acc: 0.7991
Epoch 83/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6717 - acc: 0.7963 - val_loss: 0.6813 - val_acc: 0.7977
Epoch 84/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6671 - acc: 0.7987 - val_loss: 0.7453 - val_acc: 0.7745
Epoch 85/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6686 - acc: 0.8000 - val_loss: 0.6739 - val_acc: 0.7992
Epoch 86/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6614 - acc: 0.8003 - val_loss: 0.6793 - val_acc: 0.7975
Epoch 87/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6552 - acc: 0.8014 - val_loss: 0.6969 - val_acc: 0.7904
Epoch 88/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6524 - acc: 0.8022 - val_loss: 0.6672 - val_acc: 0.8000
Epoch 89/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6473 - acc: 0.8039 - val_loss: 0.6661 - val_acc: 0.7994
Epoch 90/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6463 - acc: 0.8042 - val_loss: 0.6901 - val_acc: 0.7949
Epoch 91/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6423 - acc: 0.8070 - val_loss: 0.6594 - val_acc: 0.8036
Epoch 92/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6373 - acc: 0.8077 - val_loss: 0.7119 - val_acc: 0.7857
Epoch 93/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6325 - acc: 0.8087 - val_loss: 0.7002 - val_acc: 0.7896
Epoch 94/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6286 - acc: 0.8102 - val_loss: 0.6647 - val_acc: 0.8014
Epoch 95/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6266 - acc: 0.8102 - val_loss: 0.6754 - val_acc: 0.7953
Epoch 96/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6194 - acc: 0.8131 - val_loss: 0.6490 - val_acc: 0.8067
Epoch 97/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6192 - acc: 0.8125 - val_loss: 0.6230 - val_acc: 0.8147
Epoch 98/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6151 - acc: 0.8145 - val_loss: 0.6406 - val_acc: 0.8116
Epoch 99/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6118 - acc: 0.8143 - val_loss: 0.6255 - val_acc: 0.8143
Epoch 100/100
42000/42000 [==============================] - 1s 26us/sample - loss: 0.6101 - acc: 0.8161 - val_loss: 0.6550 - val_acc: 0.8033
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with relu activations and changing the number of activators&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with relu activations and changing the number of activators
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 49us/sample - loss: 0.6550 - acc: 0.8033
Validation accuracy: 80.33
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-changing-number-of-activators,-Adam-optimizers">NN model, relu activations, changing number of activators, Adam optimizers<a class="anchor-link" href="#NN-model,-relu-activations,-changing-number-of-activators,-Adam-optimizers">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">model3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.9431 - acc: 0.7111 - val_loss: 0.7650 - val_acc: 0.7681
Epoch 2/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7697 - acc: 0.7615 - val_loss: 0.8645 - val_acc: 0.7370
Epoch 3/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7513 - acc: 0.7701 - val_loss: 0.7942 - val_acc: 0.7514
Epoch 4/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7354 - acc: 0.7748 - val_loss: 0.7716 - val_acc: 0.7655
Epoch 5/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7217 - acc: 0.7776 - val_loss: 0.7024 - val_acc: 0.7878
Epoch 6/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6969 - acc: 0.7889 - val_loss: 0.7223 - val_acc: 0.7825
Epoch 7/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6787 - acc: 0.7916 - val_loss: 0.6787 - val_acc: 0.7961
Epoch 8/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.6733 - acc: 0.7931 - val_loss: 0.6695 - val_acc: 0.7995
Epoch 9/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.6702 - acc: 0.7970 - val_loss: 0.6557 - val_acc: 0.7993
Epoch 10/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6459 - acc: 0.8030 - val_loss: 0.6377 - val_acc: 0.8059
Epoch 11/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.6307 - acc: 0.8063 - val_loss: 0.6681 - val_acc: 0.7943
Epoch 12/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6220 - acc: 0.8095 - val_loss: 0.6519 - val_acc: 0.7985
Epoch 13/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6159 - acc: 0.8104 - val_loss: 0.5682 - val_acc: 0.8313
Epoch 14/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5888 - acc: 0.8195 - val_loss: 0.6379 - val_acc: 0.8075
Epoch 15/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5854 - acc: 0.8195 - val_loss: 0.6212 - val_acc: 0.8140
Epoch 16/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.5868 - acc: 0.8183 - val_loss: 0.6059 - val_acc: 0.8149
Epoch 17/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.5652 - acc: 0.8265 - val_loss: 0.6075 - val_acc: 0.8173
Epoch 18/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5573 - acc: 0.8286 - val_loss: 0.5845 - val_acc: 0.8208
Epoch 19/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5520 - acc: 0.8299 - val_loss: 0.6187 - val_acc: 0.8110
Epoch 20/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.5610 - acc: 0.8274 - val_loss: 0.5504 - val_acc: 0.8365
Epoch 21/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5195 - acc: 0.8405 - val_loss: 0.5797 - val_acc: 0.8260
Epoch 22/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5315 - acc: 0.8363 - val_loss: 0.5837 - val_acc: 0.8220
Epoch 23/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.5184 - acc: 0.8403 - val_loss: 0.5482 - val_acc: 0.8365
Epoch 24/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5084 - acc: 0.8423 - val_loss: 0.5310 - val_acc: 0.8398
Epoch 25/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4920 - acc: 0.8479 - val_loss: 0.5043 - val_acc: 0.8500
Epoch 26/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.4861 - acc: 0.8503 - val_loss: 0.5457 - val_acc: 0.8358
Epoch 27/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4943 - acc: 0.8464 - val_loss: 0.5342 - val_acc: 0.8367
Epoch 28/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4859 - acc: 0.8496 - val_loss: 0.4831 - val_acc: 0.8547
Epoch 29/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4807 - acc: 0.8505 - val_loss: 0.5247 - val_acc: 0.8406
Epoch 30/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4695 - acc: 0.8536 - val_loss: 0.5498 - val_acc: 0.8342
Epoch 31/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4653 - acc: 0.8545 - val_loss: 0.5010 - val_acc: 0.8485
Epoch 32/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4577 - acc: 0.8581 - val_loss: 0.4785 - val_acc: 0.8563
Epoch 33/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4566 - acc: 0.8579 - val_loss: 0.5020 - val_acc: 0.8483
Epoch 34/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4525 - acc: 0.8579 - val_loss: 0.5862 - val_acc: 0.8170
Epoch 35/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4355 - acc: 0.8633 - val_loss: 0.4661 - val_acc: 0.8595
Epoch 36/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4291 - acc: 0.8661 - val_loss: 0.5259 - val_acc: 0.8383
Epoch 37/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4338 - acc: 0.8625 - val_loss: 0.6068 - val_acc: 0.8148
Epoch 38/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4325 - acc: 0.8645 - val_loss: 0.4514 - val_acc: 0.8656
Epoch 39/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4294 - acc: 0.8657 - val_loss: 0.4641 - val_acc: 0.8617
Epoch 40/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4239 - acc: 0.8666 - val_loss: 0.5175 - val_acc: 0.8439
Epoch 41/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4266 - acc: 0.8659 - val_loss: 0.5023 - val_acc: 0.8489
Epoch 42/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4206 - acc: 0.8668 - val_loss: 0.4673 - val_acc: 0.8594
Epoch 43/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.4083 - acc: 0.8699 - val_loss: 0.4995 - val_acc: 0.8479
Epoch 44/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3917 - acc: 0.8773 - val_loss: 0.4362 - val_acc: 0.8698
Epoch 45/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3893 - acc: 0.8769 - val_loss: 0.5263 - val_acc: 0.8397
Epoch 46/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3958 - acc: 0.8752 - val_loss: 0.4380 - val_acc: 0.8702
Epoch 47/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.3959 - acc: 0.8743 - val_loss: 0.4739 - val_acc: 0.8581
Epoch 48/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3956 - acc: 0.8740 - val_loss: 0.4374 - val_acc: 0.8686
Epoch 49/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3933 - acc: 0.8749 - val_loss: 0.4651 - val_acc: 0.8607
Epoch 50/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3671 - acc: 0.8832 - val_loss: 0.4376 - val_acc: 0.8698
Epoch 51/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3662 - acc: 0.8822 - val_loss: 0.4165 - val_acc: 0.8781
Epoch 52/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3612 - acc: 0.8860 - val_loss: 0.4172 - val_acc: 0.8770
Epoch 53/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.3767 - acc: 0.8793 - val_loss: 0.4456 - val_acc: 0.8668
Epoch 54/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3575 - acc: 0.8863 - val_loss: 0.4409 - val_acc: 0.8695
Epoch 55/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3584 - acc: 0.8840 - val_loss: 0.4215 - val_acc: 0.8756
Epoch 56/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3558 - acc: 0.8864 - val_loss: 0.4387 - val_acc: 0.8690
Epoch 57/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3602 - acc: 0.8850 - val_loss: 0.4316 - val_acc: 0.8732
Epoch 58/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3350 - acc: 0.8931 - val_loss: 0.4214 - val_acc: 0.8757
Epoch 59/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3381 - acc: 0.8934 - val_loss: 0.4294 - val_acc: 0.8722
Epoch 60/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3374 - acc: 0.8938 - val_loss: 0.4462 - val_acc: 0.8694
Epoch 61/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.3499 - acc: 0.8881 - val_loss: 0.4223 - val_acc: 0.8754
Epoch 62/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3301 - acc: 0.8923 - val_loss: 0.4261 - val_acc: 0.8756
Epoch 63/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3302 - acc: 0.8942 - val_loss: 0.4492 - val_acc: 0.8649
Epoch 64/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.3206 - acc: 0.8978 - val_loss: 0.3936 - val_acc: 0.8864
Epoch 65/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3162 - acc: 0.8980 - val_loss: 0.3932 - val_acc: 0.8864
Epoch 66/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3092 - acc: 0.9009 - val_loss: 0.4013 - val_acc: 0.8825
Epoch 67/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3158 - acc: 0.8982 - val_loss: 0.4132 - val_acc: 0.8783
Epoch 68/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.3189 - acc: 0.8970 - val_loss: 0.3641 - val_acc: 0.8957
Epoch 69/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3035 - acc: 0.9028 - val_loss: 0.4218 - val_acc: 0.8760
Epoch 70/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3131 - acc: 0.8994 - val_loss: 0.4032 - val_acc: 0.8841
Epoch 71/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3009 - acc: 0.9026 - val_loss: 0.4012 - val_acc: 0.8855
Epoch 72/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2948 - acc: 0.9077 - val_loss: 0.3779 - val_acc: 0.8928
Epoch 73/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2957 - acc: 0.9047 - val_loss: 0.4244 - val_acc: 0.8788
Epoch 74/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.2927 - acc: 0.9074 - val_loss: 0.4000 - val_acc: 0.8860
Epoch 75/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2952 - acc: 0.9060 - val_loss: 0.4045 - val_acc: 0.8850
Epoch 76/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.2872 - acc: 0.9078 - val_loss: 0.4378 - val_acc: 0.8738
Epoch 77/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.3008 - acc: 0.9033 - val_loss: 0.3690 - val_acc: 0.8970
Epoch 78/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2724 - acc: 0.9125 - val_loss: 0.3860 - val_acc: 0.8903
Epoch 79/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.2974 - acc: 0.9023 - val_loss: 0.4051 - val_acc: 0.8840
Epoch 80/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2782 - acc: 0.9085 - val_loss: 0.3634 - val_acc: 0.9003
Epoch 81/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2770 - acc: 0.9094 - val_loss: 0.3970 - val_acc: 0.8867
Epoch 82/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2813 - acc: 0.9098 - val_loss: 0.3967 - val_acc: 0.8843
Epoch 83/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2933 - acc: 0.9037 - val_loss: 0.4170 - val_acc: 0.8803
Epoch 84/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2803 - acc: 0.9088 - val_loss: 0.3711 - val_acc: 0.8977
Epoch 85/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2688 - acc: 0.9134 - val_loss: 0.4142 - val_acc: 0.8851
Epoch 86/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2594 - acc: 0.9154 - val_loss: 0.3891 - val_acc: 0.8889
Epoch 87/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2721 - acc: 0.9106 - val_loss: 0.4202 - val_acc: 0.8810
Epoch 88/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2624 - acc: 0.9143 - val_loss: 0.4145 - val_acc: 0.8846
Epoch 89/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.2672 - acc: 0.9133 - val_loss: 0.4157 - val_acc: 0.8844
Epoch 90/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2453 - acc: 0.9196 - val_loss: 0.3752 - val_acc: 0.8970
Epoch 91/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2564 - acc: 0.9160 - val_loss: 0.3450 - val_acc: 0.9084
Epoch 92/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2401 - acc: 0.9220 - val_loss: 0.4096 - val_acc: 0.8861
Epoch 93/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2460 - acc: 0.9199 - val_loss: 0.3834 - val_acc: 0.8932
Epoch 94/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2424 - acc: 0.9212 - val_loss: 0.3874 - val_acc: 0.8963
Epoch 95/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.2699 - acc: 0.9125 - val_loss: 0.3681 - val_acc: 0.9016
Epoch 96/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2392 - acc: 0.9211 - val_loss: 0.4090 - val_acc: 0.8891
Epoch 97/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2432 - acc: 0.9213 - val_loss: 0.3536 - val_acc: 0.9046
Epoch 98/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.2430 - acc: 0.9205 - val_loss: 0.3895 - val_acc: 0.8961
Epoch 99/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2386 - acc: 0.9211 - val_loss: 0.3641 - val_acc: 0.9031
Epoch 100/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2458 - acc: 0.9195 - val_loss: 0.3539 - val_acc: 0.9066
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluate NN model with relu activations and changing the number of activators&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluate NN model with relu activations and changing the number of activators
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 49us/sample - loss: 0.3539 - acc: 0.9066
Validation accuracy: 90.66
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o5'></a></p>
<h5 id="Observation-5---NN-model-with-relu-activations-and-changing-activators">Observation 5 - NN model with relu activations and changing activators<a class="anchor-link" href="#Observation-5---NN-model-with-relu-activations-and-changing-activators">&#182;</a></h5><ul>
<li>Adding relu activations and changing activators results in improvement of score.</li>
<li>Best accuracy achieved till now is using relu activations, changing number of activators and Adam optimizers with a learning rate of 0.001</li>
<li>Next, let's try adding weight initilization.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='Weight'></a></p>
<h3 id="With-Weight-Initializers">With Weight Initializers<a class="anchor-link" href="#With-Weight-Initializers">&#182;</a></h3><p>Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-SGD-optimizers-with-weight-initializers">NN model, relu activations, SGD optimizers with weight initializers<a class="anchor-link" href="#NN-model,-relu-activations,-SGD-optimizers-with-weight-initializers">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with weight initializers&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model4</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Input Layer - adding input layer and activation functions relu and weight initializer</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">),</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 2 - adding second hidden layer</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 3 - adding third hidden layer</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with weight initializers
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model4</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_3&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 256)               262400    
_________________________________________________________________
activation_10 (Activation)   (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 128)               32896     
_________________________________________________________________
activation_11 (Activation)   (None, 128)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 64)                8256      
_________________________________________________________________
activation_12 (Activation)   (None, 64)                0         
_________________________________________________________________
dense_13 (Dense)             (None, 32)                2080      
_________________________________________________________________
activation_13 (Activation)   (None, 32)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 10)                330       
_________________________________________________________________
activation_14 (Activation)   (None, 10)                0         
=================================================================
Total params: 305,962
Trainable params: 305,962
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model4</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 31us/sample - loss: 2.3023 - acc: 0.1175 - val_loss: 2.2772 - val_acc: 0.1445
Epoch 2/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2583 - acc: 0.1590 - val_loss: 2.2352 - val_acc: 0.1811
Epoch 3/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.2025 - acc: 0.1988 - val_loss: 2.1630 - val_acc: 0.2169
Epoch 4/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.1205 - acc: 0.2455 - val_loss: 2.0677 - val_acc: 0.2791
Epoch 5/100
42000/42000 [==============================] - 1s 28us/sample - loss: 2.0151 - acc: 0.3002 - val_loss: 1.9792 - val_acc: 0.2936
Epoch 6/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.9102 - acc: 0.3502 - val_loss: 1.8788 - val_acc: 0.3721
Epoch 7/100
42000/42000 [==============================] - 1s 31us/sample - loss: 1.8119 - acc: 0.3987 - val_loss: 1.7286 - val_acc: 0.4290
Epoch 8/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.7188 - acc: 0.4394 - val_loss: 1.6887 - val_acc: 0.4459
Epoch 9/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.6454 - acc: 0.4664 - val_loss: 1.5630 - val_acc: 0.4977
Epoch 10/100
42000/42000 [==============================] - 1s 30us/sample - loss: 1.5575 - acc: 0.5016 - val_loss: 1.4854 - val_acc: 0.5321
Epoch 11/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.4950 - acc: 0.5230 - val_loss: 1.4138 - val_acc: 0.5634
Epoch 12/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.4227 - acc: 0.5528 - val_loss: 1.3826 - val_acc: 0.5729
Epoch 13/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.3695 - acc: 0.5711 - val_loss: 1.3418 - val_acc: 0.5759
Epoch 14/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.3157 - acc: 0.5902 - val_loss: 1.2598 - val_acc: 0.6136
Epoch 15/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.2658 - acc: 0.6087 - val_loss: 1.2570 - val_acc: 0.6051
Epoch 16/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.2305 - acc: 0.6206 - val_loss: 1.1832 - val_acc: 0.6360
Epoch 17/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.1781 - acc: 0.6407 - val_loss: 1.1872 - val_acc: 0.6325
Epoch 18/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.1564 - acc: 0.6430 - val_loss: 1.1064 - val_acc: 0.6654
Epoch 19/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.1314 - acc: 0.6545 - val_loss: 1.1058 - val_acc: 0.6610
Epoch 20/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.1027 - acc: 0.6636 - val_loss: 1.0935 - val_acc: 0.6723
Epoch 21/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0788 - acc: 0.6717 - val_loss: 1.0264 - val_acc: 0.6935
Epoch 22/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0554 - acc: 0.6769 - val_loss: 1.0594 - val_acc: 0.6763
Epoch 23/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0394 - acc: 0.6810 - val_loss: 1.0024 - val_acc: 0.6969
Epoch 24/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0207 - acc: 0.6883 - val_loss: 1.0085 - val_acc: 0.6931
Epoch 25/100
42000/42000 [==============================] - 1s 28us/sample - loss: 1.0036 - acc: 0.6933 - val_loss: 0.9629 - val_acc: 0.7112
Epoch 26/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9817 - acc: 0.7005 - val_loss: 0.9621 - val_acc: 0.7084
Epoch 27/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9767 - acc: 0.7021 - val_loss: 0.9664 - val_acc: 0.7089
Epoch 28/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9630 - acc: 0.7063 - val_loss: 0.9301 - val_acc: 0.7188
Epoch 29/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9437 - acc: 0.7120 - val_loss: 0.9326 - val_acc: 0.7169
Epoch 30/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9364 - acc: 0.7131 - val_loss: 0.9065 - val_acc: 0.7268
Epoch 31/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.9258 - acc: 0.7177 - val_loss: 0.9086 - val_acc: 0.7228
Epoch 32/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.9093 - acc: 0.7233 - val_loss: 0.9859 - val_acc: 0.6932
Epoch 33/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8930 - acc: 0.7258 - val_loss: 0.8975 - val_acc: 0.7272
Epoch 34/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8898 - acc: 0.7287 - val_loss: 0.9300 - val_acc: 0.7106
Epoch 35/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8749 - acc: 0.7321 - val_loss: 0.8580 - val_acc: 0.7386
Epoch 36/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8671 - acc: 0.7364 - val_loss: 0.8540 - val_acc: 0.7415
Epoch 37/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.8604 - acc: 0.7385 - val_loss: 0.8776 - val_acc: 0.7315
Epoch 38/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8520 - acc: 0.7388 - val_loss: 0.8911 - val_acc: 0.7285
Epoch 39/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8411 - acc: 0.7417 - val_loss: 0.8206 - val_acc: 0.7509
Epoch 40/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8298 - acc: 0.7486 - val_loss: 0.8165 - val_acc: 0.7536
Epoch 41/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8214 - acc: 0.7479 - val_loss: 0.8244 - val_acc: 0.7494
Epoch 42/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8155 - acc: 0.7504 - val_loss: 0.8274 - val_acc: 0.7457
Epoch 43/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.8055 - acc: 0.7525 - val_loss: 0.7904 - val_acc: 0.7614
Epoch 44/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7994 - acc: 0.7544 - val_loss: 0.8214 - val_acc: 0.7481
Epoch 45/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7903 - acc: 0.7585 - val_loss: 0.7907 - val_acc: 0.7623
Epoch 46/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7772 - acc: 0.7641 - val_loss: 0.7760 - val_acc: 0.7646
Epoch 47/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7708 - acc: 0.7637 - val_loss: 0.7748 - val_acc: 0.7641
Epoch 48/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7647 - acc: 0.7668 - val_loss: 0.7755 - val_acc: 0.7647
Epoch 49/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7619 - acc: 0.7675 - val_loss: 0.8349 - val_acc: 0.7467
Epoch 50/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7527 - acc: 0.7716 - val_loss: 0.8013 - val_acc: 0.7557
Epoch 51/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7460 - acc: 0.7721 - val_loss: 0.8218 - val_acc: 0.7488
Epoch 52/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7374 - acc: 0.7745 - val_loss: 0.7460 - val_acc: 0.7739
Epoch 53/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.7298 - acc: 0.7764 - val_loss: 0.7361 - val_acc: 0.7758
Epoch 54/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7241 - acc: 0.7789 - val_loss: 0.7359 - val_acc: 0.7771
Epoch 55/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7231 - acc: 0.7796 - val_loss: 0.7706 - val_acc: 0.7632
Epoch 56/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.7154 - acc: 0.7819 - val_loss: 0.6990 - val_acc: 0.7884
Epoch 57/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.7089 - acc: 0.7844 - val_loss: 0.7225 - val_acc: 0.7826
Epoch 58/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6965 - acc: 0.7884 - val_loss: 0.7235 - val_acc: 0.7802
Epoch 59/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6945 - acc: 0.7878 - val_loss: 0.6968 - val_acc: 0.7902
Epoch 60/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.6934 - acc: 0.7889 - val_loss: 0.6906 - val_acc: 0.7930
Epoch 61/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6812 - acc: 0.7935 - val_loss: 0.7031 - val_acc: 0.7886
Epoch 62/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6734 - acc: 0.7948 - val_loss: 0.6841 - val_acc: 0.7936
Epoch 63/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6704 - acc: 0.7957 - val_loss: 0.7160 - val_acc: 0.7796
Epoch 64/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6639 - acc: 0.7963 - val_loss: 0.7002 - val_acc: 0.7873
Epoch 65/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6635 - acc: 0.7970 - val_loss: 0.6885 - val_acc: 0.7896
Epoch 66/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6577 - acc: 0.7989 - val_loss: 0.6442 - val_acc: 0.8066
Epoch 67/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6460 - acc: 0.8025 - val_loss: 0.6553 - val_acc: 0.8033
Epoch 68/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6456 - acc: 0.8022 - val_loss: 0.6597 - val_acc: 0.8029
Epoch 69/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6428 - acc: 0.8029 - val_loss: 0.6701 - val_acc: 0.7975
Epoch 70/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6438 - acc: 0.8018 - val_loss: 0.6699 - val_acc: 0.7985
Epoch 71/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6290 - acc: 0.8080 - val_loss: 0.6421 - val_acc: 0.8052
Epoch 72/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.6306 - acc: 0.8080 - val_loss: 0.7013 - val_acc: 0.7821
Epoch 73/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6264 - acc: 0.8086 - val_loss: 0.6395 - val_acc: 0.8061
Epoch 74/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.6162 - acc: 0.8125 - val_loss: 0.6528 - val_acc: 0.8025
Epoch 75/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6137 - acc: 0.8125 - val_loss: 0.6327 - val_acc: 0.8090
Epoch 76/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6107 - acc: 0.8144 - val_loss: 0.6555 - val_acc: 0.8019
Epoch 77/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6071 - acc: 0.8128 - val_loss: 0.6139 - val_acc: 0.8156
Epoch 78/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6012 - acc: 0.8164 - val_loss: 0.6277 - val_acc: 0.8092
Epoch 79/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.6028 - acc: 0.8175 - val_loss: 0.6266 - val_acc: 0.8112
Epoch 80/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5946 - acc: 0.8199 - val_loss: 0.6035 - val_acc: 0.8183
Epoch 81/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.5892 - acc: 0.8203 - val_loss: 0.6225 - val_acc: 0.8119
Epoch 82/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5836 - acc: 0.8201 - val_loss: 0.6568 - val_acc: 0.8032
Epoch 83/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5772 - acc: 0.8246 - val_loss: 0.6034 - val_acc: 0.8190
Epoch 84/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5778 - acc: 0.8245 - val_loss: 0.6260 - val_acc: 0.8090
Epoch 85/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5757 - acc: 0.8242 - val_loss: 0.5882 - val_acc: 0.8230
Epoch 86/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5666 - acc: 0.8275 - val_loss: 0.6215 - val_acc: 0.8104
Epoch 87/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5657 - acc: 0.8270 - val_loss: 0.5943 - val_acc: 0.8211
Epoch 88/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5611 - acc: 0.8284 - val_loss: 0.5841 - val_acc: 0.8231
Epoch 89/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5546 - acc: 0.8317 - val_loss: 0.5673 - val_acc: 0.8303
Epoch 90/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5512 - acc: 0.8315 - val_loss: 0.5769 - val_acc: 0.8254
Epoch 91/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5524 - acc: 0.8309 - val_loss: 0.5750 - val_acc: 0.8269
Epoch 92/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5496 - acc: 0.8310 - val_loss: 0.5701 - val_acc: 0.8285
Epoch 93/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5473 - acc: 0.8340 - val_loss: 0.5738 - val_acc: 0.8263
Epoch 94/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5401 - acc: 0.8360 - val_loss: 0.5505 - val_acc: 0.8365
Epoch 95/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5413 - acc: 0.8350 - val_loss: 0.6173 - val_acc: 0.8122
Epoch 96/100
42000/42000 [==============================] - 1s 27us/sample - loss: 0.5368 - acc: 0.8359 - val_loss: 0.5707 - val_acc: 0.8304
Epoch 97/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5295 - acc: 0.8385 - val_loss: 0.5667 - val_acc: 0.8296
Epoch 98/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5249 - acc: 0.8381 - val_loss: 0.5843 - val_acc: 0.8244
Epoch 99/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5273 - acc: 0.8393 - val_loss: 0.5687 - val_acc: 0.8294
Epoch 100/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.5213 - acc: 0.8399 - val_loss: 0.5648 - val_acc: 0.8295
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN with weight initializers&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results4</span> <span class="o">=</span> <span class="n">model4</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results4</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN with weight initializers
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 51us/sample - loss: 0.5648 - acc: 0.8295
Validation accuracy: 82.95
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-Adam-optimizers-with-weight-initializers">NN model, relu activations, Adam optimizers with weight initializers<a class="anchor-link" href="#NN-model,-relu-activations,-Adam-optimizers-with-weight-initializers">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model4</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 1s 33us/sample - loss: 0.8991 - acc: 0.7259 - val_loss: 0.7777 - val_acc: 0.7567
Epoch 2/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.7556 - acc: 0.7651 - val_loss: 0.7145 - val_acc: 0.7837
Epoch 3/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.7233 - acc: 0.7769 - val_loss: 0.7429 - val_acc: 0.7717
Epoch 4/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.7134 - acc: 0.7808 - val_loss: 0.7203 - val_acc: 0.7836
Epoch 5/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.7006 - acc: 0.7834 - val_loss: 0.7579 - val_acc: 0.7643
Epoch 6/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6854 - acc: 0.7876 - val_loss: 0.6947 - val_acc: 0.7862
Epoch 7/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.6375 - acc: 0.8048 - val_loss: 0.6920 - val_acc: 0.7847
Epoch 8/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6482 - acc: 0.7993 - val_loss: 0.7172 - val_acc: 0.7798
Epoch 9/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6429 - acc: 0.8015 - val_loss: 0.6664 - val_acc: 0.7970
Epoch 10/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6220 - acc: 0.8086 - val_loss: 0.5867 - val_acc: 0.8212
Epoch 11/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.6078 - acc: 0.8123 - val_loss: 0.6032 - val_acc: 0.8152
Epoch 12/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5877 - acc: 0.8190 - val_loss: 0.5871 - val_acc: 0.8198
Epoch 13/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6041 - acc: 0.8137 - val_loss: 0.6405 - val_acc: 0.8071
Epoch 14/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5615 - acc: 0.8272 - val_loss: 0.6205 - val_acc: 0.8112
Epoch 15/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5613 - acc: 0.8273 - val_loss: 0.5388 - val_acc: 0.8364
Epoch 16/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.5540 - acc: 0.8296 - val_loss: 0.5700 - val_acc: 0.8283
Epoch 17/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.5484 - acc: 0.8299 - val_loss: 0.6048 - val_acc: 0.8130
Epoch 18/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.5484 - acc: 0.8280 - val_loss: 0.5539 - val_acc: 0.8290
Epoch 19/100
42000/42000 [==============================] - 1s 33us/sample - loss: 0.5517 - acc: 0.8289 - val_loss: 0.5933 - val_acc: 0.8200
Epoch 20/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.5333 - acc: 0.8333 - val_loss: 0.5172 - val_acc: 0.8419
Epoch 21/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.5145 - acc: 0.8397 - val_loss: 0.5776 - val_acc: 0.8227
Epoch 22/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.5038 - acc: 0.8428 - val_loss: 0.5885 - val_acc: 0.8203
Epoch 23/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.5021 - acc: 0.8435 - val_loss: 0.5563 - val_acc: 0.8313
Epoch 24/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4995 - acc: 0.8436 - val_loss: 0.5187 - val_acc: 0.8443
Epoch 25/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4902 - acc: 0.8461 - val_loss: 0.5196 - val_acc: 0.8422
Epoch 26/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4710 - acc: 0.8533 - val_loss: 0.4911 - val_acc: 0.8530
Epoch 27/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4936 - acc: 0.8451 - val_loss: 0.5424 - val_acc: 0.8342
Epoch 28/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4797 - acc: 0.8485 - val_loss: 0.5177 - val_acc: 0.8429
Epoch 29/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4690 - acc: 0.8533 - val_loss: 0.4953 - val_acc: 0.8504
Epoch 30/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4609 - acc: 0.8557 - val_loss: 0.5042 - val_acc: 0.8469
Epoch 31/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4545 - acc: 0.8564 - val_loss: 0.4685 - val_acc: 0.8587
Epoch 32/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4528 - acc: 0.8584 - val_loss: 0.5315 - val_acc: 0.8411
Epoch 33/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.4509 - acc: 0.8584 - val_loss: 0.5534 - val_acc: 0.8298
Epoch 34/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4374 - acc: 0.8635 - val_loss: 0.5036 - val_acc: 0.8473
Epoch 35/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4344 - acc: 0.8632 - val_loss: 0.4816 - val_acc: 0.8529
Epoch 36/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4361 - acc: 0.8620 - val_loss: 0.6043 - val_acc: 0.8112
Epoch 37/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4331 - acc: 0.8619 - val_loss: 0.5036 - val_acc: 0.8474
Epoch 38/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4255 - acc: 0.8643 - val_loss: 0.4520 - val_acc: 0.8638
Epoch 39/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4218 - acc: 0.8663 - val_loss: 0.4762 - val_acc: 0.8538
Epoch 40/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4104 - acc: 0.8693 - val_loss: 0.4917 - val_acc: 0.8511
Epoch 41/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4133 - acc: 0.8700 - val_loss: 0.4658 - val_acc: 0.8579
Epoch 42/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4138 - acc: 0.8682 - val_loss: 0.4311 - val_acc: 0.8703
Epoch 43/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4022 - acc: 0.8722 - val_loss: 0.5085 - val_acc: 0.8441
Epoch 44/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3980 - acc: 0.8724 - val_loss: 0.4468 - val_acc: 0.8643
Epoch 45/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3898 - acc: 0.8754 - val_loss: 0.4190 - val_acc: 0.8749
Epoch 46/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3825 - acc: 0.8784 - val_loss: 0.4479 - val_acc: 0.8654
Epoch 47/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3758 - acc: 0.8804 - val_loss: 0.4472 - val_acc: 0.8663
Epoch 48/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3744 - acc: 0.8803 - val_loss: 0.4578 - val_acc: 0.8621
Epoch 49/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3732 - acc: 0.8777 - val_loss: 0.4057 - val_acc: 0.8789
Epoch 50/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3702 - acc: 0.8817 - val_loss: 0.4784 - val_acc: 0.8530
Epoch 51/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3802 - acc: 0.8784 - val_loss: 0.4168 - val_acc: 0.8766
Epoch 52/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.3640 - acc: 0.8855 - val_loss: 0.4354 - val_acc: 0.8693
Epoch 53/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3655 - acc: 0.8817 - val_loss: 0.4408 - val_acc: 0.8706
Epoch 54/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3629 - acc: 0.8839 - val_loss: 0.4955 - val_acc: 0.8507
Epoch 55/100
42000/42000 [==============================] - 1s 33us/sample - loss: 0.3575 - acc: 0.8848 - val_loss: 0.4405 - val_acc: 0.8676
Epoch 56/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3460 - acc: 0.8889 - val_loss: 0.4270 - val_acc: 0.8721
Epoch 57/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3463 - acc: 0.8882 - val_loss: 0.4216 - val_acc: 0.8741
Epoch 58/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3444 - acc: 0.8886 - val_loss: 0.4267 - val_acc: 0.8738
Epoch 59/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3352 - acc: 0.8926 - val_loss: 0.4318 - val_acc: 0.8720
Epoch 60/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3576 - acc: 0.8835 - val_loss: 0.4341 - val_acc: 0.8686
Epoch 61/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3416 - acc: 0.8905 - val_loss: 0.4321 - val_acc: 0.8719
Epoch 62/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3321 - acc: 0.8934 - val_loss: 0.4097 - val_acc: 0.8776
Epoch 63/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3265 - acc: 0.8952 - val_loss: 0.3944 - val_acc: 0.8839
Epoch 64/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3281 - acc: 0.8930 - val_loss: 0.4291 - val_acc: 0.8740
Epoch 65/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3175 - acc: 0.8973 - val_loss: 0.4325 - val_acc: 0.8718
Epoch 66/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.3356 - acc: 0.8910 - val_loss: 0.3925 - val_acc: 0.8855
Epoch 67/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3264 - acc: 0.8937 - val_loss: 0.4110 - val_acc: 0.8832
Epoch 68/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3193 - acc: 0.8961 - val_loss: 0.4201 - val_acc: 0.8763
Epoch 69/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3213 - acc: 0.8955 - val_loss: 0.4312 - val_acc: 0.8732
Epoch 70/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3135 - acc: 0.8977 - val_loss: 0.4648 - val_acc: 0.8613
Epoch 71/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3129 - acc: 0.8984 - val_loss: 0.3997 - val_acc: 0.8838
Epoch 72/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3039 - acc: 0.9007 - val_loss: 0.4164 - val_acc: 0.8781
Epoch 73/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3088 - acc: 0.9005 - val_loss: 0.4063 - val_acc: 0.8815
Epoch 74/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3041 - acc: 0.9022 - val_loss: 0.3704 - val_acc: 0.8949
Epoch 75/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2971 - acc: 0.9039 - val_loss: 0.4283 - val_acc: 0.8779
Epoch 76/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3031 - acc: 0.9018 - val_loss: 0.4305 - val_acc: 0.8752
Epoch 77/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2963 - acc: 0.9041 - val_loss: 0.4077 - val_acc: 0.8816
Epoch 78/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.2873 - acc: 0.9086 - val_loss: 0.4098 - val_acc: 0.8811
Epoch 79/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2926 - acc: 0.9044 - val_loss: 0.3991 - val_acc: 0.8887
Epoch 80/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.2840 - acc: 0.9085 - val_loss: 0.3795 - val_acc: 0.8923
Epoch 81/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.2877 - acc: 0.9056 - val_loss: 0.4328 - val_acc: 0.8731
Epoch 82/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2810 - acc: 0.9073 - val_loss: 0.3815 - val_acc: 0.8924
Epoch 83/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.2881 - acc: 0.9066 - val_loss: 0.4516 - val_acc: 0.8707
Epoch 84/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2902 - acc: 0.9050 - val_loss: 0.3960 - val_acc: 0.8873
Epoch 85/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2647 - acc: 0.9148 - val_loss: 0.3972 - val_acc: 0.8877
Epoch 86/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2760 - acc: 0.9100 - val_loss: 0.3952 - val_acc: 0.8874
Epoch 87/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2739 - acc: 0.9095 - val_loss: 0.4250 - val_acc: 0.8813
Epoch 88/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2745 - acc: 0.9099 - val_loss: 0.4271 - val_acc: 0.8791
Epoch 89/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2576 - acc: 0.9163 - val_loss: 0.4173 - val_acc: 0.8834
Epoch 90/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2657 - acc: 0.9130 - val_loss: 0.3729 - val_acc: 0.8973
Epoch 91/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.2493 - acc: 0.9177 - val_loss: 0.3755 - val_acc: 0.8954
Epoch 92/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2611 - acc: 0.9147 - val_loss: 0.3596 - val_acc: 0.9012
Epoch 93/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2543 - acc: 0.9182 - val_loss: 0.3893 - val_acc: 0.8908
Epoch 94/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2478 - acc: 0.9176 - val_loss: 0.4036 - val_acc: 0.8882
Epoch 95/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2613 - acc: 0.9129 - val_loss: 0.4178 - val_acc: 0.8851
Epoch 96/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2535 - acc: 0.9170 - val_loss: 0.3966 - val_acc: 0.8928
Epoch 97/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2520 - acc: 0.9163 - val_loss: 0.3765 - val_acc: 0.8971
Epoch 98/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2548 - acc: 0.9166 - val_loss: 0.4093 - val_acc: 0.8857
Epoch 99/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.2535 - acc: 0.9170 - val_loss: 0.4349 - val_acc: 0.8797
Epoch 100/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.2450 - acc: 0.9200 - val_loss: 0.4037 - val_acc: 0.8873
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN with weight initializers&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results4</span> <span class="o">=</span> <span class="n">model4</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results4</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN with weight initializers
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 53us/sample - loss: 0.4037 - acc: 0.8873
Validation accuracy: 88.73
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o6'></a></p>
<h5 id="Observation-6---Weight-initializers">Observation 6 - Weight initializers<a class="anchor-link" href="#Observation-6---Weight-initializers">&#182;</a></h5><ul>
<li>Adding weight initialiers didn't result in improvement of score.</li>
<li>relu activations, changing number of activators, Adam optimizers gives the best score out of the ones tried as of now.</li>
<li>Next, let's try batch normalization.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='Batch'></a></p>
<h3 id="Batch-Normalization">Batch Normalization<a class="anchor-link" href="#Batch-Normalization">&#182;</a></h3><p>Batch Normalization, one of the methods to prevent the "internal covariance shift" problem, has proven to be highly effective. Normalize each mini-batch before nonlinearity.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-SGD-optimizers-with-weight-initializers-and-batch-normalization">NN model, relu activations, SGD optimizers with weight initializers and batch normalization<a class="anchor-link" href="#NN-model,-relu-activations,-SGD-optimizers-with-weight-initializers-and-batch-normalization">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with batch normalization&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model5</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Input Layer - adding input layer and activation functions relu and weight initializer</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">),</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 2 - adding second hidden layer</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 3 - adding third hidden layer</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with batch normalization
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model5</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_4&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 256)               262400    
_________________________________________________________________
batch_normalization (BatchNo (None, 256)               1024      
_________________________________________________________________
activation_15 (Activation)   (None, 256)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 128)               32896     
_________________________________________________________________
batch_normalization_1 (Batch (None, 128)               512       
_________________________________________________________________
activation_16 (Activation)   (None, 128)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 64)                8256      
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_17 (Activation)   (None, 64)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 32)                2080      
_________________________________________________________________
batch_normalization_3 (Batch (None, 32)                128       
_________________________________________________________________
activation_18 (Activation)   (None, 32)                0         
_________________________________________________________________
dense_19 (Dense)             (None, 10)                330       
_________________________________________________________________
activation_19 (Activation)   (None, 10)                0         
=================================================================
Total params: 307,882
Trainable params: 306,922
Non-trainable params: 960
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model5</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 2s 58us/sample - loss: 2.3150 - acc: 0.1844 - val_loss: 2.2163 - val_acc: 0.1867
Epoch 2/100
42000/42000 [==============================] - 2s 48us/sample - loss: 1.8823 - acc: 0.3717 - val_loss: 1.8685 - val_acc: 0.3833
Epoch 3/100
42000/42000 [==============================] - 2s 47us/sample - loss: 1.6338 - acc: 0.4850 - val_loss: 1.6083 - val_acc: 0.4873
Epoch 4/100
42000/42000 [==============================] - 2s 48us/sample - loss: 1.4471 - acc: 0.5612 - val_loss: 1.4532 - val_acc: 0.5435
Epoch 5/100
42000/42000 [==============================] - 2s 47us/sample - loss: 1.3017 - acc: 0.6110 - val_loss: 1.2819 - val_acc: 0.6060
Epoch 6/100
42000/42000 [==============================] - 2s 48us/sample - loss: 1.1888 - acc: 0.6459 - val_loss: 1.2110 - val_acc: 0.6357
Epoch 7/100
42000/42000 [==============================] - 2s 51us/sample - loss: 1.0931 - acc: 0.6720 - val_loss: 1.1470 - val_acc: 0.6414
Epoch 8/100
42000/42000 [==============================] - 2s 48us/sample - loss: 1.0188 - acc: 0.6929 - val_loss: 1.0641 - val_acc: 0.6710
Epoch 9/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.9576 - acc: 0.7099 - val_loss: 1.0080 - val_acc: 0.6921
Epoch 10/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.9052 - acc: 0.7238 - val_loss: 0.9584 - val_acc: 0.7056
Epoch 11/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.8609 - acc: 0.7344 - val_loss: 0.9839 - val_acc: 0.6924
Epoch 12/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.8205 - acc: 0.7494 - val_loss: 0.9355 - val_acc: 0.7078
Epoch 13/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.7844 - acc: 0.7591 - val_loss: 0.8979 - val_acc: 0.7123
Epoch 14/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.7555 - acc: 0.7667 - val_loss: 0.9690 - val_acc: 0.6953
Epoch 15/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.7297 - acc: 0.7736 - val_loss: 0.8284 - val_acc: 0.7423
Epoch 16/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.7034 - acc: 0.7813 - val_loss: 0.9007 - val_acc: 0.7136
Epoch 17/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.6805 - acc: 0.7895 - val_loss: 0.9803 - val_acc: 0.6925
Epoch 18/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.6578 - acc: 0.7969 - val_loss: 0.7991 - val_acc: 0.7457
Epoch 19/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.6425 - acc: 0.8005 - val_loss: 0.8517 - val_acc: 0.7338
Epoch 20/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.6255 - acc: 0.8049 - val_loss: 0.8117 - val_acc: 0.7400
Epoch 21/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.6085 - acc: 0.8114 - val_loss: 0.8065 - val_acc: 0.7500
Epoch 22/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.5910 - acc: 0.8164 - val_loss: 0.7252 - val_acc: 0.7730
Epoch 23/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.5801 - acc: 0.8195 - val_loss: 0.8067 - val_acc: 0.7415
Epoch 24/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.5632 - acc: 0.8253 - val_loss: 0.8137 - val_acc: 0.7422
Epoch 25/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.5505 - acc: 0.8272 - val_loss: 0.6932 - val_acc: 0.7826
Epoch 26/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.5378 - acc: 0.8322 - val_loss: 0.9460 - val_acc: 0.7073
Epoch 27/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.5254 - acc: 0.8360 - val_loss: 0.6978 - val_acc: 0.7786
Epoch 28/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.5168 - acc: 0.8379 - val_loss: 0.8921 - val_acc: 0.7368
Epoch 29/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.5062 - acc: 0.8424 - val_loss: 0.7901 - val_acc: 0.7526
Epoch 30/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.4920 - acc: 0.8462 - val_loss: 0.6657 - val_acc: 0.7909
Epoch 31/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.4873 - acc: 0.8475 - val_loss: 0.9750 - val_acc: 0.7089
Epoch 32/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4793 - acc: 0.8509 - val_loss: 0.7757 - val_acc: 0.7625
Epoch 33/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4699 - acc: 0.8526 - val_loss: 0.7678 - val_acc: 0.7598
Epoch 34/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.4629 - acc: 0.8545 - val_loss: 0.7930 - val_acc: 0.7597
Epoch 35/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.4515 - acc: 0.8596 - val_loss: 0.6978 - val_acc: 0.7844
Epoch 36/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.4392 - acc: 0.8636 - val_loss: 0.6710 - val_acc: 0.7926
Epoch 37/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.4332 - acc: 0.8650 - val_loss: 0.7249 - val_acc: 0.7742
Epoch 38/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4249 - acc: 0.8675 - val_loss: 0.6876 - val_acc: 0.7842
Epoch 39/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4179 - acc: 0.8695 - val_loss: 0.6177 - val_acc: 0.8071
Epoch 40/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4102 - acc: 0.8732 - val_loss: 1.1939 - val_acc: 0.6915
Epoch 41/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4061 - acc: 0.8729 - val_loss: 0.7878 - val_acc: 0.7606
Epoch 42/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.4005 - acc: 0.8746 - val_loss: 0.6239 - val_acc: 0.8039
Epoch 43/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3936 - acc: 0.8773 - val_loss: 0.6273 - val_acc: 0.8059
Epoch 44/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.3872 - acc: 0.8802 - val_loss: 0.5841 - val_acc: 0.8211
Epoch 45/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3789 - acc: 0.8835 - val_loss: 0.5863 - val_acc: 0.8203
Epoch 46/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.3709 - acc: 0.8839 - val_loss: 0.6137 - val_acc: 0.8091
Epoch 47/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.3669 - acc: 0.8873 - val_loss: 0.6152 - val_acc: 0.8077
Epoch 48/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.3640 - acc: 0.8870 - val_loss: 0.6704 - val_acc: 0.7876
Epoch 49/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3575 - acc: 0.8888 - val_loss: 0.6125 - val_acc: 0.8124
Epoch 50/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3488 - acc: 0.8913 - val_loss: 0.7482 - val_acc: 0.7721
Epoch 51/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.3417 - acc: 0.8925 - val_loss: 0.6436 - val_acc: 0.8008
Epoch 52/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.3388 - acc: 0.8943 - val_loss: 0.6630 - val_acc: 0.8002
Epoch 53/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3363 - acc: 0.8953 - val_loss: 1.0303 - val_acc: 0.7077
Epoch 54/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3302 - acc: 0.8977 - val_loss: 0.6981 - val_acc: 0.7801
Epoch 55/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3246 - acc: 0.8993 - val_loss: 0.7736 - val_acc: 0.7778
Epoch 56/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3225 - acc: 0.9000 - val_loss: 0.9034 - val_acc: 0.7348
Epoch 57/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3214 - acc: 0.9002 - val_loss: 0.9498 - val_acc: 0.7229
Epoch 58/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3085 - acc: 0.9051 - val_loss: 0.5623 - val_acc: 0.8292
Epoch 59/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.3056 - acc: 0.9064 - val_loss: 0.9083 - val_acc: 0.7462
Epoch 60/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3017 - acc: 0.9069 - val_loss: 0.6753 - val_acc: 0.7982
Epoch 61/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2960 - acc: 0.9097 - val_loss: 0.8200 - val_acc: 0.7688
Epoch 62/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2921 - acc: 0.9085 - val_loss: 0.7007 - val_acc: 0.7875
Epoch 63/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.2870 - acc: 0.9111 - val_loss: 0.5730 - val_acc: 0.8280
Epoch 64/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2868 - acc: 0.9124 - val_loss: 0.6654 - val_acc: 0.8033
Epoch 65/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2802 - acc: 0.9140 - val_loss: 0.9222 - val_acc: 0.7542
Epoch 66/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2723 - acc: 0.9172 - val_loss: 0.7212 - val_acc: 0.7878
Epoch 67/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2724 - acc: 0.9156 - val_loss: 0.5668 - val_acc: 0.8287
Epoch 68/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.2662 - acc: 0.9178 - val_loss: 0.6644 - val_acc: 0.8062
Epoch 69/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2692 - acc: 0.9163 - val_loss: 0.5836 - val_acc: 0.8216
Epoch 70/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2586 - acc: 0.9201 - val_loss: 0.6806 - val_acc: 0.7996
Epoch 71/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2588 - acc: 0.9211 - val_loss: 0.6559 - val_acc: 0.8069
Epoch 72/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2556 - acc: 0.9227 - val_loss: 0.6227 - val_acc: 0.8114
Epoch 73/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2572 - acc: 0.9206 - val_loss: 0.5525 - val_acc: 0.8367
Epoch 74/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2480 - acc: 0.9237 - val_loss: 1.9892 - val_acc: 0.6235
Epoch 75/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2453 - acc: 0.9242 - val_loss: 0.9709 - val_acc: 0.7505
Epoch 76/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2417 - acc: 0.9260 - val_loss: 0.5700 - val_acc: 0.8296
Epoch 77/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2377 - acc: 0.9266 - val_loss: 0.5419 - val_acc: 0.8381
Epoch 78/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.2350 - acc: 0.9288 - val_loss: 0.7219 - val_acc: 0.7956
Epoch 79/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2356 - acc: 0.9276 - val_loss: 0.6147 - val_acc: 0.8211
Epoch 80/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2337 - acc: 0.9287 - val_loss: 0.6259 - val_acc: 0.8096
Epoch 81/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.2274 - acc: 0.9311 - val_loss: 0.5695 - val_acc: 0.8381
Epoch 82/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2224 - acc: 0.9329 - val_loss: 0.5421 - val_acc: 0.8424
Epoch 83/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2269 - acc: 0.9294 - val_loss: 0.8632 - val_acc: 0.7679
Epoch 84/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2149 - acc: 0.9343 - val_loss: 0.6775 - val_acc: 0.8163
Epoch 85/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2183 - acc: 0.9321 - val_loss: 0.6102 - val_acc: 0.8263
Epoch 86/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.2136 - acc: 0.9340 - val_loss: 0.6119 - val_acc: 0.8273
Epoch 87/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2130 - acc: 0.9346 - val_loss: 0.9060 - val_acc: 0.7550
Epoch 88/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2108 - acc: 0.9350 - val_loss: 0.7187 - val_acc: 0.8004
Epoch 89/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2061 - acc: 0.9364 - val_loss: 0.6345 - val_acc: 0.8180
Epoch 90/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2057 - acc: 0.9381 - val_loss: 0.4849 - val_acc: 0.8626
Epoch 91/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.1968 - acc: 0.9413 - val_loss: 0.6472 - val_acc: 0.8304
Epoch 92/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1917 - acc: 0.9424 - val_loss: 0.6683 - val_acc: 0.8133
Epoch 93/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.1934 - acc: 0.9407 - val_loss: 0.7798 - val_acc: 0.7920
Epoch 94/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1913 - acc: 0.9417 - val_loss: 0.7867 - val_acc: 0.7778
Epoch 95/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1907 - acc: 0.9420 - val_loss: 0.6375 - val_acc: 0.8199
Epoch 96/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.1893 - acc: 0.9419 - val_loss: 0.6015 - val_acc: 0.8279
Epoch 97/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1853 - acc: 0.9440 - val_loss: 0.5841 - val_acc: 0.8378
Epoch 98/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.1819 - acc: 0.9442 - val_loss: 0.7618 - val_acc: 0.8002
Epoch 99/100
42000/42000 [==============================] - 2s 46us/sample - loss: 0.1804 - acc: 0.9435 - val_loss: 0.7315 - val_acc: 0.8016
Epoch 100/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1793 - acc: 0.9457 - val_loss: 0.7381 - val_acc: 0.8078
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN with batch normalization&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results5</span> <span class="o">=</span> <span class="n">model5</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results5</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN with batch normalization
--------------------------------------------------------------------------------
60000/60000 [==============================] - 4s 68us/sample - loss: 0.7381 - acc: 0.8078
Validation accuracy: 80.78
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-Adam-optimizers-with-weight-initializers-and-batch-normalization">NN model, relu activations, Adam optimizers with weight initializers and batch normalization<a class="anchor-link" href="#NN-model,-relu-activations,-Adam-optimizers-with-weight-initializers-and-batch-normalization">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model5</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.7504 - acc: 0.7711 - val_loss: 3.2994 - val_acc: 0.3926
Epoch 2/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.5840 - acc: 0.8120 - val_loss: 1.2989 - val_acc: 0.5782
Epoch 3/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.5254 - acc: 0.8286 - val_loss: 1.5073 - val_acc: 0.5588
Epoch 4/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.4785 - acc: 0.8432 - val_loss: 1.4805 - val_acc: 0.5900
Epoch 5/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.4628 - acc: 0.8490 - val_loss: 1.5200 - val_acc: 0.5520
Epoch 6/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.4416 - acc: 0.8556 - val_loss: 1.1569 - val_acc: 0.6578
Epoch 7/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.4216 - acc: 0.8632 - val_loss: 1.1616 - val_acc: 0.6521
Epoch 8/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.3979 - acc: 0.8718 - val_loss: 1.0359 - val_acc: 0.6737
Epoch 9/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.3967 - acc: 0.8716 - val_loss: 1.4157 - val_acc: 0.6081
Epoch 10/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3868 - acc: 0.8749 - val_loss: 1.1907 - val_acc: 0.6233
Epoch 11/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.3657 - acc: 0.8803 - val_loss: 1.0921 - val_acc: 0.6475
Epoch 12/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.3518 - acc: 0.8872 - val_loss: 1.0731 - val_acc: 0.6741
Epoch 13/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3442 - acc: 0.8874 - val_loss: 1.1014 - val_acc: 0.6781
Epoch 14/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.3349 - acc: 0.8899 - val_loss: 1.2347 - val_acc: 0.6433
Epoch 15/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.3198 - acc: 0.8963 - val_loss: 1.0597 - val_acc: 0.6864
Epoch 16/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.3151 - acc: 0.8965 - val_loss: 1.3385 - val_acc: 0.6374
Epoch 17/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.3006 - acc: 0.9024 - val_loss: 1.2399 - val_acc: 0.6477
Epoch 18/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.2937 - acc: 0.9026 - val_loss: 1.7937 - val_acc: 0.6011
Epoch 19/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2807 - acc: 0.9075 - val_loss: 0.8963 - val_acc: 0.7358
Epoch 20/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2783 - acc: 0.9098 - val_loss: 0.9110 - val_acc: 0.7418
Epoch 21/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2730 - acc: 0.9120 - val_loss: 0.9502 - val_acc: 0.7330
Epoch 22/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.2706 - acc: 0.9109 - val_loss: 0.9985 - val_acc: 0.7336
Epoch 23/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2596 - acc: 0.9153 - val_loss: 1.4751 - val_acc: 0.6206
Epoch 24/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2459 - acc: 0.9192 - val_loss: 1.0131 - val_acc: 0.7315
Epoch 25/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2410 - acc: 0.9215 - val_loss: 1.3443 - val_acc: 0.6587
Epoch 26/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2471 - acc: 0.9187 - val_loss: 1.0037 - val_acc: 0.7185
Epoch 27/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2468 - acc: 0.9188 - val_loss: 0.8069 - val_acc: 0.7687
Epoch 28/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2256 - acc: 0.9253 - val_loss: 0.7956 - val_acc: 0.7738
Epoch 29/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.2232 - acc: 0.9268 - val_loss: 0.9224 - val_acc: 0.7399
Epoch 30/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2189 - acc: 0.9274 - val_loss: 0.8176 - val_acc: 0.7669
Epoch 31/100
42000/42000 [==============================] - 2s 53us/sample - loss: 0.2169 - acc: 0.9281 - val_loss: 0.8483 - val_acc: 0.7552
Epoch 32/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2185 - acc: 0.9276 - val_loss: 0.9837 - val_acc: 0.7370
Epoch 33/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.2079 - acc: 0.9323 - val_loss: 0.8542 - val_acc: 0.7669
Epoch 34/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.2026 - acc: 0.9330 - val_loss: 0.9887 - val_acc: 0.7467
Epoch 35/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1968 - acc: 0.9350 - val_loss: 1.0074 - val_acc: 0.7355
Epoch 36/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1947 - acc: 0.9348 - val_loss: 0.8603 - val_acc: 0.7645
Epoch 37/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.1904 - acc: 0.9379 - val_loss: 0.7189 - val_acc: 0.7949
Epoch 38/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1789 - acc: 0.9404 - val_loss: 0.9522 - val_acc: 0.7534
Epoch 39/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1776 - acc: 0.9414 - val_loss: 0.7963 - val_acc: 0.8006
Epoch 40/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1767 - acc: 0.9409 - val_loss: 0.9288 - val_acc: 0.7571
Epoch 41/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1766 - acc: 0.9411 - val_loss: 1.1659 - val_acc: 0.7217
Epoch 42/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1626 - acc: 0.9458 - val_loss: 0.9868 - val_acc: 0.7480
Epoch 43/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.1718 - acc: 0.9429 - val_loss: 0.7413 - val_acc: 0.7992
Epoch 44/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.1626 - acc: 0.9460 - val_loss: 1.3095 - val_acc: 0.6971
Epoch 45/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1561 - acc: 0.9485 - val_loss: 0.8414 - val_acc: 0.7886
Epoch 46/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1580 - acc: 0.9470 - val_loss: 0.7729 - val_acc: 0.8021
Epoch 47/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1604 - acc: 0.9472 - val_loss: 1.3858 - val_acc: 0.7020
Epoch 48/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1538 - acc: 0.9488 - val_loss: 1.4758 - val_acc: 0.6984
Epoch 49/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1425 - acc: 0.9529 - val_loss: 1.3721 - val_acc: 0.7090
Epoch 50/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1504 - acc: 0.9494 - val_loss: 1.0456 - val_acc: 0.7430
Epoch 51/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.1506 - acc: 0.9496 - val_loss: 1.0405 - val_acc: 0.7593
Epoch 52/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1414 - acc: 0.9524 - val_loss: 0.8466 - val_acc: 0.7840
Epoch 53/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1373 - acc: 0.9538 - val_loss: 0.9790 - val_acc: 0.7692
Epoch 54/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1469 - acc: 0.9508 - val_loss: 0.6021 - val_acc: 0.8406
Epoch 55/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1327 - acc: 0.9560 - val_loss: 1.0881 - val_acc: 0.7641
Epoch 56/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1317 - acc: 0.9556 - val_loss: 1.0091 - val_acc: 0.7638
Epoch 57/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1291 - acc: 0.9558 - val_loss: 1.0545 - val_acc: 0.7565
Epoch 58/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1291 - acc: 0.9569 - val_loss: 0.6812 - val_acc: 0.8264
Epoch 59/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1252 - acc: 0.9581 - val_loss: 0.8298 - val_acc: 0.8017
Epoch 60/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.1217 - acc: 0.9590 - val_loss: 1.1110 - val_acc: 0.7636
Epoch 61/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.1219 - acc: 0.9591 - val_loss: 0.8744 - val_acc: 0.7934
Epoch 62/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.1249 - acc: 0.9574 - val_loss: 1.2907 - val_acc: 0.7352
Epoch 63/100
42000/42000 [==============================] - 2s 47us/sample - loss: 0.1188 - acc: 0.9600 - val_loss: 0.9428 - val_acc: 0.7811
Epoch 64/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1189 - acc: 0.9592 - val_loss: 1.0607 - val_acc: 0.7717
Epoch 65/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1173 - acc: 0.9614 - val_loss: 0.8250 - val_acc: 0.8036
Epoch 66/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1102 - acc: 0.9630 - val_loss: 0.8915 - val_acc: 0.7794
Epoch 67/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1150 - acc: 0.9620 - val_loss: 0.8700 - val_acc: 0.7963
Epoch 68/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1051 - acc: 0.9645 - val_loss: 0.8872 - val_acc: 0.7971
Epoch 69/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1120 - acc: 0.9622 - val_loss: 1.2268 - val_acc: 0.7523
Epoch 70/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1117 - acc: 0.9622 - val_loss: 0.8054 - val_acc: 0.8112
Epoch 71/100
42000/42000 [==============================] - 2s 53us/sample - loss: 0.1154 - acc: 0.9614 - val_loss: 0.8851 - val_acc: 0.7975
Epoch 72/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.1071 - acc: 0.9640 - val_loss: 1.2763 - val_acc: 0.7354
Epoch 73/100
42000/42000 [==============================] - 2s 53us/sample - loss: 0.1113 - acc: 0.9617 - val_loss: 1.0526 - val_acc: 0.7878
Epoch 74/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0973 - acc: 0.9672 - val_loss: 0.9450 - val_acc: 0.7733
Epoch 75/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1012 - acc: 0.9657 - val_loss: 1.3132 - val_acc: 0.7354
Epoch 76/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.1073 - acc: 0.9642 - val_loss: 1.2652 - val_acc: 0.7547
Epoch 77/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0974 - acc: 0.9671 - val_loss: 0.6400 - val_acc: 0.8382
Epoch 78/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0929 - acc: 0.9692 - val_loss: 1.3082 - val_acc: 0.7578
Epoch 79/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.0951 - acc: 0.9686 - val_loss: 0.6770 - val_acc: 0.8472
Epoch 80/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.0961 - acc: 0.9680 - val_loss: 0.8655 - val_acc: 0.8092
Epoch 81/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0991 - acc: 0.9665 - val_loss: 0.8122 - val_acc: 0.8212
Epoch 82/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0931 - acc: 0.9688 - val_loss: 0.7419 - val_acc: 0.8227
Epoch 83/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0910 - acc: 0.9695 - val_loss: 1.1053 - val_acc: 0.7612
Epoch 84/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.1015 - acc: 0.9658 - val_loss: 0.8460 - val_acc: 0.8165
Epoch 85/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0871 - acc: 0.9707 - val_loss: 0.8258 - val_acc: 0.8185
Epoch 86/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.0931 - acc: 0.9679 - val_loss: 0.7424 - val_acc: 0.8282
Epoch 87/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0896 - acc: 0.9692 - val_loss: 1.8734 - val_acc: 0.7012
Epoch 88/100
42000/42000 [==============================] - 2s 48us/sample - loss: 0.0949 - acc: 0.9678 - val_loss: 0.9185 - val_acc: 0.7866
Epoch 89/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.0945 - acc: 0.9676 - val_loss: 1.1041 - val_acc: 0.7891
Epoch 90/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0850 - acc: 0.9713 - val_loss: 1.0702 - val_acc: 0.7694
Epoch 91/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0888 - acc: 0.9695 - val_loss: 0.8052 - val_acc: 0.8224
Epoch 92/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0860 - acc: 0.9713 - val_loss: 0.7990 - val_acc: 0.8161
Epoch 93/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0729 - acc: 0.9757 - val_loss: 1.1168 - val_acc: 0.7737
Epoch 94/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0783 - acc: 0.9731 - val_loss: 0.7263 - val_acc: 0.8390
Epoch 95/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0854 - acc: 0.9707 - val_loss: 0.6956 - val_acc: 0.8449
Epoch 96/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0763 - acc: 0.9735 - val_loss: 1.0002 - val_acc: 0.8003
Epoch 97/100
42000/42000 [==============================] - 2s 50us/sample - loss: 0.0863 - acc: 0.9700 - val_loss: 0.9083 - val_acc: 0.8045
Epoch 98/100
42000/42000 [==============================] - 2s 51us/sample - loss: 0.0833 - acc: 0.9722 - val_loss: 1.1478 - val_acc: 0.7791
Epoch 99/100
42000/42000 [==============================] - 2s 49us/sample - loss: 0.0819 - acc: 0.9722 - val_loss: 0.9367 - val_acc: 0.8083
Epoch 100/100
42000/42000 [==============================] - 2s 52us/sample - loss: 0.0795 - acc: 0.9729 - val_loss: 1.1002 - val_acc: 0.7901
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN with batch normalization&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results5</span> <span class="o">=</span> <span class="n">model5</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results5</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN with batch normalization
--------------------------------------------------------------------------------
60000/60000 [==============================] - 4s 68us/sample - loss: 1.1002 - acc: 0.7901
Validation accuracy: 79.01
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o7'></a></p>
<h5 id="Observation-7---Batch-Normalization">Observation 7 - Batch Normalization<a class="anchor-link" href="#Observation-7---Batch-Normalization">&#182;</a></h5><ul>
<li>Batch normalization didn't result in improvement of score.</li>
<li>Relu activations, changing number of activators, Adam optimizers achieved the best score.</li>
<li>Next, let's try batch normalization with dropout.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='Dropout'></a></p>
<h3 id="Dropout">Dropout<a class="anchor-link" href="#Dropout">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="NN-model,-relu-activations,-SGD-optimizers-with-weight-initializers,--batch-normalization-and-dropout">NN model, relu activations, SGD optimizers with weight initializers,  batch normalization and dropout<a class="anchor-link" href="#NN-model,-relu-activations,-SGD-optimizers-with-weight-initializers,--batch-normalization-and-dropout">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with dropout - sgd optimizer&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model6</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="c1"># Input Layer - adding input layer and activation functions relu and weight initializer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">),</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span> 
<span class="c1"># Adding activation function</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="c1"># Adding dropout layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="c1"># Adding dropout layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>

<span class="c1">#Hidden Layer 2 - adding second hidden layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="c1"># Adding dropout layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>

<span class="c1">#Hidden Layer 3 - adding third hidden layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="c1"># Adding dropout layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>

<span class="c1">#Hidden Layer 4 - adding fourth hidden layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding batch normalization</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="c1"># Adding activation function</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="c1"># Adding dropout layer</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_normal&#39;</span><span class="p">,</span><span class="n">bias_initializer</span> <span class="o">=</span> <span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with dropout - sgd optimizer
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model6</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &#34;sequential_5&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_20 (Dense)             (None, 512)               524800    
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048      
_________________________________________________________________
activation_20 (Activation)   (None, 512)               0         
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_21 (Activation)   (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 128)               32896     
_________________________________________________________________
batch_normalization_6 (Batch (None, 128)               512       
_________________________________________________________________
activation_22 (Activation)   (None, 128)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 64)                8256      
_________________________________________________________________
batch_normalization_7 (Batch (None, 64)                256       
_________________________________________________________________
activation_23 (Activation)   (None, 64)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_24 (Dense)             (None, 32)                2080      
_________________________________________________________________
batch_normalization_8 (Batch (None, 32)                128       
_________________________________________________________________
activation_24 (Activation)   (None, 32)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_25 (Dense)             (None, 10)                330       
_________________________________________________________________
activation_25 (Activation)   (None, 10)                0         
=================================================================
Total params: 703,658
Trainable params: 701,674
Non-trainable params: 1,984
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, sgd optimizer</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">model6</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model6</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 3s 71us/sample - loss: 2.6054 - acc: 0.1100 - val_loss: 2.3237 - val_acc: 0.1209
Epoch 2/100
42000/42000 [==============================] - 2s 55us/sample - loss: 2.4142 - acc: 0.1332 - val_loss: 2.2139 - val_acc: 0.2095
Epoch 3/100
42000/42000 [==============================] - 2s 56us/sample - loss: 2.3151 - acc: 0.1548 - val_loss: 2.1209 - val_acc: 0.2677
Epoch 4/100
42000/42000 [==============================] - 2s 56us/sample - loss: 2.2315 - acc: 0.1876 - val_loss: 2.0331 - val_acc: 0.3157
Epoch 5/100
42000/42000 [==============================] - 3s 60us/sample - loss: 2.1531 - acc: 0.2181 - val_loss: 1.9579 - val_acc: 0.3408
Epoch 6/100
42000/42000 [==============================] - 2s 56us/sample - loss: 2.0815 - acc: 0.2495 - val_loss: 1.8626 - val_acc: 0.3965
Epoch 7/100
42000/42000 [==============================] - 2s 56us/sample - loss: 2.0079 - acc: 0.2789 - val_loss: 1.7922 - val_acc: 0.4313
Epoch 8/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.9351 - acc: 0.3115 - val_loss: 1.7376 - val_acc: 0.4426
Epoch 9/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.8709 - acc: 0.3382 - val_loss: 1.6199 - val_acc: 0.4975
Epoch 10/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.8116 - acc: 0.3619 - val_loss: 1.5512 - val_acc: 0.5238
Epoch 11/100
42000/42000 [==============================] - 2s 54us/sample - loss: 1.7518 - acc: 0.3841 - val_loss: 1.4736 - val_acc: 0.5408
Epoch 12/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.7028 - acc: 0.4066 - val_loss: 1.3984 - val_acc: 0.5655
Epoch 13/100
42000/42000 [==============================] - 2s 59us/sample - loss: 1.6439 - acc: 0.4270 - val_loss: 1.3576 - val_acc: 0.5828
Epoch 14/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.5967 - acc: 0.4430 - val_loss: 1.3111 - val_acc: 0.5965
Epoch 15/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.5617 - acc: 0.4607 - val_loss: 1.2542 - val_acc: 0.6111
Epoch 16/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.5186 - acc: 0.4753 - val_loss: 1.2091 - val_acc: 0.6265
Epoch 17/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.4842 - acc: 0.4868 - val_loss: 1.1793 - val_acc: 0.6374
Epoch 18/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.4473 - acc: 0.5011 - val_loss: 1.1519 - val_acc: 0.6433
Epoch 19/100
42000/42000 [==============================] - 2s 54us/sample - loss: 1.4101 - acc: 0.5162 - val_loss: 1.1057 - val_acc: 0.6606
Epoch 20/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.3852 - acc: 0.5309 - val_loss: 1.0990 - val_acc: 0.6641
Epoch 21/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.3534 - acc: 0.5418 - val_loss: 1.0614 - val_acc: 0.6762
Epoch 22/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.3285 - acc: 0.5496 - val_loss: 1.0304 - val_acc: 0.6890
Epoch 23/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.2992 - acc: 0.5609 - val_loss: 1.0085 - val_acc: 0.6887
Epoch 24/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.2786 - acc: 0.5706 - val_loss: 0.9750 - val_acc: 0.7053
Epoch 25/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.2606 - acc: 0.5766 - val_loss: 0.9636 - val_acc: 0.7069
Epoch 26/100
42000/42000 [==============================] - 2s 58us/sample - loss: 1.2394 - acc: 0.5840 - val_loss: 0.9422 - val_acc: 0.7091
Epoch 27/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.2132 - acc: 0.5979 - val_loss: 0.9353 - val_acc: 0.7169
Epoch 28/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.1932 - acc: 0.6047 - val_loss: 0.9152 - val_acc: 0.7215
Epoch 29/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.1793 - acc: 0.6109 - val_loss: 0.8742 - val_acc: 0.7368
Epoch 30/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.1572 - acc: 0.6158 - val_loss: 0.9592 - val_acc: 0.7013
Epoch 31/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.1357 - acc: 0.6254 - val_loss: 0.8361 - val_acc: 0.7450
Epoch 32/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.1246 - acc: 0.6317 - val_loss: 0.8718 - val_acc: 0.7318
Epoch 33/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.1089 - acc: 0.6334 - val_loss: 0.8291 - val_acc: 0.7463
Epoch 34/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.0959 - acc: 0.6414 - val_loss: 0.8557 - val_acc: 0.7293
Epoch 35/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.0835 - acc: 0.6456 - val_loss: 0.8170 - val_acc: 0.7472
Epoch 36/100
42000/42000 [==============================] - 2s 56us/sample - loss: 1.0635 - acc: 0.6545 - val_loss: 0.8103 - val_acc: 0.7564
Epoch 37/100
42000/42000 [==============================] - 2s 55us/sample - loss: 1.0554 - acc: 0.6572 - val_loss: 0.7692 - val_acc: 0.7686
Epoch 38/100
42000/42000 [==============================] - 3s 63us/sample - loss: 1.0389 - acc: 0.6655 - val_loss: 0.7873 - val_acc: 0.7632
Epoch 39/100
42000/42000 [==============================] - 3s 60us/sample - loss: 1.0189 - acc: 0.6723 - val_loss: 0.7743 - val_acc: 0.7618
Epoch 40/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.0079 - acc: 0.6775 - val_loss: 0.7309 - val_acc: 0.7797
Epoch 41/100
42000/42000 [==============================] - 2s 57us/sample - loss: 1.0044 - acc: 0.6761 - val_loss: 0.7411 - val_acc: 0.7771
Epoch 42/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.9949 - acc: 0.6807 - val_loss: 0.7256 - val_acc: 0.7826
Epoch 43/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.9799 - acc: 0.6888 - val_loss: 0.7309 - val_acc: 0.7801
Epoch 44/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.9662 - acc: 0.6906 - val_loss: 0.7218 - val_acc: 0.7818
Epoch 45/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.9578 - acc: 0.6942 - val_loss: 0.6908 - val_acc: 0.7904
Epoch 46/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.9417 - acc: 0.7012 - val_loss: 0.7344 - val_acc: 0.7721
Epoch 47/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.9413 - acc: 0.6993 - val_loss: 0.7060 - val_acc: 0.7821
Epoch 48/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.9270 - acc: 0.7054 - val_loss: 0.7181 - val_acc: 0.7824
Epoch 49/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.9109 - acc: 0.7130 - val_loss: 0.6612 - val_acc: 0.7988
Epoch 50/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.9078 - acc: 0.7140 - val_loss: 0.6873 - val_acc: 0.7903
Epoch 51/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.8992 - acc: 0.7155 - val_loss: 0.6665 - val_acc: 0.8009
Epoch 52/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.8844 - acc: 0.7209 - val_loss: 0.6310 - val_acc: 0.8111
Epoch 53/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.8843 - acc: 0.7214 - val_loss: 0.6561 - val_acc: 0.7992
Epoch 54/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.8734 - acc: 0.7273 - val_loss: 0.6311 - val_acc: 0.8083
Epoch 55/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.8673 - acc: 0.7281 - val_loss: 0.6193 - val_acc: 0.8108
Epoch 56/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.8486 - acc: 0.7355 - val_loss: 0.6420 - val_acc: 0.8012
Epoch 57/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.8503 - acc: 0.7352 - val_loss: 0.6994 - val_acc: 0.7861
Epoch 58/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.8442 - acc: 0.7357 - val_loss: 0.5837 - val_acc: 0.8247
Epoch 59/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.8391 - acc: 0.7389 - val_loss: 0.6363 - val_acc: 0.8028
Epoch 60/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.8335 - acc: 0.7413 - val_loss: 0.5961 - val_acc: 0.8199
Epoch 61/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.8294 - acc: 0.7413 - val_loss: 0.5941 - val_acc: 0.8199
Epoch 62/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.8155 - acc: 0.7469 - val_loss: 0.6761 - val_acc: 0.7928
Epoch 63/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.8109 - acc: 0.7496 - val_loss: 0.6227 - val_acc: 0.8094
Epoch 64/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.8007 - acc: 0.7499 - val_loss: 0.6400 - val_acc: 0.8033
Epoch 65/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.8021 - acc: 0.7507 - val_loss: 0.5850 - val_acc: 0.8219
Epoch 66/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.7899 - acc: 0.7548 - val_loss: 0.5739 - val_acc: 0.8261
Epoch 67/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.7775 - acc: 0.7590 - val_loss: 0.6175 - val_acc: 0.8099
Epoch 68/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.7847 - acc: 0.7580 - val_loss: 0.5935 - val_acc: 0.8196
Epoch 69/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.7709 - acc: 0.7607 - val_loss: 0.7921 - val_acc: 0.7597
Epoch 70/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.7697 - acc: 0.7607 - val_loss: 0.5952 - val_acc: 0.8155
Epoch 71/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.7648 - acc: 0.7630 - val_loss: 0.5414 - val_acc: 0.8394
Epoch 72/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.7613 - acc: 0.7660 - val_loss: 0.5473 - val_acc: 0.8335
Epoch 73/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.7515 - acc: 0.7674 - val_loss: 0.5540 - val_acc: 0.8316
Epoch 74/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.7506 - acc: 0.7693 - val_loss: 0.5334 - val_acc: 0.8379
Epoch 75/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.7394 - acc: 0.7717 - val_loss: 0.5623 - val_acc: 0.8301
Epoch 76/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.7449 - acc: 0.7692 - val_loss: 0.5112 - val_acc: 0.8475
Epoch 77/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.7367 - acc: 0.7758 - val_loss: 0.5499 - val_acc: 0.8302
Epoch 78/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.7347 - acc: 0.7757 - val_loss: 0.5693 - val_acc: 0.8232
Epoch 79/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.7263 - acc: 0.7772 - val_loss: 0.6090 - val_acc: 0.8162
Epoch 80/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.7270 - acc: 0.7768 - val_loss: 0.6102 - val_acc: 0.8118
Epoch 81/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.7203 - acc: 0.7798 - val_loss: 0.5505 - val_acc: 0.8335
Epoch 82/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.7166 - acc: 0.7812 - val_loss: 0.5441 - val_acc: 0.8350
Epoch 83/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.7112 - acc: 0.7829 - val_loss: 0.5885 - val_acc: 0.8156
Epoch 84/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.7027 - acc: 0.7845 - val_loss: 0.5343 - val_acc: 0.8360
Epoch 85/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.6959 - acc: 0.7876 - val_loss: 0.5293 - val_acc: 0.8361
Epoch 86/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.6922 - acc: 0.7890 - val_loss: 0.5124 - val_acc: 0.8444
Epoch 87/100
42000/42000 [==============================] - 2s 53us/sample - loss: 0.6874 - acc: 0.7903 - val_loss: 0.5271 - val_acc: 0.8380
Epoch 88/100
42000/42000 [==============================] - 2s 53us/sample - loss: 0.6906 - acc: 0.7891 - val_loss: 0.5241 - val_acc: 0.8409
Epoch 89/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.6743 - acc: 0.7943 - val_loss: 0.5262 - val_acc: 0.8401
Epoch 90/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.6803 - acc: 0.7909 - val_loss: 0.5525 - val_acc: 0.8313
Epoch 91/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.6779 - acc: 0.7928 - val_loss: 0.5164 - val_acc: 0.8436
Epoch 92/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.6767 - acc: 0.7927 - val_loss: 0.4986 - val_acc: 0.8492
Epoch 93/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.6632 - acc: 0.7985 - val_loss: 0.5105 - val_acc: 0.8431
Epoch 94/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.6640 - acc: 0.7991 - val_loss: 0.4897 - val_acc: 0.8518
Epoch 95/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.6698 - acc: 0.7959 - val_loss: 0.5073 - val_acc: 0.8418
Epoch 96/100
42000/42000 [==============================] - 2s 54us/sample - loss: 0.6591 - acc: 0.8000 - val_loss: 0.6676 - val_acc: 0.7981
Epoch 97/100
42000/42000 [==============================] - 2s 55us/sample - loss: 0.6608 - acc: 0.7998 - val_loss: 0.6813 - val_acc: 0.7984
Epoch 98/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.6470 - acc: 0.8018 - val_loss: 0.4924 - val_acc: 0.8505
Epoch 99/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.6573 - acc: 0.8001 - val_loss: 0.5130 - val_acc: 0.8419
Epoch 100/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.6478 - acc: 0.8029 - val_loss: 0.4758 - val_acc: 0.8560
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with dropout - sgd optimizer&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results6</span> <span class="o">=</span> <span class="n">model6</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with dropout - sgd optimizer
--------------------------------------------------------------------------------
60000/60000 [==============================] - 4s 73us/sample - loss: 0.4758 - acc: 0.8560
Validation accuracy: 85.6
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">model6</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model6</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 3s 75us/sample - loss: 1.0483 - acc: 0.6722 - val_loss: 1.5585 - val_acc: 0.4775
Epoch 2/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.9086 - acc: 0.7194 - val_loss: 1.3776 - val_acc: 0.5337
Epoch 3/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.8480 - acc: 0.7403 - val_loss: 1.0837 - val_acc: 0.6561
Epoch 4/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.7984 - acc: 0.7575 - val_loss: 1.1266 - val_acc: 0.6141
Epoch 5/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.7714 - acc: 0.7648 - val_loss: 1.2182 - val_acc: 0.5853
Epoch 6/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.7336 - acc: 0.7772 - val_loss: 1.0197 - val_acc: 0.6763
Epoch 7/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.7149 - acc: 0.7826 - val_loss: 1.1113 - val_acc: 0.6252
Epoch 8/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.6941 - acc: 0.7898 - val_loss: 0.9268 - val_acc: 0.7488
Epoch 9/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.6799 - acc: 0.7955 - val_loss: 1.3377 - val_acc: 0.5425
Epoch 10/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.6518 - acc: 0.8032 - val_loss: 0.8574 - val_acc: 0.7210
Epoch 11/100
42000/42000 [==============================] - 3s 63us/sample - loss: 0.6379 - acc: 0.8080 - val_loss: 1.2970 - val_acc: 0.5655
Epoch 12/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.6319 - acc: 0.8079 - val_loss: 0.9649 - val_acc: 0.7167
Epoch 13/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.6119 - acc: 0.8154 - val_loss: 1.2310 - val_acc: 0.5864
Epoch 14/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.6004 - acc: 0.8187 - val_loss: 0.8527 - val_acc: 0.7557
Epoch 15/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.5864 - acc: 0.8228 - val_loss: 1.2250 - val_acc: 0.5955
Epoch 16/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.5891 - acc: 0.8222 - val_loss: 0.9921 - val_acc: 0.6742
Epoch 17/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.5695 - acc: 0.8276 - val_loss: 1.0117 - val_acc: 0.6686
Epoch 18/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.5593 - acc: 0.8319 - val_loss: 0.8131 - val_acc: 0.7855
Epoch 19/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.5542 - acc: 0.8344 - val_loss: 1.1605 - val_acc: 0.6218
Epoch 20/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.5464 - acc: 0.8354 - val_loss: 0.9370 - val_acc: 0.6977
Epoch 21/100
42000/42000 [==============================] - 3s 63us/sample - loss: 0.5382 - acc: 0.8398 - val_loss: 0.7988 - val_acc: 0.7521
Epoch 22/100
42000/42000 [==============================] - 3s 61us/sample - loss: 0.5289 - acc: 0.8412 - val_loss: 0.9359 - val_acc: 0.6881
Epoch 23/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.5178 - acc: 0.8447 - val_loss: 0.8229 - val_acc: 0.7292
Epoch 24/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.5133 - acc: 0.8455 - val_loss: 1.0570 - val_acc: 0.6738
Epoch 25/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.5046 - acc: 0.8481 - val_loss: 0.7736 - val_acc: 0.7540
Epoch 26/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.5038 - acc: 0.8490 - val_loss: 0.8040 - val_acc: 0.7357
Epoch 27/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.4964 - acc: 0.8505 - val_loss: 1.0628 - val_acc: 0.6397
Epoch 28/100
42000/42000 [==============================] - 3s 64us/sample - loss: 0.4956 - acc: 0.8516 - val_loss: 1.0051 - val_acc: 0.6658
Epoch 29/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.4762 - acc: 0.8577 - val_loss: 0.9671 - val_acc: 0.6847
Epoch 30/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.4803 - acc: 0.8545 - val_loss: 0.9152 - val_acc: 0.7100
Epoch 31/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.4699 - acc: 0.8582 - val_loss: 0.7210 - val_acc: 0.7599
Epoch 32/100
42000/42000 [==============================] - 3s 61us/sample - loss: 0.4675 - acc: 0.8602 - val_loss: 0.7587 - val_acc: 0.7574
Epoch 33/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4615 - acc: 0.8604 - val_loss: 0.7750 - val_acc: 0.7526
Epoch 34/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.4583 - acc: 0.8603 - val_loss: 0.8713 - val_acc: 0.7247
Epoch 35/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.4579 - acc: 0.8632 - val_loss: 0.7976 - val_acc: 0.7362
Epoch 36/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.4483 - acc: 0.8645 - val_loss: 0.7683 - val_acc: 0.7563
Epoch 37/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4392 - acc: 0.8675 - val_loss: 0.7715 - val_acc: 0.7536
Epoch 38/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.4412 - acc: 0.8669 - val_loss: 0.8139 - val_acc: 0.7285
Epoch 39/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4326 - acc: 0.8701 - val_loss: 0.6890 - val_acc: 0.7885
Epoch 40/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4206 - acc: 0.8730 - val_loss: 0.8502 - val_acc: 0.7258
Epoch 41/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4262 - acc: 0.8727 - val_loss: 0.6450 - val_acc: 0.7916
Epoch 42/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4188 - acc: 0.8747 - val_loss: 0.5895 - val_acc: 0.8100
Epoch 43/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4113 - acc: 0.8745 - val_loss: 0.7252 - val_acc: 0.7735
Epoch 44/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.4156 - acc: 0.8732 - val_loss: 1.1334 - val_acc: 0.6520
Epoch 45/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.4083 - acc: 0.8765 - val_loss: 0.6479 - val_acc: 0.7949
Epoch 46/100
42000/42000 [==============================] - 3s 61us/sample - loss: 0.4091 - acc: 0.8773 - val_loss: 0.7718 - val_acc: 0.7485
Epoch 47/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.4042 - acc: 0.8782 - val_loss: 0.7290 - val_acc: 0.7611
Epoch 48/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3953 - acc: 0.8811 - val_loss: 0.6882 - val_acc: 0.7742
Epoch 49/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3882 - acc: 0.8829 - val_loss: 0.8469 - val_acc: 0.7211
Epoch 50/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.3840 - acc: 0.8865 - val_loss: 0.6448 - val_acc: 0.7923
Epoch 51/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.3824 - acc: 0.8846 - val_loss: 0.7429 - val_acc: 0.7559
Epoch 52/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.3770 - acc: 0.8862 - val_loss: 0.6541 - val_acc: 0.7947
Epoch 53/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.3806 - acc: 0.8847 - val_loss: 0.7222 - val_acc: 0.7739
Epoch 54/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3762 - acc: 0.8865 - val_loss: 0.6802 - val_acc: 0.7789
Epoch 55/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3678 - acc: 0.8901 - val_loss: 0.5836 - val_acc: 0.8153
Epoch 56/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.3635 - acc: 0.8897 - val_loss: 0.7012 - val_acc: 0.7723
Epoch 57/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.3637 - acc: 0.8902 - val_loss: 0.5000 - val_acc: 0.8412
Epoch 58/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.3613 - acc: 0.8913 - val_loss: 0.7912 - val_acc: 0.7452
Epoch 59/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3617 - acc: 0.8900 - val_loss: 0.7234 - val_acc: 0.7732
Epoch 60/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.3663 - acc: 0.8914 - val_loss: 0.7428 - val_acc: 0.7548
Epoch 61/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3541 - acc: 0.8931 - val_loss: 0.4835 - val_acc: 0.8514
Epoch 62/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.3497 - acc: 0.8946 - val_loss: 0.9309 - val_acc: 0.7019
Epoch 63/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3509 - acc: 0.8935 - val_loss: 0.6272 - val_acc: 0.8097
Epoch 64/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.3499 - acc: 0.8937 - val_loss: 0.6166 - val_acc: 0.8006
Epoch 65/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.3408 - acc: 0.8973 - val_loss: 0.5850 - val_acc: 0.8120
Epoch 66/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.3443 - acc: 0.8963 - val_loss: 0.5576 - val_acc: 0.8225
Epoch 67/100
42000/42000 [==============================] - 3s 61us/sample - loss: 0.3357 - acc: 0.8967 - val_loss: 0.5877 - val_acc: 0.8114
Epoch 68/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3436 - acc: 0.8964 - val_loss: 0.8347 - val_acc: 0.7368
Epoch 69/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.3296 - acc: 0.8996 - val_loss: 0.5776 - val_acc: 0.8166
Epoch 70/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.3298 - acc: 0.9002 - val_loss: 0.7237 - val_acc: 0.7641
Epoch 71/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.3314 - acc: 0.8998 - val_loss: 0.7168 - val_acc: 0.7644
Epoch 72/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3229 - acc: 0.9024 - val_loss: 0.6814 - val_acc: 0.7736
Epoch 73/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.3281 - acc: 0.8997 - val_loss: 0.5008 - val_acc: 0.8452
Epoch 74/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.3208 - acc: 0.9037 - val_loss: 0.5365 - val_acc: 0.8301
Epoch 75/100
42000/42000 [==============================] - 3s 61us/sample - loss: 0.3230 - acc: 0.9022 - val_loss: 0.6199 - val_acc: 0.8008
Epoch 76/100
42000/42000 [==============================] - 3s 65us/sample - loss: 0.3145 - acc: 0.9044 - val_loss: 0.5949 - val_acc: 0.8097
Epoch 77/100
42000/42000 [==============================] - 3s 61us/sample - loss: 0.3178 - acc: 0.9046 - val_loss: 0.6488 - val_acc: 0.7916
Epoch 78/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3136 - acc: 0.9048 - val_loss: 0.5016 - val_acc: 0.8428
Epoch 79/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.3124 - acc: 0.9065 - val_loss: 0.6061 - val_acc: 0.8069
Epoch 80/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3083 - acc: 0.9069 - val_loss: 0.5600 - val_acc: 0.8191
Epoch 81/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3097 - acc: 0.9063 - val_loss: 0.5729 - val_acc: 0.8153
Epoch 82/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.3036 - acc: 0.9097 - val_loss: 0.4584 - val_acc: 0.8562
Epoch 83/100
42000/42000 [==============================] - 3s 62us/sample - loss: 0.3066 - acc: 0.9073 - val_loss: 0.5082 - val_acc: 0.8383
Epoch 84/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.2970 - acc: 0.9109 - val_loss: 0.7692 - val_acc: 0.7568
Epoch 85/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.3044 - acc: 0.9073 - val_loss: 0.6092 - val_acc: 0.8047
Epoch 86/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.2958 - acc: 0.9103 - val_loss: 0.4906 - val_acc: 0.8454
Epoch 87/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.2953 - acc: 0.9108 - val_loss: 0.4721 - val_acc: 0.8436
Epoch 88/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.2943 - acc: 0.9105 - val_loss: 0.6549 - val_acc: 0.7836
Epoch 89/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.2943 - acc: 0.9100 - val_loss: 0.6813 - val_acc: 0.7893
Epoch 90/100
42000/42000 [==============================] - 2s 56us/sample - loss: 0.2928 - acc: 0.9110 - val_loss: 0.7207 - val_acc: 0.7628
Epoch 91/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.2925 - acc: 0.9115 - val_loss: 0.8072 - val_acc: 0.7591
Epoch 92/100
42000/42000 [==============================] - 2s 58us/sample - loss: 0.2900 - acc: 0.9117 - val_loss: 0.8668 - val_acc: 0.7243
Epoch 93/100
42000/42000 [==============================] - 3s 63us/sample - loss: 0.2853 - acc: 0.9132 - val_loss: 0.5118 - val_acc: 0.8381
Epoch 94/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.2833 - acc: 0.9132 - val_loss: 0.6805 - val_acc: 0.7838
Epoch 95/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.2863 - acc: 0.9134 - val_loss: 0.5222 - val_acc: 0.8342
Epoch 96/100
42000/42000 [==============================] - 2s 59us/sample - loss: 0.2776 - acc: 0.9172 - val_loss: 0.6173 - val_acc: 0.7970
Epoch 97/100
42000/42000 [==============================] - 2s 57us/sample - loss: 0.2856 - acc: 0.9139 - val_loss: 0.4914 - val_acc: 0.8441
Epoch 98/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.2740 - acc: 0.9163 - val_loss: 0.4306 - val_acc: 0.8653
Epoch 99/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.2711 - acc: 0.9185 - val_loss: 0.6014 - val_acc: 0.8122
Epoch 100/100
42000/42000 [==============================] - 3s 60us/sample - loss: 0.2757 - acc: 0.9154 - val_loss: 0.5253 - val_acc: 0.8297
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with dropout - adam optimizer&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results6</span> <span class="o">=</span> <span class="n">model6</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results6</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with dropout - adam optimizer
--------------------------------------------------------------------------------
60000/60000 [==============================] - 4s 72us/sample - loss: 0.5253 - acc: 0.8297
Validation accuracy: 82.97
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='o8'></a></p>
<h5 id="Observation-8---Batch-Normalization-and-Dropout">Observation 8 - Batch Normalization and Dropout<a class="anchor-link" href="#Observation-8---Batch-Normalization-and-Dropout">&#182;</a></h5><ul>
<li>Didn't result in any improvement of score.</li>
<li>NN model, relu activations, SGD optimizers with weight initializers and batch normalization is still the best model.</li>
<li>Next, let's try batch normalization and dropout with adam optimizer.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='Prediction'></a></p>
<h3 id="Prediction-on-test-dataset-using-Model-3---relu-activations,-Adam-optimizers">Prediction on test dataset using Model 3 - relu activations, Adam optimizers<a class="anchor-link" href="#Prediction-on-test-dataset-using-Model-3---relu-activations,-Adam-optimizers">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN model with relu activations and changing number of activators&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="c1"># Initialize the neural network classifier</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Input Layer - adding input layer and activation functions relu</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="p">)))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 1 - adding first hidden layer</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1">#Hidden Layer 2 - Adding second hidden layer</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
<span class="c1"># Adding activation function</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Output Layer - adding output layer which is of 10 nodes (digits)</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># Adding activation function - softmax for multiclass classification</span>
<span class="n">model3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN model with relu activations and changing number of activators
--------------------------------------------------------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># compiling the neural network classifier, adam optimizer</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">model3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fitting the neural network for training</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 42000 samples, validate on 60000 samples
Epoch 1/100
42000/42000 [==============================] - 2s 39us/sample - loss: 2.2450 - acc: 0.1494 - val_loss: 1.9481 - val_acc: 0.3398
Epoch 2/100
42000/42000 [==============================] - 1s 30us/sample - loss: 1.5502 - acc: 0.4844 - val_loss: 1.3632 - val_acc: 0.5493
Epoch 3/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.2826 - acc: 0.5840 - val_loss: 1.1971 - val_acc: 0.6190
Epoch 4/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.1456 - acc: 0.6382 - val_loss: 1.0864 - val_acc: 0.6639
Epoch 5/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0588 - acc: 0.6704 - val_loss: 1.0618 - val_acc: 0.6653
Epoch 6/100
42000/42000 [==============================] - 1s 29us/sample - loss: 1.0035 - acc: 0.6882 - val_loss: 0.9490 - val_acc: 0.7054
Epoch 7/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.9524 - acc: 0.7060 - val_loss: 0.9711 - val_acc: 0.7005
Epoch 8/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.9115 - acc: 0.7183 - val_loss: 0.8688 - val_acc: 0.7336
Epoch 9/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.8822 - acc: 0.7289 - val_loss: 0.8723 - val_acc: 0.7294
Epoch 10/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.8557 - acc: 0.7358 - val_loss: 0.8526 - val_acc: 0.7390
Epoch 11/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.8294 - acc: 0.7449 - val_loss: 0.8516 - val_acc: 0.7340
Epoch 12/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.8123 - acc: 0.7475 - val_loss: 0.7854 - val_acc: 0.7562
Epoch 13/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.7956 - acc: 0.7556 - val_loss: 0.8098 - val_acc: 0.7527
Epoch 14/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7827 - acc: 0.7574 - val_loss: 0.7563 - val_acc: 0.7686
Epoch 15/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7541 - acc: 0.7695 - val_loss: 0.7475 - val_acc: 0.7719
Epoch 16/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7410 - acc: 0.7709 - val_loss: 0.7352 - val_acc: 0.7752
Epoch 17/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.7287 - acc: 0.7764 - val_loss: 0.7410 - val_acc: 0.7713
Epoch 18/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7150 - acc: 0.7795 - val_loss: 0.7157 - val_acc: 0.7821
Epoch 19/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.7025 - acc: 0.7840 - val_loss: 0.7085 - val_acc: 0.7825
Epoch 20/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6890 - acc: 0.7884 - val_loss: 0.7198 - val_acc: 0.7801
Epoch 21/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6722 - acc: 0.7940 - val_loss: 0.7024 - val_acc: 0.7853
Epoch 22/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.6632 - acc: 0.7958 - val_loss: 0.7599 - val_acc: 0.7661
Epoch 23/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6577 - acc: 0.7969 - val_loss: 0.6656 - val_acc: 0.7979
Epoch 24/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6323 - acc: 0.8049 - val_loss: 0.6612 - val_acc: 0.7972
Epoch 25/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6246 - acc: 0.8080 - val_loss: 0.6253 - val_acc: 0.8116
Epoch 26/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.6241 - acc: 0.8078 - val_loss: 0.6045 - val_acc: 0.8176
Epoch 27/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.6085 - acc: 0.8138 - val_loss: 0.6033 - val_acc: 0.8179
Epoch 28/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5945 - acc: 0.8184 - val_loss: 0.5880 - val_acc: 0.8226
Epoch 29/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.5854 - acc: 0.8206 - val_loss: 0.5891 - val_acc: 0.8232
Epoch 30/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5819 - acc: 0.8211 - val_loss: 0.5972 - val_acc: 0.8191
Epoch 31/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5704 - acc: 0.8244 - val_loss: 0.5885 - val_acc: 0.8224
Epoch 32/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.5728 - acc: 0.8236 - val_loss: 0.5906 - val_acc: 0.8203
Epoch 33/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5547 - acc: 0.8282 - val_loss: 0.5743 - val_acc: 0.8260
Epoch 34/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.5482 - acc: 0.8301 - val_loss: 0.5979 - val_acc: 0.8173
Epoch 35/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.5397 - acc: 0.8349 - val_loss: 0.5557 - val_acc: 0.8319
Epoch 36/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5328 - acc: 0.8364 - val_loss: 0.5550 - val_acc: 0.8320
Epoch 37/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5315 - acc: 0.8366 - val_loss: 0.5342 - val_acc: 0.8388
Epoch 38/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5190 - acc: 0.8395 - val_loss: 0.5484 - val_acc: 0.8354
Epoch 39/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.5133 - acc: 0.8424 - val_loss: 0.5546 - val_acc: 0.8307
Epoch 40/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5245 - acc: 0.8354 - val_loss: 0.5637 - val_acc: 0.8249
Epoch 41/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.5054 - acc: 0.8429 - val_loss: 0.5232 - val_acc: 0.8415
Epoch 42/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.5053 - acc: 0.8436 - val_loss: 0.5410 - val_acc: 0.8354
Epoch 43/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.5047 - acc: 0.8423 - val_loss: 0.5490 - val_acc: 0.8328
Epoch 44/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4911 - acc: 0.8472 - val_loss: 0.5196 - val_acc: 0.8423
Epoch 45/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4943 - acc: 0.8452 - val_loss: 0.5047 - val_acc: 0.8465
Epoch 46/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4728 - acc: 0.8534 - val_loss: 0.5193 - val_acc: 0.8446
Epoch 47/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4728 - acc: 0.8541 - val_loss: 0.5411 - val_acc: 0.8332
Epoch 48/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4783 - acc: 0.8500 - val_loss: 0.5254 - val_acc: 0.8409
Epoch 49/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4661 - acc: 0.8535 - val_loss: 0.4862 - val_acc: 0.8540
Epoch 50/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4548 - acc: 0.8591 - val_loss: 0.4810 - val_acc: 0.8564
Epoch 51/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4544 - acc: 0.8582 - val_loss: 0.5049 - val_acc: 0.8487
Epoch 52/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4551 - acc: 0.8577 - val_loss: 0.4743 - val_acc: 0.8570
Epoch 53/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4540 - acc: 0.8572 - val_loss: 0.4703 - val_acc: 0.8590
Epoch 54/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4449 - acc: 0.8603 - val_loss: 0.5001 - val_acc: 0.8488
Epoch 55/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4390 - acc: 0.8627 - val_loss: 0.4796 - val_acc: 0.8548
Epoch 56/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4353 - acc: 0.8651 - val_loss: 0.4902 - val_acc: 0.8526
Epoch 57/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4404 - acc: 0.8614 - val_loss: 0.5234 - val_acc: 0.8398
Epoch 58/100
42000/42000 [==============================] - 1s 33us/sample - loss: 0.4391 - acc: 0.8615 - val_loss: 0.4935 - val_acc: 0.8507
Epoch 59/100
42000/42000 [==============================] - 1s 31us/sample - loss: 0.4318 - acc: 0.8632 - val_loss: 0.4953 - val_acc: 0.8497
Epoch 60/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4265 - acc: 0.8662 - val_loss: 0.5158 - val_acc: 0.8422
Epoch 61/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4205 - acc: 0.8655 - val_loss: 0.5047 - val_acc: 0.8468
Epoch 62/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.4207 - acc: 0.8683 - val_loss: 0.4942 - val_acc: 0.8505
Epoch 63/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4136 - acc: 0.8702 - val_loss: 0.4649 - val_acc: 0.8625
Epoch 64/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4127 - acc: 0.8694 - val_loss: 0.4480 - val_acc: 0.8663
Epoch 65/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4169 - acc: 0.8680 - val_loss: 0.4424 - val_acc: 0.8684
Epoch 66/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4004 - acc: 0.8735 - val_loss: 0.4501 - val_acc: 0.8655
Epoch 67/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4046 - acc: 0.8707 - val_loss: 0.4404 - val_acc: 0.8692
Epoch 68/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4078 - acc: 0.8700 - val_loss: 0.4328 - val_acc: 0.8717
Epoch 69/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.4011 - acc: 0.8722 - val_loss: 0.4715 - val_acc: 0.8596
Epoch 70/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3974 - acc: 0.8742 - val_loss: 0.4439 - val_acc: 0.8680
Epoch 71/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3904 - acc: 0.8752 - val_loss: 0.4707 - val_acc: 0.8602
Epoch 72/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3903 - acc: 0.8760 - val_loss: 0.4233 - val_acc: 0.8751
Epoch 73/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3848 - acc: 0.8788 - val_loss: 0.4433 - val_acc: 0.8659
Epoch 74/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3820 - acc: 0.8785 - val_loss: 0.4359 - val_acc: 0.8703
Epoch 75/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3744 - acc: 0.8806 - val_loss: 0.4497 - val_acc: 0.8642
Epoch 76/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3889 - acc: 0.8754 - val_loss: 0.4522 - val_acc: 0.8640
Epoch 77/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.3780 - acc: 0.8807 - val_loss: 0.5019 - val_acc: 0.8474
Epoch 78/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3741 - acc: 0.8813 - val_loss: 0.4329 - val_acc: 0.8713
Epoch 79/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3686 - acc: 0.8828 - val_loss: 0.4347 - val_acc: 0.8714
Epoch 80/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.3624 - acc: 0.8852 - val_loss: 0.4339 - val_acc: 0.8716
Epoch 81/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3730 - acc: 0.8813 - val_loss: 0.4617 - val_acc: 0.8615
Epoch 82/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3621 - acc: 0.8837 - val_loss: 0.4089 - val_acc: 0.8799
Epoch 83/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3633 - acc: 0.8843 - val_loss: 0.4048 - val_acc: 0.8813
Epoch 84/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3598 - acc: 0.8852 - val_loss: 0.4693 - val_acc: 0.8583
Epoch 85/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3580 - acc: 0.8858 - val_loss: 0.4362 - val_acc: 0.8702
Epoch 86/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3572 - acc: 0.8849 - val_loss: 0.4603 - val_acc: 0.8621
Epoch 87/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3524 - acc: 0.8885 - val_loss: 0.4158 - val_acc: 0.8780
Epoch 88/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3495 - acc: 0.8895 - val_loss: 0.4046 - val_acc: 0.8816
Epoch 89/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3430 - acc: 0.8909 - val_loss: 0.4195 - val_acc: 0.8769
Epoch 90/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3433 - acc: 0.8904 - val_loss: 0.4739 - val_acc: 0.8565
Epoch 91/100
42000/42000 [==============================] - 1s 32us/sample - loss: 0.3410 - acc: 0.8909 - val_loss: 0.4222 - val_acc: 0.8758
Epoch 92/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3433 - acc: 0.8912 - val_loss: 0.4033 - val_acc: 0.8818
Epoch 93/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3392 - acc: 0.8909 - val_loss: 0.4610 - val_acc: 0.8605
Epoch 94/100
42000/42000 [==============================] - 1s 28us/sample - loss: 0.3302 - acc: 0.8946 - val_loss: 0.3992 - val_acc: 0.8845
Epoch 95/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3377 - acc: 0.8926 - val_loss: 0.4248 - val_acc: 0.8755
Epoch 96/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3321 - acc: 0.8932 - val_loss: 0.4212 - val_acc: 0.8764
Epoch 97/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3279 - acc: 0.8958 - val_loss: 0.4042 - val_acc: 0.8802
Epoch 98/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3348 - acc: 0.8917 - val_loss: 0.3966 - val_acc: 0.8849
Epoch 99/100
42000/42000 [==============================] - 1s 29us/sample - loss: 0.3188 - acc: 0.8980 - val_loss: 0.4341 - val_acc: 0.8735
Epoch 100/100
42000/42000 [==============================] - 1s 30us/sample - loss: 0.3311 - acc: 0.8932 - val_loss: 0.3852 - val_acc: 0.8892
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NN with batch normalization&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="n">results3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation accuracy: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">results3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;%&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NN with batch normalization
--------------------------------------------------------------------------------
60000/60000 [==============================] - 3s 53us/sample - loss: 0.3852 - acc: 0.8892
Validation accuracy: 88.92
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing the model on test dataset&#39;</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss :&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy :&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing the model on test dataset
18000/18000 [==============================] - 1s 52us/sample - loss: 0.6316 - acc: 0.8357
Test loss : 0.6316036958562004
Test accuracy : 0.8357222
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Classification Report&#39;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="o">*</span><span class="mi">40</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_o</span><span class="p">,</span> <span class="n">predictions</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Classification Report
--------------------------------------------------------------------------------
              precision    recall  f1-score   support

           0       0.84      0.88      0.86      1814
           1       0.85      0.86      0.86      1828
           2       0.86      0.85      0.86      1803
           3       0.79      0.79      0.79      1719
           4       0.86      0.88      0.87      1812
           5       0.76      0.83      0.80      1768
           6       0.83      0.81      0.82      1832
           7       0.91      0.85      0.88      1808
           8       0.80      0.79      0.80      1812
           9       0.84      0.82      0.83      1804

    accuracy                           0.84     18000
   macro avg       0.84      0.84      0.84     18000
weighted avg       0.84      0.84      0.84     18000

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Visualizing the confusion matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">7.2</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_o</span><span class="p">,</span> <span class="n">predictions</span><span class="p">),</span> <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Visualizing the confusion matrix
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[75]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f7fa60fd0b8&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2oAAAGjCAYAAABdU+ZeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># summarize history for accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model3 Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">loc</span> <span class="o">=</span> <span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># summarize history for loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model3 Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">loc</span> <span class="o">=</span> <span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAaoAAAEXCAYAAAD82wBdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbEAAAEXCAYAAAAjlXpCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model3</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[77]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>9</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Showing the image</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">20</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[78]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x7f7f9f3c72b0&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model3</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[</span><span class="mi">20</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[79]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[82]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x7f7f9f2fd198&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model3</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[83]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>9</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id='Conclusion'></a></p>
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h3><p>Evaluated the accuracy using two methods i.e. baby sitting the NN and NN through API. Followed all the required steps starting with loading the datasets to performing hyperparameter optimization and running a finer search by using a finer range. Explored different options in optimizers, number of activators, learning rate and activation methods in NN through API. Found that baby sitting process achieved the best accuracy of 21% using hyper parameter optimization. It might have been further improved but that's the trade off vs time taken to run the script. NN through API method achieved best accuracy of 90% on validation set. Also printed the classification report, visualized the confusion matrix and summarized history for accuracy and loss.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
